{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1\\. Задан двухмерный массив ar1 размерности (10, 10), состоящий из случайных целых чисел в пределах от 0 до 15. Вычислить разность s_odd - s_even, где s_odd - сумма элементов, стоящих на позиции (x, y), где (x + y) является нечетным числом; s_even - сумма элементов, стоящих на позиции (x, y), где (x + y) является четным числом.\n",
    "Решить задачу средствами numpy и/или pandas. Не использовать циклы и конструкции стандартного Python там, где можно использовать возможности данных библиотек\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8,  7, 11,  1, 10,  9,  4,  3,  8,  4],\n       [ 8,  3, 10,  4, 12,  3,  0,  2,  8, 11],\n       [ 7, 10,  0,  0,  1, 12, 10,  5,  4, 11],\n       [11,  3,  4,  4, 10, 11,  3,  1,  3,  5],\n       [ 4,  3,  7, 13,  5, 14,  0,  6,  9, 13],\n       [ 8, 11,  1, 11,  4,  1,  9,  2,  7, 10],\n       [12, 10, 13, 11, 14,  5,  1,  8, 10,  7],\n       [13, 10, 10, 14,  6,  3, 12, 10,  8,  0],\n       [ 3,  3,  3,  5, 11,  0, 12,  7,  8,  1],\n       [14,  6, 12, 14,  3,  1, 10, 13,  2,  9]], dtype=int64)"
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "ar1 = rng.integers(0, 15, size=(10, 10))  # 15 + 1\n",
    "ar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[False,  True, False,  True, False,  True, False,  True, False,\n         True],\n       [ True, False,  True, False,  True, False,  True, False,  True,\n        False],\n       [False,  True, False,  True, False,  True, False,  True, False,\n         True],\n       [ True, False,  True, False,  True, False,  True, False,  True,\n        False],\n       [False,  True, False,  True, False,  True, False,  True, False,\n         True],\n       [ True, False,  True, False,  True, False,  True, False,  True,\n        False],\n       [False,  True, False,  True, False,  True, False,  True, False,\n         True],\n       [ True, False,  True, False,  True, False,  True, False,  True,\n        False],\n       [False,  True, False,  True, False,  True, False,  True, False,\n         True],\n       [ True, False,  True, False,  True, False,  True, False,  True,\n        False]])"
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_x = np.arange(ar1.shape[0])\n",
    "idx_y = np.arange(ar1.shape[1]).reshape(-1, 1)\n",
    "idx_s_odd = (idx_x + idx_y) % 2 == 1\n",
    "idx_s_even = ~idx_s_odd\n",
    "idx_s_odd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "outputs": [
    {
     "data": {
      "text/plain": "19"
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_odd = ar1[idx_s_odd].sum()\n",
    "s_even = ar1[idx_s_even].sum()\n",
    "s_odd - s_even"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2\\. Датасет: Chinook_Sqlite.sqlite\n",
    "С помощью кода на Python с использованием sqlite3 и SQL решить задачу. Реализовать функции на Python:\n",
    "1. Которая возвращает все имеющиеся жанры.\n",
    "2. Которая возвращает ID жанров, в которых написано более 100 треков, и их (жанров) название.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "outputs": [],
   "source": [
    "import sqlite3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "outputs": [],
   "source": [
    "def find_all_genres(cur: sqlite3.Cursor) -> list:\n",
    "    stmt = 'SELECT * FROM Genre'\n",
    "    return cur.execute(stmt).fetchall()\n",
    "\n",
    "\n",
    "def find_genres_ids_by_n_tracks_gt(cur: sqlite3.Cursor, n: int = 100) -> list:\n",
    "    stmt = '''\n",
    "    SELECT G.GenreId, G.Name FROM Genre G\n",
    "    JOIN Track T ON G.GenreId = T.GenreId\n",
    "    GROUP BY T.GenreId HAVING COUNT(T.GenreId) > ?'''\n",
    "    return cur.execute(stmt, [n]).fetchall()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "outputs": [],
   "source": [
    "con = sqlite3.connect('data/Chinook_Sqlite.sqlite')\n",
    "cur = con.cursor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 'Rock'),\n (2, 'Jazz'),\n (3, 'Metal'),\n (4, 'Alternative & Punk'),\n (5, 'Rock And Roll'),\n (6, 'Blues'),\n (7, 'Latin'),\n (8, 'Reggae'),\n (9, 'Pop'),\n (10, 'Soundtrack'),\n (11, 'Bossa Nova'),\n (12, 'Easy Listening'),\n (13, 'Heavy Metal'),\n (14, 'R&B/Soul'),\n (15, 'Electronica/Dance'),\n (16, 'World'),\n (17, 'Hip Hop/Rap'),\n (18, 'Science Fiction'),\n (19, 'TV Shows'),\n (20, 'Sci Fi & Fantasy'),\n (21, 'Drama'),\n (22, 'Comedy'),\n (23, 'Alternative'),\n (24, 'Classical'),\n (25, 'Opera')]"
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_genres(cur)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 'Rock'),\n (2, 'Jazz'),\n (3, 'Metal'),\n (4, 'Alternative & Punk'),\n (7, 'Latin')]"
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_genres_ids_by_n_tracks_gt(cur, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3\\. Датасет: album_artist.xlsx\n",
    "С помощью кода на Python с использованием xlwings решить задачу. Вынести названия артистов на отдельный лист \"Артисты\" и присвоить каждому артисту уникальный идентификатор. Заменить названия артистов на исходном листе на идентификаторы с листа \"Артисты\".\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "outputs": [],
   "source": [
    "import xlwings as xw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "outputs": [],
   "source": [
    "wb = xw.Book('data/album_artist.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "outputs": [],
   "source": [
    "data_sheet: xw.Sheet = wb.sheets['Sheet1']\n",
    "artists_sheet: xw.Sheet = wb.sheets.add('Артисты')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "outputs": [],
   "source": [
    "artist_names_range: xw.Range = data_sheet.range('D2').expand('down')\n",
    "artist_names = sorted(set(artist_names_range.value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "outputs": [],
   "source": [
    "artists_map = {name: id_ for id_, name in enumerate(artist_names)}\n",
    "artists_sheet.range('A1').value = ('name', 'id')\n",
    "artists_sheet.range('A2').value = list(artists_map.items())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "outputs": [],
   "source": [
    "artist_names_range.value = list(map(lambda x: [artists_map[x]], artist_names_range.value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "outputs": [],
   "source": [
    "# wb.save()\n",
    "wb.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4\\. Датасет: us-countries.csv\n",
    "Создайте таблицу, где по строкам располагаются названия штатов, по столбцам - каждый из 12 месяцев 2020 года, а в ячейках таблицы хранится суммарное количество смертей в данном штате в этот месяц. Если информация за какой-то месяц отсутствует, укажите в этой ячейке значение 0.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "outputs": [
    {
     "data": {
      "text/plain": "        date     county       state     fips  cases  deaths\n0 2020-01-21  Snohomish  Washington  53061.0      1     0.0\n1 2020-01-22  Snohomish  Washington  53061.0      1     0.0\n2 2020-01-23  Snohomish  Washington  53061.0      1     0.0\n3 2020-01-24       Cook    Illinois  17031.0      1     0.0\n4 2020-01-24  Snohomish  Washington  53061.0      1     0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>county</th>\n      <th>state</th>\n      <th>fips</th>\n      <th>cases</th>\n      <th>deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-01-21</td>\n      <td>Snohomish</td>\n      <td>Washington</td>\n      <td>53061.0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-01-22</td>\n      <td>Snohomish</td>\n      <td>Washington</td>\n      <td>53061.0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-01-23</td>\n      <td>Snohomish</td>\n      <td>Washington</td>\n      <td>53061.0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-01-24</td>\n      <td>Cook</td>\n      <td>Illinois</td>\n      <td>17031.0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-01-24</td>\n      <td>Snohomish</td>\n      <td>Washington</td>\n      <td>53061.0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_countries_df = pd.read_csv('data/us-counties.csv', sep=',', parse_dates=['date'])\n",
    "us_countries_df = us_countries_df[us_countries_df['date'].dt.year == 2020]\n",
    "us_countries_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "outputs": [
    {
     "data": {
      "text/plain": "            1   2     3      4      5       6       7       8       9   \\\nAlabama      0   0    42   4044  14438   23697   38436   58883   71419   \nAlaska       0   0     8    173    243     291     496     843    1265   \nArizona      0   0   118   4870  19864   37510   79906  138063  161423   \nArkansas     0   0    36   1007   3137    5895   10829   19077   32549   \nCalifornia   0   0  1113  30176  99379  155690  232621  349458  438311   \n\n                10      11      12  \nAlabama      85064   98538  131827  \nAlaska        1890    2802    5136  \nArizona     179976  189527  237564  \nArkansas     51328   66765   95245  \nCalifornia  522654  551791  683920  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Alabama</th>\n      <td>0</td>\n      <td>0</td>\n      <td>42</td>\n      <td>4044</td>\n      <td>14438</td>\n      <td>23697</td>\n      <td>38436</td>\n      <td>58883</td>\n      <td>71419</td>\n      <td>85064</td>\n      <td>98538</td>\n      <td>131827</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>173</td>\n      <td>243</td>\n      <td>291</td>\n      <td>496</td>\n      <td>843</td>\n      <td>1265</td>\n      <td>1890</td>\n      <td>2802</td>\n      <td>5136</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>0</td>\n      <td>0</td>\n      <td>118</td>\n      <td>4870</td>\n      <td>19864</td>\n      <td>37510</td>\n      <td>79906</td>\n      <td>138063</td>\n      <td>161423</td>\n      <td>179976</td>\n      <td>189527</td>\n      <td>237564</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>0</td>\n      <td>0</td>\n      <td>36</td>\n      <td>1007</td>\n      <td>3137</td>\n      <td>5895</td>\n      <td>10829</td>\n      <td>19077</td>\n      <td>32549</td>\n      <td>51328</td>\n      <td>66765</td>\n      <td>95245</td>\n    </tr>\n    <tr>\n      <th>California</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1113</td>\n      <td>30176</td>\n      <td>99379</td>\n      <td>155690</td>\n      <td>232621</td>\n      <td>349458</td>\n      <td>438311</td>\n      <td>522654</td>\n      <td>551791</td>\n      <td>683920</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Способ 1. Сводная таблица\n",
    "pivot_table = us_countries_df.pivot_table(\n",
    "    'deaths',\n",
    "    index=us_countries_df['state'].rename(None),\n",
    "    columns=us_countries_df['date'].dt.month.rename(None),\n",
    "    aggfunc='sum'\n",
    ")\n",
    "pivot_table = pivot_table.fillna(0).astype(int)\n",
    "pivot_table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "outputs": [
    {
     "data": {
      "text/plain": "            1   2     3      4      5       6       7       8       9   \\\nAlabama      0   0    42   4044  14438   23697   38436   58883   71419   \nAlaska       0   0     8    173    243     291     496     843    1265   \nArizona      0   0   118   4870  19864   37510   79906  138063  161423   \nArkansas     0   0    36   1007   3137    5895   10829   19077   32549   \nCalifornia   0   0  1113  30176  99379  155690  232621  349458  438311   \n\n                10      11      12  \nAlabama      85064   98538  131827  \nAlaska        1890    2802    5136  \nArizona     179976  189527  237564  \nArkansas     51328   66765   95245  \nCalifornia  522654  551791  683920  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Alabama</th>\n      <td>0</td>\n      <td>0</td>\n      <td>42</td>\n      <td>4044</td>\n      <td>14438</td>\n      <td>23697</td>\n      <td>38436</td>\n      <td>58883</td>\n      <td>71419</td>\n      <td>85064</td>\n      <td>98538</td>\n      <td>131827</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>173</td>\n      <td>243</td>\n      <td>291</td>\n      <td>496</td>\n      <td>843</td>\n      <td>1265</td>\n      <td>1890</td>\n      <td>2802</td>\n      <td>5136</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>0</td>\n      <td>0</td>\n      <td>118</td>\n      <td>4870</td>\n      <td>19864</td>\n      <td>37510</td>\n      <td>79906</td>\n      <td>138063</td>\n      <td>161423</td>\n      <td>179976</td>\n      <td>189527</td>\n      <td>237564</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>0</td>\n      <td>0</td>\n      <td>36</td>\n      <td>1007</td>\n      <td>3137</td>\n      <td>5895</td>\n      <td>10829</td>\n      <td>19077</td>\n      <td>32549</td>\n      <td>51328</td>\n      <td>66765</td>\n      <td>95245</td>\n    </tr>\n    <tr>\n      <th>California</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1113</td>\n      <td>30176</td>\n      <td>99379</td>\n      <td>155690</td>\n      <td>232621</td>\n      <td>349458</td>\n      <td>438311</td>\n      <td>522654</td>\n      <td>551791</td>\n      <td>683920</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Способ 2. Groupby\n",
    "groupby_table = us_countries_df.groupby([\n",
    "    us_countries_df['state'].rename(None),\n",
    "    us_countries_df['date'].dt.month.rename(None)\n",
    "])['deaths'].sum()\n",
    "grouped_table = groupby_table.unstack()\n",
    "grouped_table = grouped_table.fillna(0).astype(int)\n",
    "grouped_table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5\\. По данным из файла data/meals.json сформировать словарь, в котором по идентификатору блюда можно получить список ингредиентов."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "outputs": [],
   "source": [
    "def read_json(path: str) -> dict:\n",
    "    with open(path) as f:\n",
    "        return json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "outputs": [
    {
     "data": {
      "text/plain": "{'52768': ['digestive biscuits',\n  'butter',\n  'Bramley apples',\n  'butter, softened',\n  'caster sugar',\n  'free-range eggs, beaten',\n  'ground almonds',\n  'almond extract',\n  'flaked almonds'],\n '52893': ['Plain Flour',\n  'Caster Sugar',\n  'Butter',\n  'Braeburn Apples',\n  'Butter',\n  'Demerara Sugar',\n  'Blackberrys',\n  'Cinnamon',\n  'Ice Cream'],\n '53049': ['Milk',\n  'Oil',\n  'Eggs',\n  'Flour',\n  'Baking Powder',\n  'Salt',\n  'Unsalted Butter',\n  'Sugar',\n  'Peanut Butter'],\n '53050': ['Chicken Thighs',\n  'Challots',\n  'Ginger',\n  'Garlic Clove',\n  'Cayenne Pepper',\n  'Turmeric',\n  'Cumin',\n  'Coriander',\n  'Fennel',\n  'Tamarind Paste',\n  'Coconut Milk',\n  'Sugar',\n  'Water']}"
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meals = read_json('data/meals.json')\n",
    "meals = meals['meals']\n",
    "meals_ingredients = {}\n",
    "for meal in meals:\n",
    "    meals_ingredients[meal['idMeal']] = [\n",
    "        v for k, v in meal.items() if k.startswith('strIngredient') and v\n",
    "    ]\n",
    "meals_ingredients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6\\. Датасет: Womens Clothing E-Commerce Reviews.csv\n",
    "Для каждого уникального значения в столбце Division Name найти топ-5 самых часто используемых слов в описании отзыва. Исключить из рассмотрения стоп-слова.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus.reader.wordnet import VERB, NOUN\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         Review Text   Division Name\n0  Absolutely wonderful - silky and sexy and comf...       Initmates\n1  Love this dress!  it's sooo pretty.  i happene...         General\n2  I had such high hopes for this dress and reall...         General\n3  I love, love, love this jumpsuit. it's fun, fl...  General Petite\n4  This shirt is very flattering to all due to th...         General",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Text</th>\n      <th>Division Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Absolutely wonderful - silky and sexy and comf...</td>\n      <td>Initmates</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n      <td>General</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I had such high hopes for this dress and reall...</td>\n      <td>General</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n      <td>General Petite</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This shirt is very flattering to all due to th...</td>\n      <td>General</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_clothing_reviews_df = pd.read_csv('data/Womens Clothing E-Commerce Reviews.csv', sep=',', index_col=0)\n",
    "w_clothing_reviews_df = w_clothing_reviews_df[['Review Text', 'Division Name']].dropna()\n",
    "w_clothing_reviews_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[^a-z0-9\\s]', re.IGNORECASE)\n",
    "\n",
    "\n",
    "def agg(s: pd.Series, lemmatizer: nltk.WordNetLemmatizer, stop_words: set[str]):\n",
    "    text = pattern.sub(' ', ' '.join(s.array).casefold())\n",
    "    normalized_text = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        pos = VERB if word == 'was' else NOUN\n",
    "        lemma = lemmatizer.lemmatize(word, pos)\n",
    "        if lemma not in stop_words:\n",
    "            normalized_text.append(lemma)\n",
    "    return nltk.FreqDist(normalized_text).most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "outputs": [
    {
     "data": {
      "text/plain": "Division Name\nGeneral           [(dress, 6542), (fit, 6048), (size, 5601), (lo...\nGeneral Petite    [(dress, 4657), (fit, 3549), (size, 3298), (lo...\nInitmates         [(fit, 580), (size, 538), (love, 526), (like, ...\nName: Review Text, dtype: object"
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "w_clothing_reviews_df.groupby('Division Name')['Review Text'].agg(lambda s: agg(s, lemmatizer, stop_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7\\. Датасет: people.*.csv\n",
    "В people.*.csv найти номера карт, сумма цифр в которых кратна 7. Выполнить задание с использованием Dask, распараллелив процесс обработки данных. Выполнить задание с использованием Dask (корректным!), распараллелив процесс обработки данных (использование Dask должно приводить к истинной параллельной обработке данных).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "outputs": [
    {
     "data": {
      "text/plain": "0    5438 1968 9922 9337\n1      3769 395661 41045\n2    2657 4280 9607 4252\n3      3454 218578 39569\n4    4994 8117 4888 3147\nName: card, dtype: object"
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards_s: dd.Series = dd.read_csv('data/people/*.csv')['card']\n",
    "cards_s.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "outputs": [
    {
     "data": {
      "text/plain": "8      2718 8407 9504 4344\n22       3435 949578 19046\n31       3769 780398 39694\n32     4904 9489 9196 8990\n33       3770 280012 98351\n              ...         \n990      3706 093760 91856\n992    4895 9639 6182 3803\n996      3473 326557 62424\n998    4796 5663 9678 4738\n999    5515 8388 1476 5236\nName: card, Length: 449, dtype: object"
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = cards_s.apply(lambda x: sum([int(i) for i in x if i.isdigit()]), meta=('card', int)) % 7 == 0\n",
    "cards_s[mask].compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8\\. Подсчитать, сколько раз во всех текстовых файлах, лежащих в каталоге fish, встречаются слова, начинающиеся с прописной буквы. Выполнить задание с использованием Dask, распараллелив процесс обработки данных. Выполнить задание с использованием Dask (корректным!), распараллелив процесс обработки данных (использование Dask должно приводить к истинной параллельной обработке данных)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "outputs": [],
   "source": [
    "fish_bag = db.read_text('data/fish/*.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "outputs": [
    {
     "data": {
      "text/plain": "649"
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer(accum: int, curr: str) -> int:\n",
    "    for word in nltk.word_tokenize(curr):\n",
    "        if word[0].isupper():\n",
    "            accum += 1\n",
    "    return accum\n",
    "\n",
    "\n",
    "def combine(left, right):\n",
    "    return left + right\n",
    "\n",
    "\n",
    "n_titles = fish_bag.fold(reducer, combine, initial=0).compute()\n",
    "n_titles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9\\. Сгенерируйте 10 строк длиной в 10000 символов, состоящих из маленьких английских букв. Посчитайте, сколько раз в этих 10 строках встречается шаблон \"x?y?z\", где знак вопроса обозначает один любой символ. Решение этой задачи распараллелить, используя multiprocessing Pool. Сравнить продолжительность последовательного и параллельного решения задачи."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "outputs": [],
   "source": [
    "import string\n",
    "import re  # noqa\n",
    "from multiprocessing import Pool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "strings = [''.join(rng.choice(list(string.ascii_lowercase), size=10_000)) for _ in range(10)]\n",
    "len(strings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/nmatch.py\n"
     ]
    }
   ],
   "source": [
    "%%file 'src/nmatch.py'\n",
    "import re\n",
    "\n",
    "\n",
    "def nmatch(s: str, pattern: re.Pattern) -> int:\n",
    "    return len(pattern.findall(s))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "outputs": [],
   "source": [
    "def blocking_mode(strings: list[str]) -> int:\n",
    "    pattern = re.compile(r'x.y.z')\n",
    "    n = 0\n",
    "    for s in strings:\n",
    "        n += nmatch(s, pattern)\n",
    "    return n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "outputs": [],
   "source": [
    "def nonblocking_mode(strings: list[str]) -> int:\n",
    "    from src.nmatch import nmatch\n",
    "    pattern = re.compile(r'x.y.z')\n",
    "    with Pool(8) as pool:\n",
    "        result = pool.starmap(nmatch, zip(strings, [pattern] * len(strings)))\n",
    "        return sum(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 µs ± 4.22 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "blocking_mode(strings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 ms ± 16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "nonblocking_mode(strings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "outputs": [],
   "source": [
    "assert blocking_mode(strings) == nonblocking_mode(strings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "10\\. Создайте dask.array размерности 10 тыс на 5, заполненный случайными целыми числами на отрезке [0, 10]. Создайте версию этого массива, оставив только строки, в которых есть число 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "outputs": [],
   "source": [
    "import dask.array as da"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = da.random.randint(0, 10 + 1, size=(10_000, 5), chunks=(1000, 5))\n",
    "arr.npartitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2,  8,  2,  7,  7],\n       [ 2,  9,  7, 10,  9],\n       [ 7, 10,  2,  2,  7],\n       ...,\n       [ 8,  2,  7,  0,  9],\n       [ 3,  7,  6,  3,  7],\n       [ 7,  8,  3,  7,  7]])"
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[(arr[:] == 7).any(axis=1)].compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}