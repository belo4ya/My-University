{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import string\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['высокопревосходительства',\n 'попреблагорассмотрительст',\n 'попреблагорассмотрительствующемуся',\n 'убегающих',\n 'уменьшившейся']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATA_DIR.joinpath('litw-win.txt'), encoding='cp1251') as f:\n",
    "    words = [line.strip().split()[-1].lower() for line in f]\n",
    "\n",
    "words[-5:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('с велечайшим усилием выбравшись из потока убегающих людей Кутузов со '\n",
    "        'свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def find_replacements(text: str, dictionary: Iterable) -> dict[str, tuple[int, list[str]]]:\n",
    "    dictionary = set(dictionary)\n",
    "    replacements = {}\n",
    "    for word in text.lower().split():\n",
    "        if word not in dictionary:\n",
    "            sorted_edit_distances = sorted(\n",
    "                map(lambda x: (nltk.edit_distance(word, x), x), dictionary),\n",
    "                key=lambda x: x[0]\n",
    "            )\n",
    "            min_edit_distance = sorted_edit_distances[0][0]\n",
    "            replacement_list = []\n",
    "            for edit_distance, dict_word in sorted_edit_distances:\n",
    "                if edit_distance > min_edit_distance:\n",
    "                    break\n",
    "                replacement_list.append(dict_word)\n",
    "            replacements[word] = (min_edit_distance, replacement_list)\n",
    "\n",
    "    return replacements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "replacements = find_replacements(text, words)\n",
    "replacements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fixed_text = text\n",
    "for word, repl in replacements.items():\n",
    "    fixed_text = fixed_text.replace(word, repl[1][0])\n",
    "fixed_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task1_text = (\n",
    "    'Считайте слова из файла `litw-win.txt` и запишите их в список `words`. '\n",
    "    'В заданном предложении исправьте все опечатки, заменив слова с опечатками '\n",
    "    'на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. '\n",
    "    'Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`.'\n",
    ")\n",
    "stemmer = nltk.SnowballStemmer('russian')\n",
    "lemmer = pymorphy2.MorphAnalyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=[\n",
    "        [word, stemmer.stem(word), lemmer.parse(word)[0].normal_form]\n",
    "        for word in nltk.word_tokenize(task1_text)\n",
    "        if word not in string.punctuation\n",
    "    ],\n",
    "    columns=['word', 'stemma', 'lemma']\n",
    ").sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CountVectorizer().fit_transform(nltk.sent_tokenize(task1_text)).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "descriptions_df = pd.read_csv(DATA_DIR.joinpath('preprocessed_descriptions.csv'), sep=',')\n",
    "descriptions_df = descriptions_df.rename(columns={'preprocessed_descriptions': 'description'})\n",
    "descriptions_df.info()\n",
    "descriptions_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "descriptions = descriptions_df['description'].dropna()\n",
    "words = list({word for text in descriptions for word in nltk.word_tokenize(text)})\n",
    "len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "random_pairs = rng.choice(words, size=(5, 2)).tolist()\n",
    "list(map(lambda x: (x, nltk.edit_distance(x[0], x[1])), random_pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def similarity(word: str, words: list[str], k: int) -> list[str]:\n",
    "    return sorted(words, key=lambda x: nltk.edit_distance(word, x))[:k]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarity('hello', words, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для лемматизации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer('english')\n",
    "lemmatizer = nltk.WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        'stemmed_word': map(stemmer.stem, words),\n",
    "        'normalized_word': map(lemmatizer.lemmatize, words),\n",
    "    },\n",
    "    index=pd.Series(words, name='words')\n",
    ")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Всего слов: {len(df)}')\n",
    "print(f'Основ отличается: {len(set(df.index) - set(df[\"stemmed_word\"]))}')\n",
    "print(f'Лемм отличается: {len(set(df.index) - set(df[\"normalized_word\"]))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_words = [word for text in descriptions for word in nltk.word_tokenize(text)]\n",
    "words_without_stopwords = [word for word in all_words if word not in stop_words]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_words = len(all_words)\n",
    "n_words_without_stopwords = len(words_without_stopwords)\n",
    "print(f'Слов всего: {n_words}')\n",
    "print(f'Слов всего после удаления стоп-слов: {n_words_without_stopwords}')\n",
    "print(f'Доля стоп-слов {(n_words - n_words_without_stopwords) / n_words:.2%}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Топ-10 по частоте (до): \\n{nltk.FreqDist(all_words).most_common(10)}')\n",
    "print(f'Топ-10 по частоте (после): \\n{nltk.FreqDist(words_without_stopwords).most_common(10)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "descriptions_sample = descriptions_df.dropna().sample(5)\n",
    "descriptions_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfid_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "tfid_vectorizer.fit(descriptions_sample['description'])\n",
    "descriptions_sample['vector'] = descriptions_sample['description'].apply(\n",
    "    lambda x: tfid_vectorizer.transform([x]).toarray()\n",
    ")\n",
    "print(descriptions_sample.to_string())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name_values = [name[:8] + '...' for name in descriptions_sample['name'].array]\n",
    "vector_values = [v.reshape(-1) for v in descriptions_sample['vector'].array]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cosine_distances_df = pd.DataFrame(\n",
    "    data=cosine_distances(vector_values, vector_values),\n",
    "    index=name_values,\n",
    "    columns=name_values,\n",
    ")\n",
    "cosine_distances_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cosine_similarity_df = pd.DataFrame(\n",
    "    data=cosine_similarity(vector_values, vector_values),\n",
    "    index=name_values,\n",
    "    columns=name_values,\n",
    ")\n",
    "cosine_similarity_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "similarity_top = cosine_similarity_df.to_numpy()\n",
    "np.sort(similarity_top[(0 + eps < similarity_top) & (similarity_top < 1 - eps)])[::-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Два различных рецепта тем более похожи,\n",
    "# чем меньше косинусное расстояние между ними\n",
    "# (или чем больше косинусная схожесть: 1 - cosine)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-bc21e837",
   "language": "python",
   "display_name": "PyCharm (09_string_expert)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}