{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Билет 13"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задача 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n0      20000    2          2         1   24      2      2     -1     -1   \n1      90000    2          2         2   34      0      0      0      0   \n2      50000    2          2         1   37      0      0      0      0   \n3      50000    1          2         1   57     -1      0     -1      0   \n4      50000    1          1         2   37      0      0      0      0   \n\n   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n0     -2  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n1      0  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n2      0  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n3      0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n4      0  ...    19394.0    19619.0    20024.0    2500.0    1815.0     657.0   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default  \n0       0.0       0.0       0.0        1  \n1    1000.0    1000.0    5000.0        0  \n2    1100.0    1069.0    1000.0        0  \n3    9000.0     689.0     679.0        0  \n4    1000.0    1000.0     800.0        0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_1</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>default</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>14331.0</td>\n      <td>14948.0</td>\n      <td>15549.0</td>\n      <td>1518.0</td>\n      <td>1500.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>5000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>28314.0</td>\n      <td>28959.0</td>\n      <td>29547.0</td>\n      <td>2000.0</td>\n      <td>2019.0</td>\n      <td>1200.0</td>\n      <td>1100.0</td>\n      <td>1069.0</td>\n      <td>1000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>57</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>20940.0</td>\n      <td>19146.0</td>\n      <td>19131.0</td>\n      <td>2000.0</td>\n      <td>36681.0</td>\n      <td>10000.0</td>\n      <td>9000.0</td>\n      <td>689.0</td>\n      <td>679.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>19394.0</td>\n      <td>19619.0</td>\n      <td>20024.0</td>\n      <td>2500.0</td>\n      <td>1815.0</td>\n      <td>657.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>800.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = pd.read_csv(\"../data/classification/credit.csv\")\n",
    "print(credit_df.shape)\n",
    "credit_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Константных и уникальных признаков нет:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Series([], dtype: int64)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_stat = credit_df.nunique()\n",
    "uniq_stat[(uniq_stat == 1) | (uniq_stat == len(credit_df))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пропусков нет:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Series([], dtype: int64)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_stat = credit_df.isna().sum()\n",
    "na_stat[na_stat > 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дубликаты присутствуют, удалим их:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default\n20000      1    2          2         24    2      2      4      4      4      4     1650.0     1650.0     1650.0     1650.0     1650.0     1650.0     0.0       0.0       0.0       0.0       0.0       0.0       1          1\n50000      1    2          2         26    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n360000     2    1          2         29    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n                           1         41   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       1          1\n           1    2          1         41    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       1          1\n                1          2         32   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n                                     29    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n300000     1    1          2         27   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n210000     2    1          2         39    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n200000     2    1          1         36    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n                                     34    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n180000     2    1          2         28    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n           1    2          1         26   -1     -1     -1     -1     -1     -1     396.0      396.0      396.0      396.0      396.0      396.0      396.0     396.0     396.0     396.0     396.0     396.0     0          1\n160000     2    3          2         26   -1     -1     -1     -1     -1     -1     390.0      390.0      390.0      390.0      390.0      390.0      390.0     390.0     390.0     390.0     390.0     390.0     0          1\n           1    2          2         28   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n150000     2    1          2         28    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n                           1         38    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       1          1\n                                     31    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n90000      2    1          2         31    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n80000      2    3          1         42   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n                2          2         25   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n                           1         31   -2     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n50000      2    1          2         23    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       0          1\n500000     1    1          1         43    1     -2     -2     -2     -2     -2     0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.0       0.0       0.0       0.0       0.0       1          1\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df[credit_df.duplicated()].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Series([], dtype: int64)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = credit_df.drop_duplicates()\n",
    "credit_df[credit_df.duplicated()].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23976, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n0      20000    2          2         1   24      2      2     -1     -1   \n1      90000    2          2         2   34      0      0      0      0   \n2      50000    2          2         1   37      0      0      0      0   \n3      50000    1          2         1   57     -1      0     -1      0   \n4      50000    1          1         2   37      0      0      0      0   \n\n   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n0     -2  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n1      0  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n2      0  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n3      0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n4      0  ...    19394.0    19619.0    20024.0    2500.0    1815.0     657.0   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default  \n0       0.0       0.0       0.0        1  \n1    1000.0    1000.0    5000.0        0  \n2    1100.0    1069.0    1000.0        0  \n3    9000.0     689.0     679.0        0  \n4    1000.0    1000.0     800.0        0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_1</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>default</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>14331.0</td>\n      <td>14948.0</td>\n      <td>15549.0</td>\n      <td>1518.0</td>\n      <td>1500.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>5000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>28314.0</td>\n      <td>28959.0</td>\n      <td>29547.0</td>\n      <td>2000.0</td>\n      <td>2019.0</td>\n      <td>1200.0</td>\n      <td>1100.0</td>\n      <td>1069.0</td>\n      <td>1000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>57</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>20940.0</td>\n      <td>19146.0</td>\n      <td>19131.0</td>\n      <td>2000.0</td>\n      <td>36681.0</td>\n      <td>10000.0</td>\n      <td>9000.0</td>\n      <td>689.0</td>\n      <td>679.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>19394.0</td>\n      <td>19619.0</td>\n      <td>20024.0</td>\n      <td>2500.0</td>\n      <td>1815.0</td>\n      <td>657.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>800.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(credit_df.shape)\n",
    "credit_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выборка несбалансированная. Для улучшения результата нужно будет взвесить ошибку по имеющимся данным"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18675\n",
      "1     5301\n",
      "Name: default, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 300x250 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vc = credit_df[\"default\"].value_counts()\n",
    "print(vc)\n",
    "credit_df[\"default\"].value_counts().plot.bar(rot=0, figsize=(3, 2.5));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализует объекты Dataset для работы с DataLoader:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CreditDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, scaler=None):\n",
    "        if scaler:\n",
    "            self.scaler = scaler\n",
    "            scale = self.scaler.transform\n",
    "        else:\n",
    "            self.scaler = StandardScaler()\n",
    "            scale = self.scaler.fit_transform\n",
    "\n",
    "        target_col = \"default\"\n",
    "        data, targets = df.drop(columns=[target_col]), df[target_col]\n",
    "\n",
    "        self.data = torch.tensor(scale(data), dtype=torch.float)\n",
    "        self.num_features = self.data.size(1)\n",
    "        self.targets = torch.tensor(targets.to_numpy(), dtype=torch.long)\n",
    "        self.classes = [str(cls) for cls in targets.unique()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделим выборку на тренировочную и тестовую, создадим объект Dataset для каждой, StandardScaler будем обучать только на тренировочных данных:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(19180, 4796, 23, ['0', '1'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(credit_df, test_size=0.2)\n",
    "\n",
    "train_dataset = CreditDataset(train_df)\n",
    "test_dataset = CreditDataset(test_df, scaler=train_dataset.scaler)\n",
    "len(train_dataset), len(test_dataset), train_dataset.num_features, train_dataset.classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассчитаем веса классов:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0000, 3.5483])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, counts = train_dataset.targets.unique(return_counts=True)\n",
    "weights = counts.max() / counts\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Простой линейный классификатор в связке с функцией потерь `CrossEntropyLoss`, которая содержит фун-ию активации `logsoftmax`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class CreditCNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "CreditCNNClassifier(\n  (classifier): Sequential(\n    (0): Linear(in_features=23, out_features=256, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=256, out_features=256, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=256, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CreditCNNClassifier(train_dataset.num_features, num_classes=len(train_dataset.classes)).to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights.to(DEVICE))\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.002)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Цикл обучения модели:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_y_true_y_pred(model, dataloader):\n",
    "    model.eval()\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x)\n",
    "        y_test.append(y.unsqueeze(1))\n",
    "        y_pred.append(pred)\n",
    "    return torch.flatten(torch.vstack(y_test)), torch.vstack(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    num_batches = len(train_dataloader)\n",
    "    avg_loss, avg_accuracy = 0, 0\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = net(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_true = torch.flatten(y).detach().cpu()\n",
    "        y_pred = torch.flatten(pred.argmax(1)).detach().cpu()\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "        avg_loss += loss\n",
    "        avg_accuracy += accuracy\n",
    "    train_loss, train_accuracy = (avg_loss / num_batches).item(), avg_accuracy / num_batches\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    net.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(net, test_dataloader)\n",
    "    test_loss, test_accuracy = loss_fn(y_pred, y_true).item(), metrics.accuracy_score(y_true.cpu(),\n",
    "                                                                                      y_pred.argmax(1).cpu())\n",
    "    print(f\"[Epoch {epoch + 1:>2}/{epochs}] Train: loss={train_loss:.6f}, accuracy={train_accuracy:.4f} | \"\n",
    "          f\"Test: loss={test_loss:.6f}, accuracy={test_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "График значений функции потерь на обучающем множестве:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(torch.arange(len(train_loss_history)), train_loss_history)\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader)\n",
    "y_true, y_pred = y_true.cpu(), y_pred.argmax(1).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    display_labels=test_dataset.classes,\n",
    "    xticks_rotation=0,\n",
    ")\n",
    "cm_display.ax_.grid(False)\n",
    "cm_display.figure_.set_size_inches(3.5, 3.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, target_names=test_dataset.classes, zero_division=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из-за сильной несбалансированности классов модель плохо справляется с распознаванием не доминирующего класса."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задача 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WordVocab:\n",
    "    PAD = \"<PAD>\"\n",
    "    UNKNOWN = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, texts):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for text in texts:\n",
    "            words = nltk.word_tokenize(text)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.i2w = [self.PAD, self.UNKNOWN, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.i2w)}\n",
    "        unknown_idx = w2i[self.UNKNOWN]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.i2w)\n",
    "\n",
    "    def encode(self, text):\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(text)]\n",
    "        indices += [self.w2i[self.PAD]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RE_URL = re.compile(r\"\\w+://\\S+\", flags=re.MULTILINE)\n",
    "RE_ALPHA = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "\n",
    "\n",
    "class ActivitiesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, vocab=None, encoder=None):\n",
    "        self.raw_texts = df[\"Text\"].tolist()\n",
    "        self.texts = [self.preprocess_text(text) for text in self.raw_texts]\n",
    "        self.vocab = vocab or WordVocab(self.texts)\n",
    "\n",
    "        if encoder:\n",
    "            self.encoder = encoder\n",
    "            encode = self.encoder.transform\n",
    "        else:\n",
    "            self.encoder = LabelEncoder()\n",
    "            encode = self.encoder.fit_transform\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(text) for text in self.texts])\n",
    "        targets = encode(df[\"Review-Activity\"])\n",
    "        self.classes = self.encoder.classes_.tolist()\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_text(text):\n",
    "        text = text.lower()\n",
    "        for pat in [RE_URL, RE_ALPHA]:\n",
    "            text = pat.sub(\" \", text)\n",
    "\n",
    "        words = []\n",
    "        for word in nltk.word_tokenize(text):\n",
    "            if word not in STOPWORDS and len(word) >= 3:\n",
    "                word = snowball_stemmer.stem(word)\n",
    "                if word not in STOPWORDS and len(word) >= 3:\n",
    "                    words.append(word)\n",
    "\n",
    "        return \" \".join(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выборка относительно сбалансированная:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activities_df = pd.read_csv(\"../data/nlp/activities.csv\")\n",
    "vc = activities_df[\"Review-Activity\"].value_counts()\n",
    "print(vc)\n",
    "activities_df[\"Review-Activity\"].value_counts().plot.bar(rot=0, figsize=(3, 2.5));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По аналогии с предыдущим заданием Vocab и Encoder буду обучать только на тренировочной выборке:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(activities_df, test_size=0.2, random_state=0)\n",
    "\n",
    "train_dataset = ActivitiesDataset(train_df)\n",
    "test_dataset = ActivitiesDataset(test_df, vocab=train_dataset.vocab, encoder=train_dataset.encoder)\n",
    "print(len(train_dataset.vocab), train_dataset.vocab.max_len)\n",
    "len(train_dataset), len(test_dataset), train_dataset.classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно было RNN, можно было MLP (наверное, нельзя - делала в предыдущем задании) - сделаю CNN:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ActivitiesCNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=32, kernel_size=2),\n",
    "            nn.BatchNorm1d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=2),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        # сжатие размерности, предшествующей кол-ву слоев (как бы кол-во слов) до 8\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(8)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.permute(x, dims=(0, 2, 1))\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = ActivitiesCNNClassifier(\n",
    "    num_embeddings=len(train_dataset.vocab),\n",
    "    embedding_dim=64,\n",
    "    num_classes=len(train_dataset.classes),\n",
    ").to(DEVICE)\n",
    "\n",
    "# расчет весов классов\n",
    "_, counts = train_dataset.targets.unique(return_counts=True)\n",
    "weights = counts.max() / counts\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights.to(DEVICE))\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, drop_last=True)\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    num_batches = len(train_dataloader)\n",
    "    avg_loss, avg_accuracy = 0, 0\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = net(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_true = torch.flatten(y).detach().cpu()\n",
    "        y_pred = torch.flatten(pred.argmax(1)).detach().cpu()\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "        avg_loss += loss\n",
    "        avg_accuracy += accuracy\n",
    "    train_loss, train_accuracy = (avg_loss / num_batches).item(), avg_accuracy / num_batches\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    net.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(net, test_dataloader)\n",
    "    test_loss, test_accuracy = loss_fn(y_pred, y_true).item(), metrics.accuracy_score(y_true.cpu(), y_pred.argmax(1).cpu())\n",
    "    print(f\"[Epoch {epoch + 1:>2}/{epochs}] Train: loss={train_loss:.6f}, accuracy={train_accuracy:.4f} | \"\n",
    "          f\"Test: loss={test_loss:.6f}, accuracy={test_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "График значений функции потерь на обучающем множестве:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(torch.arange(len(train_loss_history)), train_loss_history)\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader)\n",
    "y_true, y_pred = y_true.cpu(), y_pred.argmax(1).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    display_labels=test_dataset.classes,\n",
    "    xticks_rotation=0,\n",
    ")\n",
    "cm_display.ax_.grid(False)\n",
    "cm_display.figure_.set_size_inches(3.5, 3.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, target_names=test_dataset.classes, zero_division=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CNN модель отлично справилась с поставленной задачей."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
