{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "%matplotlib inline\n",
    "# @formatter:on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.set_warn_always(True)\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/\")\n",
    "\n",
    "CUDA = \"cuda\"\n",
    "CPU = \"cpu\"\n",
    "DEVICE = CUDA if torch.cuda.is_available() else CPU\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def na_stat(df: pd.DataFrame) -> pd.Series:\n",
    "    stat = df.isna().sum()\n",
    "    return stat[stat > 0]\n",
    "\n",
    "\n",
    "def duplicates_stat(df: pd.DataFrame) -> pd.Series:\n",
    "    return df[df.duplicated()].value_counts()\n",
    "\n",
    "\n",
    "def get_categorical_columns(df: pd.DataFrame) -> pd.Index:\n",
    "    return df.select_dtypes(object).columns\n",
    "\n",
    "\n",
    "def get_numerical_columns(df: pd.DataFrame) -> pd.Index:\n",
    "    return df.select_dtypes(np.number).columns\n",
    "\n",
    "\n",
    "def count_categories(df: pd.DataFrame) -> pd.Series:\n",
    "    return df[get_categorical_columns(df)].nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave  None      Reg   \n1   2          20       RL         80.0     9600   Pave  None      Reg   \n2   3          60       RL         68.0    11250   Pave  None      IR1   \n3   4          70       RL         60.0     9550   Pave  None      IR1   \n4   5          60       RL         84.0    14260   Pave  None      IR1   \n\n  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n0         Lvl    AllPub  ...        0   None  None        None       0      2   \n1         Lvl    AllPub  ...        0   None  None        None       0      5   \n2         Lvl    AllPub  ...        0   None  None        None       0      9   \n3         Lvl    AllPub  ...        0   None  None        None       0      2   \n4         Lvl    AllPub  ...        0   None  None        None       0     12   \n\n  YrSold  SaleType  SaleCondition  SalePrice  \n0   2008        WD         Normal     208500  \n1   2007        WD         Normal     181500  \n2   2008        WD         Normal     223500  \n3   2006        WD        Abnorml     140000  \n4   2008        WD         Normal     250000  \n\n[5 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>None</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>None</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>None</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>None</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>None</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df: pd.DataFrame = pd.read_csv(DATA_DIR / \"regression/house.csv\")\n",
    "print(house_df.shape)\n",
    "house_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          1460 non-null   object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1460 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1460 non-null   object \n",
      " 31  BsmtCond       1460 non-null   object \n",
      " 32  BsmtExposure   1460 non-null   object \n",
      " 33  BsmtFinType1   1460 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1460 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1460 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    1460 non-null   object \n",
      " 58  GarageType     1460 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1460 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1460 non-null   object \n",
      " 64  GarageCond     1460 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         1460 non-null   object \n",
      " 73  Fence          1460 non-null   object \n",
      " 74  MiscFeature    1460 non-null   object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "house_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/emmanueldjegou/house-prices-advanced-regression-techniques/notebook\n",
    "house_df = house_df[[\n",
    "    \"SalePrice\",  # target\n",
    "    \"OverallQual\",\n",
    "    \"GrLivArea\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"GarageCars\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"Fireplaces\",\n",
    "    \"Foundation\",\n",
    "    \"BsmtQual\",\n",
    "    \"KitchenQual\",\n",
    "    \"WoodDeckSF\",\n",
    "    \"LotShape\",\n",
    "    \"Neighborhood\",\n",
    "    \"HouseStyle\",\n",
    "    \"SaleCondition\",\n",
    "]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Series([], dtype: int64)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_stat(house_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "SalePrice  OverallQual  GrLivArea  TotalBsmtSF  GarageCars  BsmtFinSF1  Fireplaces  Foundation  BsmtQual  KitchenQual  WoodDeckSF  LotShape  Neighborhood  HouseStyle  SaleCondition\n151000     7            1200       600          2           0           0           PConc       Gd        Gd           0           Reg       Somerst       2Story      Normal           1\ndtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_stat(house_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Series([], dtype: int64)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df = house_df.drop_duplicates()\n",
    "duplicates_stat(house_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Foundation        6\nBsmtQual          5\nKitchenQual       4\nLotShape          4\nNeighborhood     25\nHouseStyle        8\nSaleCondition     6\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_categories(house_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   SalePrice  OverallQual  GrLivArea  TotalBsmtSF  GarageCars  BsmtFinSF1  \\\n0     208500            7       1710          856           2         706   \n1     181500            6       1262         1262           2         978   \n2     223500            7       1786          920           2         486   \n3     140000            7       1717          756           3         216   \n4     250000            8       2198         1145           3         655   \n\n   Fireplaces Foundation BsmtQual KitchenQual  WoodDeckSF LotShape  \\\n0           0      PConc       Gd          Gd           0      Reg   \n1           1     CBlock       Gd          TA         298      Reg   \n2           1      PConc       Gd          Gd           0      IR1   \n3           1     BrkTil       TA          Gd           0      IR1   \n4           1      PConc       Gd          Gd         192      IR1   \n\n  Neighborhood HouseStyle SaleCondition  \n0      CollgCr     2Story        Normal  \n1      Veenker     1Story        Normal  \n2      CollgCr     2Story        Normal  \n3      Crawfor     2Story       Abnorml  \n4      NoRidge     2Story        Normal  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SalePrice</th>\n      <th>OverallQual</th>\n      <th>GrLivArea</th>\n      <th>TotalBsmtSF</th>\n      <th>GarageCars</th>\n      <th>BsmtFinSF1</th>\n      <th>Fireplaces</th>\n      <th>Foundation</th>\n      <th>BsmtQual</th>\n      <th>KitchenQual</th>\n      <th>WoodDeckSF</th>\n      <th>LotShape</th>\n      <th>Neighborhood</th>\n      <th>HouseStyle</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>208500</td>\n      <td>7</td>\n      <td>1710</td>\n      <td>856</td>\n      <td>2</td>\n      <td>706</td>\n      <td>0</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>Gd</td>\n      <td>0</td>\n      <td>Reg</td>\n      <td>CollgCr</td>\n      <td>2Story</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>181500</td>\n      <td>6</td>\n      <td>1262</td>\n      <td>1262</td>\n      <td>2</td>\n      <td>978</td>\n      <td>1</td>\n      <td>CBlock</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>298</td>\n      <td>Reg</td>\n      <td>Veenker</td>\n      <td>1Story</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>223500</td>\n      <td>7</td>\n      <td>1786</td>\n      <td>920</td>\n      <td>2</td>\n      <td>486</td>\n      <td>1</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>Gd</td>\n      <td>0</td>\n      <td>IR1</td>\n      <td>CollgCr</td>\n      <td>2Story</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140000</td>\n      <td>7</td>\n      <td>1717</td>\n      <td>756</td>\n      <td>3</td>\n      <td>216</td>\n      <td>1</td>\n      <td>BrkTil</td>\n      <td>TA</td>\n      <td>Gd</td>\n      <td>0</td>\n      <td>IR1</td>\n      <td>Crawfor</td>\n      <td>2Story</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>250000</td>\n      <td>8</td>\n      <td>2198</td>\n      <td>1145</td>\n      <td>3</td>\n      <td>655</td>\n      <td>1</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>Gd</td>\n      <td>192</td>\n      <td>IR1</td>\n      <td>NoRidge</td>\n      <td>2Story</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(house_df.shape)\n",
    "house_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class HouseDataset(Dataset):\n",
    "    encoder: OrdinalEncoder\n",
    "    scaler: StandardScaler\n",
    "    num_features: int\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, encoder: OrdinalEncoder = None, scaler: StandardScaler = None):\n",
    "        if encoder:\n",
    "            self.encoder = encoder\n",
    "            encode = self.encoder.transform\n",
    "        else:\n",
    "            self.encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "            encode = self.encoder.fit_transform\n",
    "\n",
    "        if scaler:\n",
    "            self.scaler = scaler\n",
    "            scale = self.scaler.transform\n",
    "        else:\n",
    "            self.scaler = StandardScaler()\n",
    "            scale = self.scaler.fit_transform\n",
    "\n",
    "        target_col = \"SalePrice\"\n",
    "        data, targets = df.drop(columns=[target_col]), df[target_col]\n",
    "\n",
    "        encode_cols, scale_cols = get_categorical_columns(data), get_numerical_columns(data)\n",
    "        data[encode_cols] = encode(data[encode_cols])\n",
    "        data[scale_cols] = scale(data[scale_cols])\n",
    "\n",
    "        self.data = torch.tensor(data.to_numpy(), dtype=torch.float)\n",
    "        self.targets = torch.tensor(targets.to_numpy(), dtype=torch.float).unsqueeze(1)\n",
    "        self.num_features = self.data.size(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1167, 292, 14)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(house_df, test_size=0.2, random_state=0)\n",
    "\n",
    "train_dataset = HouseDataset(train_df)\n",
    "test_dataset = HouseDataset(\n",
    "    test_df,\n",
    "    encoder=train_dataset.encoder,\n",
    "    scaler=train_dataset.scaler,\n",
    ")\n",
    "len(train_dataset), len(test_dataset), train_dataset.num_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        test_dataloader: DataLoader,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[t.List[float], t.List[float], t.List[float], t.List[float]]:\n",
    "    train_losses, train_r2s = [], []\n",
    "    test_losses, test_r2s = [], []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "\n",
    "        train_loss, train_r2 = train_loop(train_dataloader, model, loss_fn, optimizer, verbose=verbose, device=device)\n",
    "        print(f\"Train Error: loss: {train_loss:.6f}, R^2: {train_r2:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_r2s.append(train_r2)\n",
    "\n",
    "        test_loss, test_r2 = test_loop(test_dataloader, model, loss_fn, device=device)\n",
    "        print(f\" Test Error: loss: {test_loss:.6f}, R^2: {test_r2:.4f}\\n\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_r2s.append(test_r2)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses, train_r2s, test_losses, test_r2s\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, avg_r2 = 0, 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        r2 = metrics.r2_score(y.detach().cpu(), pred.detach().cpu())\n",
    "        avg_loss += loss\n",
    "        avg_r2 += r2\n",
    "        if verbose and batch % verbose == 0:\n",
    "            print(f\"[{batch * len(x):>4d}/{size:>4d}]: loss: {loss:.6f}, R^2: {r2:.4f}\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return (avg_loss / num_batches).item(), avg_r2 / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(model, dataloader, device)\n",
    "    return loss_fn(y_pred, y_true).item(), metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_true_y_pred(\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.flatten(torch.vstack(y_test)).cpu(), torch.flatten(torch.vstack(y_pred)).cpu()\n",
    "\n",
    "\n",
    "def plot_train_test(\n",
    "        train_losses: t.List[float],\n",
    "        train_r2s: t.List[float],\n",
    "        test_losses: t.List[float],\n",
    "        test_r2s: t.List[float],\n",
    ") -> None:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 7))\n",
    "    epochs = torch.arange(len(train_losses))\n",
    "\n",
    "    axes[0].plot(epochs, train_losses)\n",
    "    axes[0].plot(epochs, test_losses)\n",
    "    axes[0].set_ylabel(\"loss\")\n",
    "    axes[0].legend([\"train\", \"test\"])\n",
    "\n",
    "    axes[1].plot(epochs, train_r2s)\n",
    "    axes[1].plot(epochs, test_r2s)\n",
    "    axes[1].set_xlabel(\"epoch\")\n",
    "    axes[1].set_ylabel(\"$R^2$\")\n",
    "\n",
    "\n",
    "def plot_y_true_y_pred(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    x = torch.arange(len(y_pred))\n",
    "    plt.plot(x, y_true)\n",
    "    plt.plot(x, y_pred)\n",
    "    plt.legend([\"true\", \"pred\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class HouseRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features: int):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.mlp(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "HouseRegression(\n  (mlp): Sequential(\n    (0): Linear(in_features=14, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.25, inplace=False)\n    (3): Linear(in_features=512, out_features=1024, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.25, inplace=False)\n    (6): Linear(in_features=1024, out_features=512, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.25, inplace=False)\n    (9): Linear(in_features=512, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = HouseRegression(train_dataset.num_features).to(DEVICE)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0025)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "Train Error: loss: 39328296960.000000, R^2: -5.3592\n",
      " Test Error: loss: 37720154112.000000, R^2: -5.0340\n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "Train Error: loss: 36024377344.000000, R^2: -5.1423\n",
      " Test Error: loss: 30396688384.000000, R^2: -3.8624\n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "Train Error: loss: 23942193152.000000, R^2: -2.6027\n",
      " Test Error: loss: 8213587456.000000, R^2: -0.3139\n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "Train Error: loss: 7298099712.000000, R^2: -0.3074\n",
      " Test Error: loss: 7315141120.000000, R^2: -0.1702\n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "Train Error: loss: 6002701824.000000, R^2: 0.0098\n",
      " Test Error: loss: 4594213888.000000, R^2: 0.2651\n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "Train Error: loss: 4189750528.000000, R^2: 0.3391\n",
      " Test Error: loss: 3133531904.000000, R^2: 0.4987\n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "Train Error: loss: 3043065088.000000, R^2: 0.4976\n",
      " Test Error: loss: 2743749632.000000, R^2: 0.5611\n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "Train Error: loss: 2490876928.000000, R^2: 0.6085\n",
      " Test Error: loss: 2565422080.000000, R^2: 0.5896\n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "Train Error: loss: 2055199744.000000, R^2: 0.6698\n",
      " Test Error: loss: 2622811392.000000, R^2: 0.5804\n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "Train Error: loss: 1742756224.000000, R^2: 0.7001\n",
      " Test Error: loss: 2656604928.000000, R^2: 0.5750\n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "Train Error: loss: 1645729280.000000, R^2: 0.7436\n",
      " Test Error: loss: 2843681536.000000, R^2: 0.5451\n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "Train Error: loss: 1487884928.000000, R^2: 0.7314\n",
      " Test Error: loss: 2870906368.000000, R^2: 0.5408\n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "Train Error: loss: 1433364864.000000, R^2: 0.7628\n",
      " Test Error: loss: 2968639488.000000, R^2: 0.5251\n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "Train Error: loss: 1263358976.000000, R^2: 0.7929\n",
      " Test Error: loss: 2972623104.000000, R^2: 0.5245\n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "Train Error: loss: 1482021376.000000, R^2: 0.7545\n",
      " Test Error: loss: 3063409920.000000, R^2: 0.5100\n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "Train Error: loss: 1245420032.000000, R^2: 0.8015\n",
      " Test Error: loss: 2975233536.000000, R^2: 0.5241\n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "Train Error: loss: 1250303488.000000, R^2: 0.7921\n",
      " Test Error: loss: 3081507328.000000, R^2: 0.5071\n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "Train Error: loss: 1265297536.000000, R^2: 0.7838\n",
      " Test Error: loss: 3046481152.000000, R^2: 0.5127\n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "Train Error: loss: 1136477568.000000, R^2: 0.7770\n",
      " Test Error: loss: 3145358080.000000, R^2: 0.4968\n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "Train Error: loss: 1215333760.000000, R^2: 0.7966\n",
      " Test Error: loss: 3111535872.000000, R^2: 0.5023\n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "Train Error: loss: 1237662208.000000, R^2: 0.7826\n",
      " Test Error: loss: 3037706240.000000, R^2: 0.5141\n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "Train Error: loss: 1207413888.000000, R^2: 0.8045\n",
      " Test Error: loss: 3092460544.000000, R^2: 0.5053\n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "Train Error: loss: 1174507904.000000, R^2: 0.8181\n",
      " Test Error: loss: 3025808896.000000, R^2: 0.5160\n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "Train Error: loss: 1160377728.000000, R^2: 0.7926\n",
      " Test Error: loss: 3050465024.000000, R^2: 0.5120\n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "Train Error: loss: 1081085568.000000, R^2: 0.8245\n",
      " Test Error: loss: 3030712832.000000, R^2: 0.5152\n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "Train Error: loss: 1119102848.000000, R^2: 0.7914\n",
      " Test Error: loss: 3060169728.000000, R^2: 0.5105\n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "Train Error: loss: 1199899776.000000, R^2: 0.8012\n",
      " Test Error: loss: 2999776000.000000, R^2: 0.5201\n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "Train Error: loss: 1193226752.000000, R^2: 0.8060\n",
      " Test Error: loss: 3054134272.000000, R^2: 0.5114\n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "Train Error: loss: 1093092736.000000, R^2: 0.8080\n",
      " Test Error: loss: 2973146368.000000, R^2: 0.5244\n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "Train Error: loss: 1167768960.000000, R^2: 0.8088\n",
      " Test Error: loss: 3142564864.000000, R^2: 0.4973\n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "Train Error: loss: 1256769408.000000, R^2: 0.7591\n",
      " Test Error: loss: 2956322560.000000, R^2: 0.5271\n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "Train Error: loss: 1078880768.000000, R^2: 0.8269\n",
      " Test Error: loss: 3003132416.000000, R^2: 0.5196\n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "Train Error: loss: 1074250240.000000, R^2: 0.8202\n",
      " Test Error: loss: 3118325248.000000, R^2: 0.5012\n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "Train Error: loss: 1045801984.000000, R^2: 0.8200\n",
      " Test Error: loss: 3279545600.000000, R^2: 0.4754\n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "Train Error: loss: 1279446400.000000, R^2: 0.7935\n",
      " Test Error: loss: 2964740608.000000, R^2: 0.5257\n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "Train Error: loss: 1113281408.000000, R^2: 0.8212\n",
      " Test Error: loss: 3007748608.000000, R^2: 0.5189\n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "Train Error: loss: 1100529920.000000, R^2: 0.8116\n",
      " Test Error: loss: 2988454656.000000, R^2: 0.5219\n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "Train Error: loss: 1076725504.000000, R^2: 0.8230\n",
      " Test Error: loss: 3052062720.000000, R^2: 0.5118\n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "Train Error: loss: 1044117952.000000, R^2: 0.8330\n",
      " Test Error: loss: 2955721984.000000, R^2: 0.5272\n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "Train Error: loss: 1104592384.000000, R^2: 0.8052\n",
      " Test Error: loss: 3039795200.000000, R^2: 0.5137\n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "Train Error: loss: 1115021056.000000, R^2: 0.8283\n",
      " Test Error: loss: 3032794112.000000, R^2: 0.5149\n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "Train Error: loss: 1078625920.000000, R^2: 0.8034\n",
      " Test Error: loss: 3003576320.000000, R^2: 0.5195\n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "Train Error: loss: 1122638464.000000, R^2: 0.8426\n",
      " Test Error: loss: 3145353472.000000, R^2: 0.4968\n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "Train Error: loss: 1082489088.000000, R^2: 0.8140\n",
      " Test Error: loss: 3182540288.000000, R^2: 0.4909\n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "Train Error: loss: 1071225472.000000, R^2: 0.8328\n",
      " Test Error: loss: 3180259584.000000, R^2: 0.4913\n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "Train Error: loss: 1120428416.000000, R^2: 0.8267\n",
      " Test Error: loss: 3046304000.000000, R^2: 0.5127\n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "Train Error: loss: 1158911360.000000, R^2: 0.8241\n",
      " Test Error: loss: 3210860288.000000, R^2: 0.4864\n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "Train Error: loss: 1094731648.000000, R^2: 0.8122\n",
      " Test Error: loss: 3013363200.000000, R^2: 0.5180\n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "Train Error: loss: 985136640.000000, R^2: 0.8223\n",
      " Test Error: loss: 2925036032.000000, R^2: 0.5321\n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "Train Error: loss: 2297626368.000000, R^2: -0.0878\n",
      " Test Error: loss: 2824166656.000000, R^2: 0.5482\n",
      "\n",
      "Epoch 51\n",
      "--------------------------------\n",
      "Train Error: loss: 1168524800.000000, R^2: 0.8140\n",
      " Test Error: loss: 2819150848.000000, R^2: 0.5490\n",
      "\n",
      "Epoch 52\n",
      "--------------------------------\n",
      "Train Error: loss: 1261226880.000000, R^2: 0.8097\n",
      " Test Error: loss: 2484452352.000000, R^2: 0.6026\n",
      "\n",
      "Epoch 53\n",
      "--------------------------------\n",
      "Train Error: loss: 1124077184.000000, R^2: 0.8025\n",
      " Test Error: loss: 2550451456.000000, R^2: 0.5920\n",
      "\n",
      "Epoch 54\n",
      "--------------------------------\n",
      "Train Error: loss: 1106777600.000000, R^2: 0.8204\n",
      " Test Error: loss: 2865762560.000000, R^2: 0.5416\n",
      "\n",
      "Epoch 55\n",
      "--------------------------------\n",
      "Train Error: loss: 1120777728.000000, R^2: 0.8223\n",
      " Test Error: loss: 2603832832.000000, R^2: 0.5835\n",
      "\n",
      "Epoch 56\n",
      "--------------------------------\n",
      "Train Error: loss: 994944320.000000, R^2: 0.8286\n",
      " Test Error: loss: 2671266560.000000, R^2: 0.5727\n",
      "\n",
      "Epoch 57\n",
      "--------------------------------\n",
      "Train Error: loss: 1051299008.000000, R^2: 0.7989\n",
      " Test Error: loss: 2782455552.000000, R^2: 0.5549\n",
      "\n",
      "Epoch 58\n",
      "--------------------------------\n",
      "Train Error: loss: 1004801664.000000, R^2: 0.8326\n",
      " Test Error: loss: 2734852864.000000, R^2: 0.5625\n",
      "\n",
      "Epoch 59\n",
      "--------------------------------\n",
      "Train Error: loss: 1044235584.000000, R^2: 0.8292\n",
      " Test Error: loss: 2834179072.000000, R^2: 0.5466\n",
      "\n",
      "Epoch 60\n",
      "--------------------------------\n",
      "Train Error: loss: 1081527040.000000, R^2: 0.7846\n",
      " Test Error: loss: 2872574976.000000, R^2: 0.5405\n",
      "\n",
      "Epoch 61\n",
      "--------------------------------\n",
      "Train Error: loss: 1305857792.000000, R^2: 0.8165\n",
      " Test Error: loss: 2801238528.000000, R^2: 0.5519\n",
      "\n",
      "Epoch 62\n",
      "--------------------------------\n",
      "Train Error: loss: 984147392.000000, R^2: 0.8373\n",
      " Test Error: loss: 2921544960.000000, R^2: 0.5327\n",
      "\n",
      "Epoch 63\n",
      "--------------------------------\n",
      "Train Error: loss: 1040790976.000000, R^2: 0.8213\n",
      " Test Error: loss: 2922292480.000000, R^2: 0.5325\n",
      "\n",
      "Epoch 64\n",
      "--------------------------------\n",
      "Train Error: loss: 1016447424.000000, R^2: 0.8369\n",
      " Test Error: loss: 2883942400.000000, R^2: 0.5387\n",
      "\n",
      "Epoch 65\n",
      "--------------------------------\n",
      "Train Error: loss: 928100864.000000, R^2: 0.8488\n",
      " Test Error: loss: 2784370688.000000, R^2: 0.5546\n",
      "\n",
      "Epoch 66\n",
      "--------------------------------\n",
      "Train Error: loss: 1083528960.000000, R^2: 0.8405\n",
      " Test Error: loss: 2838941184.000000, R^2: 0.5459\n",
      "\n",
      "Epoch 67\n",
      "--------------------------------\n",
      "Train Error: loss: 1002261440.000000, R^2: 0.8387\n",
      " Test Error: loss: 2863458816.000000, R^2: 0.5419\n",
      "\n",
      "Epoch 68\n",
      "--------------------------------\n",
      "Train Error: loss: 951102400.000000, R^2: 0.8410\n",
      " Test Error: loss: 2935340544.000000, R^2: 0.5304\n",
      "\n",
      "Epoch 69\n",
      "--------------------------------\n",
      "Train Error: loss: 1034333888.000000, R^2: 0.8374\n",
      " Test Error: loss: 2852197632.000000, R^2: 0.5437\n",
      "\n",
      "Epoch 70\n",
      "--------------------------------\n",
      "Train Error: loss: 897793344.000000, R^2: 0.8445\n",
      " Test Error: loss: 2843621888.000000, R^2: 0.5451\n",
      "\n",
      "Epoch 71\n",
      "--------------------------------\n",
      "Train Error: loss: 950982336.000000, R^2: 0.8430\n",
      " Test Error: loss: 2877067776.000000, R^2: 0.5398\n",
      "\n",
      "Epoch 72\n",
      "--------------------------------\n",
      "Train Error: loss: 913482688.000000, R^2: 0.8499\n",
      " Test Error: loss: 2793769216.000000, R^2: 0.5531\n",
      "\n",
      "Epoch 73\n",
      "--------------------------------\n",
      "Train Error: loss: 1022377920.000000, R^2: 0.8219\n",
      " Test Error: loss: 2733721344.000000, R^2: 0.5627\n",
      "\n",
      "Epoch 74\n",
      "--------------------------------\n",
      "Train Error: loss: 958687936.000000, R^2: 0.8357\n",
      " Test Error: loss: 2732704512.000000, R^2: 0.5629\n",
      "\n",
      "Epoch 75\n",
      "--------------------------------\n",
      "Train Error: loss: 893130944.000000, R^2: 0.8404\n",
      " Test Error: loss: 2821960960.000000, R^2: 0.5486\n",
      "\n",
      "Epoch 76\n",
      "--------------------------------\n",
      "Train Error: loss: 1027967168.000000, R^2: 0.8154\n",
      " Test Error: loss: 2777700096.000000, R^2: 0.5557\n",
      "\n",
      "Epoch 77\n",
      "--------------------------------\n",
      "Train Error: loss: 988272128.000000, R^2: 0.8207\n",
      " Test Error: loss: 2890269440.000000, R^2: 0.5377\n",
      "\n",
      "Epoch 78\n",
      "--------------------------------\n",
      "Train Error: loss: 899472064.000000, R^2: 0.8460\n",
      " Test Error: loss: 2853000704.000000, R^2: 0.5436\n",
      "\n",
      "Epoch 79\n",
      "--------------------------------\n",
      "Train Error: loss: 918035584.000000, R^2: 0.8434\n",
      " Test Error: loss: 2888502784.000000, R^2: 0.5379\n",
      "\n",
      "Epoch 80\n",
      "--------------------------------\n",
      "Train Error: loss: 953074176.000000, R^2: 0.8387\n",
      " Test Error: loss: 2767842816.000000, R^2: 0.5572\n",
      "\n",
      "Epoch 81\n",
      "--------------------------------\n",
      "Train Error: loss: 898457408.000000, R^2: 0.8451\n",
      " Test Error: loss: 2742510848.000000, R^2: 0.5613\n",
      "\n",
      "Epoch 82\n",
      "--------------------------------\n",
      "Train Error: loss: 955659200.000000, R^2: 0.8138\n",
      " Test Error: loss: 2706568448.000000, R^2: 0.5670\n",
      "\n",
      "Epoch 83\n",
      "--------------------------------\n",
      "Train Error: loss: 930906048.000000, R^2: 0.8506\n",
      " Test Error: loss: 2788401152.000000, R^2: 0.5539\n",
      "\n",
      "Epoch 84\n",
      "--------------------------------\n",
      "Train Error: loss: 887217472.000000, R^2: 0.8535\n",
      " Test Error: loss: 2712889088.000000, R^2: 0.5660\n",
      "\n",
      "Epoch 85\n",
      "--------------------------------\n",
      "Train Error: loss: 992099008.000000, R^2: 0.8322\n",
      " Test Error: loss: 2731254016.000000, R^2: 0.5631\n",
      "\n",
      "Epoch 86\n",
      "--------------------------------\n",
      "Train Error: loss: 973725376.000000, R^2: 0.8501\n",
      " Test Error: loss: 2665021952.000000, R^2: 0.5737\n",
      "\n",
      "Epoch 87\n",
      "--------------------------------\n",
      "Train Error: loss: 898496192.000000, R^2: 0.8382\n",
      " Test Error: loss: 2697986560.000000, R^2: 0.5684\n",
      "\n",
      "Epoch 88\n",
      "--------------------------------\n",
      "Train Error: loss: 877339648.000000, R^2: 0.8303\n",
      " Test Error: loss: 2757700096.000000, R^2: 0.5589\n",
      "\n",
      "Epoch 89\n",
      "--------------------------------\n",
      "Train Error: loss: 870154688.000000, R^2: 0.8482\n",
      " Test Error: loss: 2747665920.000000, R^2: 0.5605\n",
      "\n",
      "Epoch 90\n",
      "--------------------------------\n",
      "Train Error: loss: 962950272.000000, R^2: 0.8372\n",
      " Test Error: loss: 2781308928.000000, R^2: 0.5551\n",
      "\n",
      "Epoch 91\n",
      "--------------------------------\n",
      "Train Error: loss: 943599808.000000, R^2: 0.8508\n",
      " Test Error: loss: 2778720256.000000, R^2: 0.5555\n",
      "\n",
      "Epoch 92\n",
      "--------------------------------\n",
      "Train Error: loss: 957736064.000000, R^2: 0.7746\n",
      " Test Error: loss: 2714593792.000000, R^2: 0.5658\n",
      "\n",
      "Epoch 93\n",
      "--------------------------------\n",
      "Train Error: loss: 1085777152.000000, R^2: 0.8192\n",
      " Test Error: loss: 2736702464.000000, R^2: 0.5622\n",
      "\n",
      "Epoch 94\n",
      "--------------------------------\n",
      "Train Error: loss: 845776064.000000, R^2: 0.8599\n",
      " Test Error: loss: 3073511680.000000, R^2: 0.5083\n",
      "\n",
      "Epoch 95\n",
      "--------------------------------\n",
      "Train Error: loss: 948613568.000000, R^2: 0.8376\n",
      " Test Error: loss: 2806855680.000000, R^2: 0.5510\n",
      "\n",
      "Epoch 96\n",
      "--------------------------------\n",
      "Train Error: loss: 1112244480.000000, R^2: 0.8101\n",
      " Test Error: loss: 2717867264.000000, R^2: 0.5652\n",
      "\n",
      "Epoch 97\n",
      "--------------------------------\n",
      "Train Error: loss: 911024768.000000, R^2: 0.8490\n",
      " Test Error: loss: 2683769344.000000, R^2: 0.5707\n",
      "\n",
      "Epoch 98\n",
      "--------------------------------\n",
      "Train Error: loss: 878467584.000000, R^2: 0.8526\n",
      " Test Error: loss: 2771414528.000000, R^2: 0.5567\n",
      "\n",
      "Epoch 99\n",
      "--------------------------------\n",
      "Train Error: loss: 963966912.000000, R^2: 0.8428\n",
      " Test Error: loss: 2710329600.000000, R^2: 0.5664\n",
      "\n",
      "Epoch 100\n",
      "--------------------------------\n",
      "Train Error: loss: 936496640.000000, R^2: 0.8511\n",
      " Test Error: loss: 2701307648.000000, R^2: 0.5679\n",
      "\n",
      "Epoch 101\n",
      "--------------------------------\n",
      "Train Error: loss: 943835840.000000, R^2: 0.8175\n",
      " Test Error: loss: 2917691392.000000, R^2: 0.5333\n",
      "\n",
      "Epoch 102\n",
      "--------------------------------\n",
      "Train Error: loss: 1041629376.000000, R^2: 0.8119\n",
      " Test Error: loss: 2703409920.000000, R^2: 0.5675\n",
      "\n",
      "Epoch 103\n",
      "--------------------------------\n",
      "Train Error: loss: 898556416.000000, R^2: 0.8503\n",
      " Test Error: loss: 2626408704.000000, R^2: 0.5799\n",
      "\n",
      "Epoch 104\n",
      "--------------------------------\n",
      "Train Error: loss: 1066627392.000000, R^2: 0.7846\n",
      " Test Error: loss: 2904806144.000000, R^2: 0.5353\n",
      "\n",
      "Epoch 105\n",
      "--------------------------------\n",
      "Train Error: loss: 863457792.000000, R^2: 0.8539\n",
      " Test Error: loss: 2756802048.000000, R^2: 0.5590\n",
      "\n",
      "Epoch 106\n",
      "--------------------------------\n",
      "Train Error: loss: 914716096.000000, R^2: 0.8531\n",
      " Test Error: loss: 2640598528.000000, R^2: 0.5776\n",
      "\n",
      "Epoch 107\n",
      "--------------------------------\n",
      "Train Error: loss: 809738688.000000, R^2: 0.8721\n",
      " Test Error: loss: 2629928704.000000, R^2: 0.5793\n",
      "\n",
      "Epoch 108\n",
      "--------------------------------\n",
      "Train Error: loss: 891421504.000000, R^2: 0.8561\n",
      " Test Error: loss: 2717683968.000000, R^2: 0.5653\n",
      "\n",
      "Epoch 109\n",
      "--------------------------------\n",
      "Train Error: loss: 962876352.000000, R^2: 0.8325\n",
      " Test Error: loss: 2828810752.000000, R^2: 0.5475\n",
      "\n",
      "Epoch 110\n",
      "--------------------------------\n",
      "Train Error: loss: 959286592.000000, R^2: 0.8310\n",
      " Test Error: loss: 2686217216.000000, R^2: 0.5703\n",
      "\n",
      "Epoch 111\n",
      "--------------------------------\n",
      "Train Error: loss: 981383488.000000, R^2: 0.8390\n",
      " Test Error: loss: 2660577792.000000, R^2: 0.5744\n",
      "\n",
      "Epoch 112\n",
      "--------------------------------\n",
      "Train Error: loss: 835639872.000000, R^2: 0.8674\n",
      " Test Error: loss: 2723886336.000000, R^2: 0.5643\n",
      "\n",
      "Epoch 113\n",
      "--------------------------------\n",
      "Train Error: loss: 925148608.000000, R^2: 0.8501\n",
      " Test Error: loss: 2625472000.000000, R^2: 0.5800\n",
      "\n",
      "Epoch 114\n",
      "--------------------------------\n",
      "Train Error: loss: 851809984.000000, R^2: 0.8432\n",
      " Test Error: loss: 2611307520.000000, R^2: 0.5823\n",
      "\n",
      "Epoch 115\n",
      "--------------------------------\n",
      "Train Error: loss: 839373248.000000, R^2: 0.8615\n",
      " Test Error: loss: 2695407616.000000, R^2: 0.5688\n",
      "\n",
      "Epoch 116\n",
      "--------------------------------\n",
      "Train Error: loss: 827410816.000000, R^2: 0.8665\n",
      " Test Error: loss: 2730180352.000000, R^2: 0.5633\n",
      "\n",
      "Epoch 117\n",
      "--------------------------------\n",
      "Train Error: loss: 920583360.000000, R^2: 0.8531\n",
      " Test Error: loss: 2689006592.000000, R^2: 0.5698\n",
      "\n",
      "Epoch 118\n",
      "--------------------------------\n",
      "Train Error: loss: 964448384.000000, R^2: 0.8437\n",
      " Test Error: loss: 2755887104.000000, R^2: 0.5592\n",
      "\n",
      "Epoch 119\n",
      "--------------------------------\n",
      "Train Error: loss: 893876416.000000, R^2: 0.8354\n",
      " Test Error: loss: 2728659968.000000, R^2: 0.5635\n",
      "\n",
      "Epoch 120\n",
      "--------------------------------\n",
      "Train Error: loss: 940166656.000000, R^2: 0.8264\n",
      " Test Error: loss: 2670674688.000000, R^2: 0.5728\n",
      "\n",
      "Epoch 121\n",
      "--------------------------------\n",
      "Train Error: loss: 872559744.000000, R^2: 0.8597\n",
      " Test Error: loss: 2618502400.000000, R^2: 0.5811\n",
      "\n",
      "Epoch 122\n",
      "--------------------------------\n",
      "Train Error: loss: 815147968.000000, R^2: 0.8691\n",
      " Test Error: loss: 2669906176.000000, R^2: 0.5729\n",
      "\n",
      "Epoch 123\n",
      "--------------------------------\n",
      "Train Error: loss: 881789952.000000, R^2: 0.8570\n",
      " Test Error: loss: 2674377216.000000, R^2: 0.5722\n",
      "\n",
      "Epoch 124\n",
      "--------------------------------\n",
      "Train Error: loss: 871632704.000000, R^2: 0.8521\n",
      " Test Error: loss: 2707970304.000000, R^2: 0.5668\n",
      "\n",
      "Epoch 125\n",
      "--------------------------------\n",
      "Train Error: loss: 1134247936.000000, R^2: 0.8572\n",
      " Test Error: loss: 2885013760.000000, R^2: 0.5385\n",
      "\n",
      "Epoch 126\n",
      "--------------------------------\n",
      "Train Error: loss: 996137280.000000, R^2: 0.8164\n",
      " Test Error: loss: 3037472256.000000, R^2: 0.5141\n",
      "\n",
      "Epoch 127\n",
      "--------------------------------\n",
      "Train Error: loss: 1076573696.000000, R^2: 0.8200\n",
      " Test Error: loss: 2717334528.000000, R^2: 0.5653\n",
      "\n",
      "Epoch 128\n",
      "--------------------------------\n",
      "Train Error: loss: 898903744.000000, R^2: 0.8524\n",
      " Test Error: loss: 2684448768.000000, R^2: 0.5706\n",
      "\n",
      "Epoch 129\n",
      "--------------------------------\n",
      "Train Error: loss: 965957312.000000, R^2: 0.8136\n",
      " Test Error: loss: 2805417984.000000, R^2: 0.5512\n",
      "\n",
      "Epoch 130\n",
      "--------------------------------\n",
      "Train Error: loss: 887720256.000000, R^2: 0.8416\n",
      " Test Error: loss: 2769340416.000000, R^2: 0.5570\n",
      "\n",
      "Epoch 131\n",
      "--------------------------------\n",
      "Train Error: loss: 875470272.000000, R^2: 0.8529\n",
      " Test Error: loss: 2719697664.000000, R^2: 0.5649\n",
      "\n",
      "Epoch 132\n",
      "--------------------------------\n",
      "Train Error: loss: 832966080.000000, R^2: 0.8602\n",
      " Test Error: loss: 2660301312.000000, R^2: 0.5744\n",
      "\n",
      "Epoch 133\n",
      "--------------------------------\n",
      "Train Error: loss: 1010957248.000000, R^2: 0.8453\n",
      " Test Error: loss: 2763748608.000000, R^2: 0.5579\n",
      "\n",
      "Epoch 134\n",
      "--------------------------------\n",
      "Train Error: loss: 923126208.000000, R^2: 0.8431\n",
      " Test Error: loss: 2769068800.000000, R^2: 0.5570\n",
      "\n",
      "Epoch 135\n",
      "--------------------------------\n",
      "Train Error: loss: 990956992.000000, R^2: 0.8336\n",
      " Test Error: loss: 2643780608.000000, R^2: 0.5771\n",
      "\n",
      "Epoch 136\n",
      "--------------------------------\n",
      "Train Error: loss: 871819200.000000, R^2: 0.8610\n",
      " Test Error: loss: 2737675776.000000, R^2: 0.5621\n",
      "\n",
      "Epoch 137\n",
      "--------------------------------\n",
      "Train Error: loss: 994596032.000000, R^2: 0.8438\n",
      " Test Error: loss: 2790771456.000000, R^2: 0.5536\n",
      "\n",
      "Epoch 138\n",
      "--------------------------------\n",
      "Train Error: loss: 878751744.000000, R^2: 0.8542\n",
      " Test Error: loss: 2764947456.000000, R^2: 0.5577\n",
      "\n",
      "Epoch 139\n",
      "--------------------------------\n",
      "Train Error: loss: 953105088.000000, R^2: 0.8218\n",
      " Test Error: loss: 2696099072.000000, R^2: 0.5687\n",
      "\n",
      "Epoch 140\n",
      "--------------------------------\n",
      "Train Error: loss: 1573649920.000000, R^2: 0.7731\n",
      " Test Error: loss: 2559509504.000000, R^2: 0.5906\n",
      "\n",
      "Epoch 141\n",
      "--------------------------------\n",
      "Train Error: loss: 954098176.000000, R^2: 0.8414\n",
      " Test Error: loss: 2320014848.000000, R^2: 0.6289\n",
      "\n",
      "Epoch 142\n",
      "--------------------------------\n",
      "Train Error: loss: 1052505920.000000, R^2: 0.8371\n",
      " Test Error: loss: 2362589440.000000, R^2: 0.6221\n",
      "\n",
      "Epoch 143\n",
      "--------------------------------\n",
      "Train Error: loss: 933418112.000000, R^2: 0.8513\n",
      " Test Error: loss: 2479182336.000000, R^2: 0.6034\n",
      "\n",
      "Epoch 144\n",
      "--------------------------------\n",
      "Train Error: loss: 955700160.000000, R^2: 0.8400\n",
      " Test Error: loss: 2436264704.000000, R^2: 0.6103\n",
      "\n",
      "Epoch 145\n",
      "--------------------------------\n",
      "Train Error: loss: 877473088.000000, R^2: 0.8675\n",
      " Test Error: loss: 2512989952.000000, R^2: 0.5980\n",
      "\n",
      "Epoch 146\n",
      "--------------------------------\n",
      "Train Error: loss: 911687360.000000, R^2: 0.8435\n",
      " Test Error: loss: 2525191680.000000, R^2: 0.5961\n",
      "\n",
      "Epoch 147\n",
      "--------------------------------\n",
      "Train Error: loss: 884908992.000000, R^2: 0.8492\n",
      " Test Error: loss: 2839907840.000000, R^2: 0.5457\n",
      "\n",
      "Epoch 148\n",
      "--------------------------------\n",
      "Train Error: loss: 927912448.000000, R^2: 0.8116\n",
      " Test Error: loss: 2517262848.000000, R^2: 0.5973\n",
      "\n",
      "Epoch 149\n",
      "--------------------------------\n",
      "Train Error: loss: 862704320.000000, R^2: 0.8489\n",
      " Test Error: loss: 2437906432.000000, R^2: 0.6100\n",
      "\n",
      "Epoch 150\n",
      "--------------------------------\n",
      "Train Error: loss: 822409920.000000, R^2: 0.8676\n",
      " Test Error: loss: 2536619776.000000, R^2: 0.5942\n",
      "\n",
      "Epoch 151\n",
      "--------------------------------\n",
      "Train Error: loss: 874594944.000000, R^2: 0.8523\n",
      " Test Error: loss: 2524378368.000000, R^2: 0.5962\n",
      "\n",
      "Epoch 152\n",
      "--------------------------------\n",
      "Train Error: loss: 886981120.000000, R^2: 0.8516\n",
      " Test Error: loss: 2456510976.000000, R^2: 0.6070\n",
      "\n",
      "Epoch 153\n",
      "--------------------------------\n",
      "Train Error: loss: 812533760.000000, R^2: 0.8649\n",
      " Test Error: loss: 2414594560.000000, R^2: 0.6137\n",
      "\n",
      "Epoch 154\n",
      "--------------------------------\n",
      "Train Error: loss: 886815552.000000, R^2: 0.8588\n",
      " Test Error: loss: 2464061184.000000, R^2: 0.6058\n",
      "\n",
      "Epoch 155\n",
      "--------------------------------\n",
      "Train Error: loss: 892724160.000000, R^2: 0.8576\n",
      " Test Error: loss: 2523413760.000000, R^2: 0.5963\n",
      "\n",
      "Epoch 156\n",
      "--------------------------------\n",
      "Train Error: loss: 918752576.000000, R^2: 0.8440\n",
      " Test Error: loss: 2549989376.000000, R^2: 0.5921\n",
      "\n",
      "Epoch 157\n",
      "--------------------------------\n",
      "Train Error: loss: 950732416.000000, R^2: 0.8285\n",
      " Test Error: loss: 2447865600.000000, R^2: 0.6084\n",
      "\n",
      "Epoch 158\n",
      "--------------------------------\n",
      "Train Error: loss: 806302208.000000, R^2: 0.8569\n",
      " Test Error: loss: 2392751104.000000, R^2: 0.6172\n",
      "\n",
      "Epoch 159\n",
      "--------------------------------\n",
      "Train Error: loss: 812360896.000000, R^2: 0.8617\n",
      " Test Error: loss: 2509518080.000000, R^2: 0.5986\n",
      "\n",
      "Epoch 160\n",
      "--------------------------------\n",
      "Train Error: loss: 975198144.000000, R^2: 0.8457\n",
      " Test Error: loss: 2539452160.000000, R^2: 0.5938\n",
      "\n",
      "Epoch 161\n",
      "--------------------------------\n",
      "Train Error: loss: 859290816.000000, R^2: 0.8472\n",
      " Test Error: loss: 2560717056.000000, R^2: 0.5904\n",
      "\n",
      "Epoch 162\n",
      "--------------------------------\n",
      "Train Error: loss: 872773760.000000, R^2: 0.8509\n",
      " Test Error: loss: 2642770944.000000, R^2: 0.5772\n",
      "\n",
      "Epoch 163\n",
      "--------------------------------\n",
      "Train Error: loss: 941483712.000000, R^2: 0.8545\n",
      " Test Error: loss: 2683996672.000000, R^2: 0.5707\n",
      "\n",
      "Epoch 164\n",
      "--------------------------------\n",
      "Train Error: loss: 846786816.000000, R^2: 0.8570\n",
      " Test Error: loss: 2758924544.000000, R^2: 0.5587\n",
      "\n",
      "Epoch 165\n",
      "--------------------------------\n",
      "Train Error: loss: 890266112.000000, R^2: 0.8329\n",
      " Test Error: loss: 2601160704.000000, R^2: 0.5839\n",
      "\n",
      "Epoch 166\n",
      "--------------------------------\n",
      "Train Error: loss: 844129152.000000, R^2: 0.8544\n",
      " Test Error: loss: 2634286592.000000, R^2: 0.5786\n",
      "\n",
      "Epoch 167\n",
      "--------------------------------\n",
      "Train Error: loss: 800312512.000000, R^2: 0.8631\n",
      " Test Error: loss: 2767191040.000000, R^2: 0.5573\n",
      "\n",
      "Epoch 168\n",
      "--------------------------------\n",
      "Train Error: loss: 929243776.000000, R^2: 0.8381\n",
      " Test Error: loss: 2633734656.000000, R^2: 0.5787\n",
      "\n",
      "Epoch 169\n",
      "--------------------------------\n",
      "Train Error: loss: 851032640.000000, R^2: 0.8620\n",
      " Test Error: loss: 2563826176.000000, R^2: 0.5899\n",
      "\n",
      "Epoch 170\n",
      "--------------------------------\n",
      "Train Error: loss: 920414848.000000, R^2: 0.8595\n",
      " Test Error: loss: 2683645440.000000, R^2: 0.5707\n",
      "\n",
      "Epoch 171\n",
      "--------------------------------\n",
      "Train Error: loss: 856545600.000000, R^2: 0.8530\n",
      " Test Error: loss: 2710655744.000000, R^2: 0.5664\n",
      "\n",
      "Epoch 172\n",
      "--------------------------------\n",
      "Train Error: loss: 1474573440.000000, R^2: 0.6543\n",
      " Test Error: loss: 2550270208.000000, R^2: 0.5920\n",
      "\n",
      "Epoch 173\n",
      "--------------------------------\n",
      "Train Error: loss: 1010528704.000000, R^2: 0.8394\n",
      " Test Error: loss: 2327426816.000000, R^2: 0.6277\n",
      "\n",
      "Epoch 174\n",
      "--------------------------------\n",
      "Train Error: loss: 826984064.000000, R^2: 0.8549\n",
      " Test Error: loss: 2224712448.000000, R^2: 0.6441\n",
      "\n",
      "Epoch 175\n",
      "--------------------------------\n",
      "Train Error: loss: 917516608.000000, R^2: 0.8462\n",
      " Test Error: loss: 2270155776.000000, R^2: 0.6369\n",
      "\n",
      "Epoch 176\n",
      "--------------------------------\n",
      "Train Error: loss: 1071767360.000000, R^2: 0.8591\n",
      " Test Error: loss: 2458611712.000000, R^2: 0.6067\n",
      "\n",
      "Epoch 177\n",
      "--------------------------------\n",
      "Train Error: loss: 888871424.000000, R^2: 0.8513\n",
      " Test Error: loss: 2599463680.000000, R^2: 0.5842\n",
      "\n",
      "Epoch 178\n",
      "--------------------------------\n",
      "Train Error: loss: 1023163520.000000, R^2: 0.7756\n",
      " Test Error: loss: 2595268608.000000, R^2: 0.5848\n",
      "\n",
      "Epoch 179\n",
      "--------------------------------\n",
      "Train Error: loss: 989280576.000000, R^2: 0.8001\n",
      " Test Error: loss: 2619518208.000000, R^2: 0.5810\n",
      "\n",
      "Epoch 180\n",
      "--------------------------------\n",
      "Train Error: loss: 829347072.000000, R^2: 0.8546\n",
      " Test Error: loss: 2706377472.000000, R^2: 0.5671\n",
      "\n",
      "Epoch 181\n",
      "--------------------------------\n",
      "Train Error: loss: 1062297024.000000, R^2: 0.8564\n",
      " Test Error: loss: 2509839360.000000, R^2: 0.5985\n",
      "\n",
      "Epoch 182\n",
      "--------------------------------\n",
      "Train Error: loss: 791128448.000000, R^2: 0.8623\n",
      " Test Error: loss: 2427246848.000000, R^2: 0.6117\n",
      "\n",
      "Epoch 183\n",
      "--------------------------------\n",
      "Train Error: loss: 841636672.000000, R^2: 0.8592\n",
      " Test Error: loss: 2428610304.000000, R^2: 0.6115\n",
      "\n",
      "Epoch 184\n",
      "--------------------------------\n",
      "Train Error: loss: 795433024.000000, R^2: 0.8524\n",
      " Test Error: loss: 2533528064.000000, R^2: 0.5947\n",
      "\n",
      "Epoch 185\n",
      "--------------------------------\n",
      "Train Error: loss: 865174336.000000, R^2: 0.8529\n",
      " Test Error: loss: 2564024064.000000, R^2: 0.5898\n",
      "\n",
      "Epoch 186\n",
      "--------------------------------\n",
      "Train Error: loss: 818576896.000000, R^2: 0.8309\n",
      " Test Error: loss: 2461209600.000000, R^2: 0.6063\n",
      "\n",
      "Epoch 187\n",
      "--------------------------------\n",
      "Train Error: loss: 873688768.000000, R^2: 0.8720\n",
      " Test Error: loss: 2470709248.000000, R^2: 0.6048\n",
      "\n",
      "Epoch 188\n",
      "--------------------------------\n",
      "Train Error: loss: 849415360.000000, R^2: 0.8434\n",
      " Test Error: loss: 2475426816.000000, R^2: 0.6040\n",
      "\n",
      "Epoch 189\n",
      "--------------------------------\n",
      "Train Error: loss: 781078464.000000, R^2: 0.8581\n",
      " Test Error: loss: 2528386816.000000, R^2: 0.5955\n",
      "\n",
      "Epoch 190\n",
      "--------------------------------\n",
      "Train Error: loss: 824089344.000000, R^2: 0.8368\n",
      " Test Error: loss: 2511325952.000000, R^2: 0.5983\n",
      "\n",
      "Epoch 191\n",
      "--------------------------------\n",
      "Train Error: loss: 968655872.000000, R^2: 0.8365\n",
      " Test Error: loss: 2351045376.000000, R^2: 0.6239\n",
      "\n",
      "Epoch 192\n",
      "--------------------------------\n",
      "Train Error: loss: 889161728.000000, R^2: 0.8623\n",
      " Test Error: loss: 2466231552.000000, R^2: 0.6055\n",
      "\n",
      "Epoch 193\n",
      "--------------------------------\n",
      "Train Error: loss: 882681280.000000, R^2: 0.8521\n",
      " Test Error: loss: 2381374208.000000, R^2: 0.6191\n",
      "\n",
      "Epoch 194\n",
      "--------------------------------\n",
      "Train Error: loss: 929713280.000000, R^2: 0.8421\n",
      " Test Error: loss: 2375520256.000000, R^2: 0.6200\n",
      "\n",
      "Epoch 195\n",
      "--------------------------------\n",
      "Train Error: loss: 845674624.000000, R^2: 0.8647\n",
      " Test Error: loss: 2318059776.000000, R^2: 0.6292\n",
      "\n",
      "Epoch 196\n",
      "--------------------------------\n",
      "Train Error: loss: 808059648.000000, R^2: 0.8648\n",
      " Test Error: loss: 2431236608.000000, R^2: 0.6111\n",
      "\n",
      "Epoch 197\n",
      "--------------------------------\n",
      "Train Error: loss: 831825600.000000, R^2: 0.8614\n",
      " Test Error: loss: 2443562752.000000, R^2: 0.6091\n",
      "\n",
      "Epoch 198\n",
      "--------------------------------\n",
      "Train Error: loss: 797015744.000000, R^2: 0.8695\n",
      " Test Error: loss: 2600744960.000000, R^2: 0.5840\n",
      "\n",
      "Epoch 199\n",
      "--------------------------------\n",
      "Train Error: loss: 872742720.000000, R^2: 0.8614\n",
      " Test Error: loss: 2430871296.000000, R^2: 0.6111\n",
      "\n",
      "Epoch 200\n",
      "--------------------------------\n",
      "Train Error: loss: 967533888.000000, R^2: 0.8364\n",
      " Test Error: loss: 2380509440.000000, R^2: 0.6192\n",
      "\n",
      "Epoch 201\n",
      "--------------------------------\n",
      "Train Error: loss: 763110144.000000, R^2: 0.8666\n",
      " Test Error: loss: 2423522560.000000, R^2: 0.6123\n",
      "\n",
      "Epoch 202\n",
      "--------------------------------\n",
      "Train Error: loss: 863683072.000000, R^2: 0.8692\n",
      " Test Error: loss: 2411396352.000000, R^2: 0.6143\n",
      "\n",
      "Epoch 203\n",
      "--------------------------------\n",
      "Train Error: loss: 835228480.000000, R^2: 0.8668\n",
      " Test Error: loss: 2431253504.000000, R^2: 0.6111\n",
      "\n",
      "Epoch 204\n",
      "--------------------------------\n",
      "Train Error: loss: 761558464.000000, R^2: 0.8665\n",
      " Test Error: loss: 2455275776.000000, R^2: 0.6072\n",
      "\n",
      "Epoch 205\n",
      "--------------------------------\n",
      "Train Error: loss: 787759872.000000, R^2: 0.8759\n",
      " Test Error: loss: 2410898432.000000, R^2: 0.6143\n",
      "\n",
      "Epoch 206\n",
      "--------------------------------\n",
      "Train Error: loss: 856569920.000000, R^2: 0.8597\n",
      " Test Error: loss: 2398410752.000000, R^2: 0.6163\n",
      "\n",
      "Epoch 207\n",
      "--------------------------------\n",
      "Train Error: loss: 760879232.000000, R^2: 0.8762\n",
      " Test Error: loss: 2402291200.000000, R^2: 0.6157\n",
      "\n",
      "Epoch 208\n",
      "--------------------------------\n",
      "Train Error: loss: 807347200.000000, R^2: 0.8635\n",
      " Test Error: loss: 2507891712.000000, R^2: 0.5988\n",
      "\n",
      "Epoch 209\n",
      "--------------------------------\n",
      "Train Error: loss: 790800704.000000, R^2: 0.8550\n",
      " Test Error: loss: 2364709120.000000, R^2: 0.6217\n",
      "\n",
      "Epoch 210\n",
      "--------------------------------\n",
      "Train Error: loss: 836727936.000000, R^2: 0.8704\n",
      " Test Error: loss: 2359377152.000000, R^2: 0.6226\n",
      "\n",
      "Epoch 211\n",
      "--------------------------------\n",
      "Train Error: loss: 927937728.000000, R^2: 0.8374\n",
      " Test Error: loss: 2573784576.000000, R^2: 0.5883\n",
      "\n",
      "Epoch 212\n",
      "--------------------------------\n",
      "Train Error: loss: 869614400.000000, R^2: 0.8581\n",
      " Test Error: loss: 2393091072.000000, R^2: 0.6172\n",
      "\n",
      "Epoch 213\n",
      "--------------------------------\n",
      "Train Error: loss: 870043136.000000, R^2: 0.8648\n",
      " Test Error: loss: 2421667072.000000, R^2: 0.6126\n",
      "\n",
      "Epoch 214\n",
      "--------------------------------\n",
      "Train Error: loss: 931134976.000000, R^2: 0.8483\n",
      " Test Error: loss: 2361342976.000000, R^2: 0.6223\n",
      "\n",
      "Epoch 215\n",
      "--------------------------------\n",
      "Train Error: loss: 838214656.000000, R^2: 0.8548\n",
      " Test Error: loss: 2400687872.000000, R^2: 0.6160\n",
      "\n",
      "Epoch 216\n",
      "--------------------------------\n",
      "Train Error: loss: 855543680.000000, R^2: 0.8522\n",
      " Test Error: loss: 2402455552.000000, R^2: 0.6157\n",
      "\n",
      "Epoch 217\n",
      "--------------------------------\n",
      "Train Error: loss: 784493376.000000, R^2: 0.8705\n",
      " Test Error: loss: 2490346752.000000, R^2: 0.6016\n",
      "\n",
      "Epoch 218\n",
      "--------------------------------\n",
      "Train Error: loss: 758259456.000000, R^2: 0.8573\n",
      " Test Error: loss: 2437492480.000000, R^2: 0.6101\n",
      "\n",
      "Epoch 219\n",
      "--------------------------------\n",
      "Train Error: loss: 780794624.000000, R^2: 0.8739\n",
      " Test Error: loss: 2413656320.000000, R^2: 0.6139\n",
      "\n",
      "Epoch 220\n",
      "--------------------------------\n",
      "Train Error: loss: 920431232.000000, R^2: 0.8502\n",
      " Test Error: loss: 2536901120.000000, R^2: 0.5942\n",
      "\n",
      "Epoch 221\n",
      "--------------------------------\n",
      "Train Error: loss: 841775552.000000, R^2: 0.8402\n",
      " Test Error: loss: 2519650304.000000, R^2: 0.5969\n",
      "\n",
      "Epoch 222\n",
      "--------------------------------\n",
      "Train Error: loss: 787823936.000000, R^2: 0.8683\n",
      " Test Error: loss: 2415313664.000000, R^2: 0.6136\n",
      "\n",
      "Epoch 223\n",
      "--------------------------------\n",
      "Train Error: loss: 879074112.000000, R^2: 0.8534\n",
      " Test Error: loss: 2444305408.000000, R^2: 0.6090\n",
      "\n",
      "Epoch 224\n",
      "--------------------------------\n",
      "Train Error: loss: 769766528.000000, R^2: 0.8615\n",
      " Test Error: loss: 2437323264.000000, R^2: 0.6101\n",
      "\n",
      "Epoch 225\n",
      "--------------------------------\n",
      "Train Error: loss: 829576704.000000, R^2: 0.8688\n",
      " Test Error: loss: 2390031872.000000, R^2: 0.6177\n",
      "\n",
      "Epoch 226\n",
      "--------------------------------\n",
      "Train Error: loss: 814684800.000000, R^2: 0.8760\n",
      " Test Error: loss: 2462264320.000000, R^2: 0.6061\n",
      "\n",
      "Epoch 227\n",
      "--------------------------------\n",
      "Train Error: loss: 878858176.000000, R^2: 0.8362\n",
      " Test Error: loss: 2342035456.000000, R^2: 0.6254\n",
      "\n",
      "Epoch 228\n",
      "--------------------------------\n",
      "Train Error: loss: 860432576.000000, R^2: 0.8543\n",
      " Test Error: loss: 2294600192.000000, R^2: 0.6329\n",
      "\n",
      "Epoch 229\n",
      "--------------------------------\n",
      "Train Error: loss: 759603200.000000, R^2: 0.8739\n",
      " Test Error: loss: 2363877632.000000, R^2: 0.6219\n",
      "\n",
      "Epoch 230\n",
      "--------------------------------\n",
      "Train Error: loss: 779938752.000000, R^2: 0.8773\n",
      " Test Error: loss: 2391993600.000000, R^2: 0.6174\n",
      "\n",
      "Epoch 231\n",
      "--------------------------------\n",
      "Train Error: loss: 789428416.000000, R^2: 0.8686\n",
      " Test Error: loss: 2370888704.000000, R^2: 0.6207\n",
      "\n",
      "Epoch 232\n",
      "--------------------------------\n",
      "Train Error: loss: 889716736.000000, R^2: 0.8615\n",
      " Test Error: loss: 2499297024.000000, R^2: 0.6002\n",
      "\n",
      "Epoch 233\n",
      "--------------------------------\n",
      "Train Error: loss: 753561792.000000, R^2: 0.8681\n",
      " Test Error: loss: 2518295552.000000, R^2: 0.5972\n",
      "\n",
      "Epoch 234\n",
      "--------------------------------\n",
      "Train Error: loss: 891613376.000000, R^2: 0.8524\n",
      " Test Error: loss: 2393438976.000000, R^2: 0.6171\n",
      "\n",
      "Epoch 235\n",
      "--------------------------------\n",
      "Train Error: loss: 751215296.000000, R^2: 0.8817\n",
      " Test Error: loss: 2337239040.000000, R^2: 0.6261\n",
      "\n",
      "Epoch 236\n",
      "--------------------------------\n",
      "Train Error: loss: 780639424.000000, R^2: 0.8614\n",
      " Test Error: loss: 2505673472.000000, R^2: 0.5992\n",
      "\n",
      "Epoch 237\n",
      "--------------------------------\n",
      "Train Error: loss: 761186112.000000, R^2: 0.8722\n",
      " Test Error: loss: 2389838848.000000, R^2: 0.6177\n",
      "\n",
      "Epoch 238\n",
      "--------------------------------\n",
      "Train Error: loss: 776093440.000000, R^2: 0.8603\n",
      " Test Error: loss: 2290531584.000000, R^2: 0.6336\n",
      "\n",
      "Epoch 239\n",
      "--------------------------------\n",
      "Train Error: loss: 774526400.000000, R^2: 0.8830\n",
      " Test Error: loss: 2289157632.000000, R^2: 0.6338\n",
      "\n",
      "Epoch 240\n",
      "--------------------------------\n",
      "Train Error: loss: 800714688.000000, R^2: 0.8712\n",
      " Test Error: loss: 2281234688.000000, R^2: 0.6351\n",
      "\n",
      "Epoch 241\n",
      "--------------------------------\n",
      "Train Error: loss: 791939264.000000, R^2: 0.8721\n",
      " Test Error: loss: 2402956032.000000, R^2: 0.6156\n",
      "\n",
      "Epoch 242\n",
      "--------------------------------\n",
      "Train Error: loss: 745079488.000000, R^2: 0.8813\n",
      " Test Error: loss: 2535429376.000000, R^2: 0.5944\n",
      "\n",
      "Epoch 243\n",
      "--------------------------------\n",
      "Train Error: loss: 764575104.000000, R^2: 0.8684\n",
      " Test Error: loss: 2309810944.000000, R^2: 0.6305\n",
      "\n",
      "Epoch 244\n",
      "--------------------------------\n",
      "Train Error: loss: 774827200.000000, R^2: 0.8755\n",
      " Test Error: loss: 2225394432.000000, R^2: 0.6440\n",
      "\n",
      "Epoch 245\n",
      "--------------------------------\n",
      "Train Error: loss: 775961664.000000, R^2: 0.8693\n",
      " Test Error: loss: 2368471808.000000, R^2: 0.6211\n",
      "\n",
      "Epoch 246\n",
      "--------------------------------\n",
      "Train Error: loss: 824731776.000000, R^2: 0.8653\n",
      " Test Error: loss: 2420867328.000000, R^2: 0.6127\n",
      "\n",
      "Epoch 247\n",
      "--------------------------------\n",
      "Train Error: loss: 815740736.000000, R^2: 0.8697\n",
      " Test Error: loss: 2317650688.000000, R^2: 0.6293\n",
      "\n",
      "Epoch 248\n",
      "--------------------------------\n",
      "Train Error: loss: 769871296.000000, R^2: 0.8412\n",
      " Test Error: loss: 2288259328.000000, R^2: 0.6340\n",
      "\n",
      "Epoch 249\n",
      "--------------------------------\n",
      "Train Error: loss: 782076352.000000, R^2: 0.8562\n",
      " Test Error: loss: 2268893440.000000, R^2: 0.6371\n",
      "\n",
      "Epoch 250\n",
      "--------------------------------\n",
      "Train Error: loss: 800289984.000000, R^2: 0.8607\n",
      " Test Error: loss: 2178472192.000000, R^2: 0.6515\n",
      "\n",
      "Epoch 251\n",
      "--------------------------------\n",
      "Train Error: loss: 918828544.000000, R^2: 0.8468\n",
      " Test Error: loss: 2200756224.000000, R^2: 0.6480\n",
      "\n",
      "Epoch 252\n",
      "--------------------------------\n",
      "Train Error: loss: 745581312.000000, R^2: 0.8411\n",
      " Test Error: loss: 2351339008.000000, R^2: 0.6239\n",
      "\n",
      "Epoch 253\n",
      "--------------------------------\n",
      "Train Error: loss: 793082560.000000, R^2: 0.8632\n",
      " Test Error: loss: 2253313536.000000, R^2: 0.6395\n",
      "\n",
      "Epoch 254\n",
      "--------------------------------\n",
      "Train Error: loss: 808862080.000000, R^2: 0.8653\n",
      " Test Error: loss: 2240657408.000000, R^2: 0.6416\n",
      "\n",
      "Epoch 255\n",
      "--------------------------------\n",
      "Train Error: loss: 832474304.000000, R^2: 0.8530\n",
      " Test Error: loss: 2135672576.000000, R^2: 0.6584\n",
      "\n",
      "Epoch 256\n",
      "--------------------------------\n",
      "Train Error: loss: 782671808.000000, R^2: 0.8631\n",
      " Test Error: loss: 2186946304.000000, R^2: 0.6502\n",
      "\n",
      "Epoch 257\n",
      "--------------------------------\n",
      "Train Error: loss: 780448512.000000, R^2: 0.8643\n",
      " Test Error: loss: 2244115456.000000, R^2: 0.6410\n",
      "\n",
      "Epoch 258\n",
      "--------------------------------\n",
      "Train Error: loss: 723237056.000000, R^2: 0.8734\n",
      " Test Error: loss: 2137488768.000000, R^2: 0.6581\n",
      "\n",
      "Epoch 259\n",
      "--------------------------------\n",
      "Train Error: loss: 760795136.000000, R^2: 0.8756\n",
      " Test Error: loss: 2182722816.000000, R^2: 0.6508\n",
      "\n",
      "Epoch 260\n",
      "--------------------------------\n",
      "Train Error: loss: 768006016.000000, R^2: 0.8732\n",
      " Test Error: loss: 2107622784.000000, R^2: 0.6629\n",
      "\n",
      "Epoch 261\n",
      "--------------------------------\n",
      "Train Error: loss: 1472663936.000000, R^2: 0.7246\n",
      " Test Error: loss: 2185545984.000000, R^2: 0.6504\n",
      "\n",
      "Epoch 262\n",
      "--------------------------------\n",
      "Train Error: loss: 1017756352.000000, R^2: 0.8312\n",
      " Test Error: loss: 1968188160.000000, R^2: 0.6852\n",
      "\n",
      "Epoch 263\n",
      "--------------------------------\n",
      "Train Error: loss: 849208512.000000, R^2: 0.8650\n",
      " Test Error: loss: 2032715520.000000, R^2: 0.6748\n",
      "\n",
      "Epoch 264\n",
      "--------------------------------\n",
      "Train Error: loss: 793171904.000000, R^2: 0.8643\n",
      " Test Error: loss: 1957658112.000000, R^2: 0.6868\n",
      "\n",
      "Epoch 265\n",
      "--------------------------------\n",
      "Train Error: loss: 789133760.000000, R^2: 0.8696\n",
      " Test Error: loss: 2049990272.000000, R^2: 0.6721\n",
      "\n",
      "Epoch 266\n",
      "--------------------------------\n",
      "Train Error: loss: 749183232.000000, R^2: 0.8762\n",
      " Test Error: loss: 2138322560.000000, R^2: 0.6579\n",
      "\n",
      "Epoch 267\n",
      "--------------------------------\n",
      "Train Error: loss: 710462656.000000, R^2: 0.8825\n",
      " Test Error: loss: 2094646784.000000, R^2: 0.6649\n",
      "\n",
      "Epoch 268\n",
      "--------------------------------\n",
      "Train Error: loss: 723757760.000000, R^2: 0.8806\n",
      " Test Error: loss: 2052953856.000000, R^2: 0.6716\n",
      "\n",
      "Epoch 269\n",
      "--------------------------------\n",
      "Train Error: loss: 730364288.000000, R^2: 0.8674\n",
      " Test Error: loss: 2057261696.000000, R^2: 0.6709\n",
      "\n",
      "Epoch 270\n",
      "--------------------------------\n",
      "Train Error: loss: 719720448.000000, R^2: 0.8819\n",
      " Test Error: loss: 2135646976.000000, R^2: 0.6584\n",
      "\n",
      "Epoch 271\n",
      "--------------------------------\n",
      "Train Error: loss: 841028160.000000, R^2: 0.8673\n",
      " Test Error: loss: 2144516096.000000, R^2: 0.6569\n",
      "\n",
      "Epoch 272\n",
      "--------------------------------\n",
      "Train Error: loss: 822713792.000000, R^2: 0.8615\n",
      " Test Error: loss: 2158365440.000000, R^2: 0.6547\n",
      "\n",
      "Epoch 273\n",
      "--------------------------------\n",
      "Train Error: loss: 753508864.000000, R^2: 0.8750\n",
      " Test Error: loss: 2042786944.000000, R^2: 0.6732\n",
      "\n",
      "Epoch 274\n",
      "--------------------------------\n",
      "Train Error: loss: 757249280.000000, R^2: 0.8774\n",
      " Test Error: loss: 2012448128.000000, R^2: 0.6781\n",
      "\n",
      "Epoch 275\n",
      "--------------------------------\n",
      "Train Error: loss: 690050816.000000, R^2: 0.8798\n",
      " Test Error: loss: 2160584960.000000, R^2: 0.6544\n",
      "\n",
      "Epoch 276\n",
      "--------------------------------\n",
      "Train Error: loss: 845959360.000000, R^2: 0.8545\n",
      " Test Error: loss: 2251552000.000000, R^2: 0.6398\n",
      "\n",
      "Epoch 277\n",
      "--------------------------------\n",
      "Train Error: loss: 722557632.000000, R^2: 0.8814\n",
      " Test Error: loss: 2053132928.000000, R^2: 0.6716\n",
      "\n",
      "Epoch 278\n",
      "--------------------------------\n",
      "Train Error: loss: 739185984.000000, R^2: 0.8700\n",
      " Test Error: loss: 2033929088.000000, R^2: 0.6746\n",
      "\n",
      "Epoch 279\n",
      "--------------------------------\n",
      "Train Error: loss: 746210752.000000, R^2: 0.8578\n",
      " Test Error: loss: 2105031552.000000, R^2: 0.6633\n",
      "\n",
      "Epoch 280\n",
      "--------------------------------\n",
      "Train Error: loss: 753577792.000000, R^2: 0.8776\n",
      " Test Error: loss: 2173264640.000000, R^2: 0.6524\n",
      "\n",
      "Epoch 281\n",
      "--------------------------------\n",
      "Train Error: loss: 761766976.000000, R^2: 0.8742\n",
      " Test Error: loss: 2100866688.000000, R^2: 0.6639\n",
      "\n",
      "Epoch 282\n",
      "--------------------------------\n",
      "Train Error: loss: 929718400.000000, R^2: 0.8408\n",
      " Test Error: loss: 2012589696.000000, R^2: 0.6781\n",
      "\n",
      "Epoch 283\n",
      "--------------------------------\n",
      "Train Error: loss: 783449536.000000, R^2: 0.8666\n",
      " Test Error: loss: 2005150720.000000, R^2: 0.6792\n",
      "\n",
      "Epoch 284\n",
      "--------------------------------\n",
      "Train Error: loss: 735122432.000000, R^2: 0.8766\n",
      " Test Error: loss: 1964243584.000000, R^2: 0.6858\n",
      "\n",
      "Epoch 285\n",
      "--------------------------------\n",
      "Train Error: loss: 722170496.000000, R^2: 0.8660\n",
      " Test Error: loss: 2059904384.000000, R^2: 0.6705\n",
      "\n",
      "Epoch 286\n",
      "--------------------------------\n",
      "Train Error: loss: 793420992.000000, R^2: 0.8675\n",
      " Test Error: loss: 2091374080.000000, R^2: 0.6655\n",
      "\n",
      "Epoch 287\n",
      "--------------------------------\n",
      "Train Error: loss: 726104768.000000, R^2: 0.8685\n",
      " Test Error: loss: 2041733632.000000, R^2: 0.6734\n",
      "\n",
      "Epoch 288\n",
      "--------------------------------\n",
      "Train Error: loss: 771543168.000000, R^2: 0.8632\n",
      " Test Error: loss: 2023203840.000000, R^2: 0.6764\n",
      "\n",
      "Epoch 289\n",
      "--------------------------------\n",
      "Train Error: loss: 754619840.000000, R^2: 0.8726\n",
      " Test Error: loss: 1940376832.000000, R^2: 0.6896\n",
      "\n",
      "Epoch 290\n",
      "--------------------------------\n",
      "Train Error: loss: 670104000.000000, R^2: 0.8817\n",
      " Test Error: loss: 1974171904.000000, R^2: 0.6842\n",
      "\n",
      "Epoch 291\n",
      "--------------------------------\n",
      "Train Error: loss: 720502400.000000, R^2: 0.8828\n",
      " Test Error: loss: 2012994816.000000, R^2: 0.6780\n",
      "\n",
      "Epoch 292\n",
      "--------------------------------\n",
      "Train Error: loss: 783915072.000000, R^2: 0.8783\n",
      " Test Error: loss: 2074224256.000000, R^2: 0.6682\n",
      "\n",
      "Epoch 293\n",
      "--------------------------------\n",
      "Train Error: loss: 740692608.000000, R^2: 0.8658\n",
      " Test Error: loss: 2151030784.000000, R^2: 0.6559\n",
      "\n",
      "Epoch 294\n",
      "--------------------------------\n",
      "Train Error: loss: 1670009088.000000, R^2: 0.6407\n",
      " Test Error: loss: 2076973696.000000, R^2: 0.6678\n",
      "\n",
      "Epoch 295\n",
      "--------------------------------\n",
      "Train Error: loss: 1102572288.000000, R^2: 0.8213\n",
      " Test Error: loss: 1675644928.000000, R^2: 0.7320\n",
      "\n",
      "Epoch 296\n",
      "--------------------------------\n",
      "Train Error: loss: 944605632.000000, R^2: 0.8416\n",
      " Test Error: loss: 2099316992.000000, R^2: 0.6642\n",
      "\n",
      "Epoch 297\n",
      "--------------------------------\n",
      "Train Error: loss: 743976768.000000, R^2: 0.8676\n",
      " Test Error: loss: 1825237504.000000, R^2: 0.7080\n",
      "\n",
      "Epoch 298\n",
      "--------------------------------\n",
      "Train Error: loss: 783443136.000000, R^2: 0.8598\n",
      " Test Error: loss: 1842540288.000000, R^2: 0.7053\n",
      "\n",
      "Epoch 299\n",
      "--------------------------------\n",
      "Train Error: loss: 899248640.000000, R^2: 0.8437\n",
      " Test Error: loss: 1889410944.000000, R^2: 0.6978\n",
      "\n",
      "Epoch 300\n",
      "--------------------------------\n",
      "Train Error: loss: 966264000.000000, R^2: 0.8513\n",
      " Test Error: loss: 1903149952.000000, R^2: 0.6956\n",
      "\n",
      "Epoch 301\n",
      "--------------------------------\n",
      "Train Error: loss: 735053824.000000, R^2: 0.8851\n",
      " Test Error: loss: 1874525056.000000, R^2: 0.7001\n",
      "\n",
      "Epoch 302\n",
      "--------------------------------\n",
      "Train Error: loss: 695221632.000000, R^2: 0.8854\n",
      " Test Error: loss: 1934301312.000000, R^2: 0.6906\n",
      "\n",
      "Epoch 303\n",
      "--------------------------------\n",
      "Train Error: loss: 668747584.000000, R^2: 0.8694\n",
      " Test Error: loss: 1918568192.000000, R^2: 0.6931\n",
      "\n",
      "Epoch 304\n",
      "--------------------------------\n",
      "Train Error: loss: 781206720.000000, R^2: 0.8615\n",
      " Test Error: loss: 1938881920.000000, R^2: 0.6898\n",
      "\n",
      "Epoch 305\n",
      "--------------------------------\n",
      "Train Error: loss: 680524224.000000, R^2: 0.8741\n",
      " Test Error: loss: 1957872512.000000, R^2: 0.6868\n",
      "\n",
      "Epoch 306\n",
      "--------------------------------\n",
      "Train Error: loss: 732600256.000000, R^2: 0.8787\n",
      " Test Error: loss: 1950182144.000000, R^2: 0.6880\n",
      "\n",
      "Epoch 307\n",
      "--------------------------------\n",
      "Train Error: loss: 744225216.000000, R^2: 0.8573\n",
      " Test Error: loss: 1923899008.000000, R^2: 0.6922\n",
      "\n",
      "Epoch 308\n",
      "--------------------------------\n",
      "Train Error: loss: 685462144.000000, R^2: 0.8848\n",
      " Test Error: loss: 1909258496.000000, R^2: 0.6946\n",
      "\n",
      "Epoch 309\n",
      "--------------------------------\n",
      "Train Error: loss: 839261184.000000, R^2: 0.8477\n",
      " Test Error: loss: 1876742272.000000, R^2: 0.6998\n",
      "\n",
      "Epoch 310\n",
      "--------------------------------\n",
      "Train Error: loss: 809615360.000000, R^2: 0.8732\n",
      " Test Error: loss: 1971696384.000000, R^2: 0.6846\n",
      "\n",
      "Epoch 311\n",
      "--------------------------------\n",
      "Train Error: loss: 679903744.000000, R^2: 0.8935\n",
      " Test Error: loss: 1885014272.000000, R^2: 0.6985\n",
      "\n",
      "Epoch 312\n",
      "--------------------------------\n",
      "Train Error: loss: 747323072.000000, R^2: 0.8705\n",
      " Test Error: loss: 1905099264.000000, R^2: 0.6952\n",
      "\n",
      "Epoch 313\n",
      "--------------------------------\n",
      "Train Error: loss: 640308544.000000, R^2: 0.8846\n",
      " Test Error: loss: 1912537728.000000, R^2: 0.6941\n",
      "\n",
      "Epoch 314\n",
      "--------------------------------\n",
      "Train Error: loss: 734343552.000000, R^2: 0.8804\n",
      " Test Error: loss: 1897954432.000000, R^2: 0.6964\n",
      "\n",
      "Epoch 315\n",
      "--------------------------------\n",
      "Train Error: loss: 821326528.000000, R^2: 0.8379\n",
      " Test Error: loss: 1929642880.000000, R^2: 0.6913\n",
      "\n",
      "Epoch 316\n",
      "--------------------------------\n",
      "Train Error: loss: 772364992.000000, R^2: 0.8857\n",
      " Test Error: loss: 1860368128.000000, R^2: 0.7024\n",
      "\n",
      "Epoch 317\n",
      "--------------------------------\n",
      "Train Error: loss: 667767232.000000, R^2: 0.8884\n",
      " Test Error: loss: 1981747584.000000, R^2: 0.6830\n",
      "\n",
      "Epoch 318\n",
      "--------------------------------\n",
      "Train Error: loss: 655979840.000000, R^2: 0.8616\n",
      " Test Error: loss: 1876968960.000000, R^2: 0.6997\n",
      "\n",
      "Epoch 319\n",
      "--------------------------------\n",
      "Train Error: loss: 833607616.000000, R^2: 0.8830\n",
      " Test Error: loss: 1921541504.000000, R^2: 0.6926\n",
      "\n",
      "Epoch 320\n",
      "--------------------------------\n",
      "Train Error: loss: 669267520.000000, R^2: 0.8890\n",
      " Test Error: loss: 2041347584.000000, R^2: 0.6735\n",
      "\n",
      "Epoch 321\n",
      "--------------------------------\n",
      "Train Error: loss: 727390336.000000, R^2: 0.8730\n",
      " Test Error: loss: 2107354240.000000, R^2: 0.6629\n",
      "\n",
      "Epoch 322\n",
      "--------------------------------\n",
      "Train Error: loss: 847315072.000000, R^2: 0.8660\n",
      " Test Error: loss: 1923138944.000000, R^2: 0.6924\n",
      "\n",
      "Epoch 323\n",
      "--------------------------------\n",
      "Train Error: loss: 787761728.000000, R^2: 0.8731\n",
      " Test Error: loss: 1870811008.000000, R^2: 0.7007\n",
      "\n",
      "Epoch 324\n",
      "--------------------------------\n",
      "Train Error: loss: 705180800.000000, R^2: 0.8730\n",
      " Test Error: loss: 1838118528.000000, R^2: 0.7060\n",
      "\n",
      "Epoch 325\n",
      "--------------------------------\n",
      "Train Error: loss: 690428224.000000, R^2: 0.8849\n",
      " Test Error: loss: 1942658688.000000, R^2: 0.6892\n",
      "\n",
      "Epoch 326\n",
      "--------------------------------\n",
      "Train Error: loss: 667476288.000000, R^2: 0.8936\n",
      " Test Error: loss: 1892008576.000000, R^2: 0.6973\n",
      "\n",
      "Epoch 327\n",
      "--------------------------------\n",
      "Train Error: loss: 689080384.000000, R^2: 0.8862\n",
      " Test Error: loss: 1906205440.000000, R^2: 0.6951\n",
      "\n",
      "Epoch 328\n",
      "--------------------------------\n",
      "Train Error: loss: 866286528.000000, R^2: 0.8505\n",
      " Test Error: loss: 1848543872.000000, R^2: 0.7043\n",
      "\n",
      "Epoch 329\n",
      "--------------------------------\n",
      "Train Error: loss: 634144512.000000, R^2: 0.8849\n",
      " Test Error: loss: 1924730624.000000, R^2: 0.6921\n",
      "\n",
      "Epoch 330\n",
      "--------------------------------\n",
      "Train Error: loss: 897509824.000000, R^2: 0.8744\n",
      " Test Error: loss: 1923341056.000000, R^2: 0.6923\n",
      "\n",
      "Epoch 331\n",
      "--------------------------------\n",
      "Train Error: loss: 732765056.000000, R^2: 0.8840\n",
      " Test Error: loss: 2013652864.000000, R^2: 0.6779\n",
      "\n",
      "Epoch 332\n",
      "--------------------------------\n",
      "Train Error: loss: 838083264.000000, R^2: 0.8678\n",
      " Test Error: loss: 2077500160.000000, R^2: 0.6677\n",
      "\n",
      "Epoch 333\n",
      "--------------------------------\n",
      "Train Error: loss: 821092480.000000, R^2: 0.8572\n",
      " Test Error: loss: 1809698048.000000, R^2: 0.7105\n",
      "\n",
      "Epoch 334\n",
      "--------------------------------\n",
      "Train Error: loss: 679994304.000000, R^2: 0.8884\n",
      " Test Error: loss: 1751420800.000000, R^2: 0.7198\n",
      "\n",
      "Epoch 335\n",
      "--------------------------------\n",
      "Train Error: loss: 645140288.000000, R^2: 0.8914\n",
      " Test Error: loss: 1805096320.000000, R^2: 0.7112\n",
      "\n",
      "Epoch 336\n",
      "--------------------------------\n",
      "Train Error: loss: 764127552.000000, R^2: 0.8860\n",
      " Test Error: loss: 1820259200.000000, R^2: 0.7088\n",
      "\n",
      "Epoch 337\n",
      "--------------------------------\n",
      "Train Error: loss: 678883584.000000, R^2: 0.8763\n",
      " Test Error: loss: 1897535232.000000, R^2: 0.6965\n",
      "\n",
      "Epoch 338\n",
      "--------------------------------\n",
      "Train Error: loss: 679891136.000000, R^2: 0.8872\n",
      " Test Error: loss: 1775925760.000000, R^2: 0.7159\n",
      "\n",
      "Epoch 339\n",
      "--------------------------------\n",
      "Train Error: loss: 867516032.000000, R^2: 0.8483\n",
      " Test Error: loss: 1767607680.000000, R^2: 0.7172\n",
      "\n",
      "Epoch 340\n",
      "--------------------------------\n",
      "Train Error: loss: 663964160.000000, R^2: 0.8767\n",
      " Test Error: loss: 1715022720.000000, R^2: 0.7257\n",
      "\n",
      "Epoch 341\n",
      "--------------------------------\n",
      "Train Error: loss: 756865280.000000, R^2: 0.8759\n",
      " Test Error: loss: 1672594048.000000, R^2: 0.7324\n",
      "\n",
      "Epoch 342\n",
      "--------------------------------\n",
      "Train Error: loss: 660515712.000000, R^2: 0.8881\n",
      " Test Error: loss: 1704802944.000000, R^2: 0.7273\n",
      "\n",
      "Epoch 343\n",
      "--------------------------------\n",
      "Train Error: loss: 606595264.000000, R^2: 0.8944\n",
      " Test Error: loss: 1688876800.000000, R^2: 0.7298\n",
      "\n",
      "Epoch 344\n",
      "--------------------------------\n",
      "Train Error: loss: 780343040.000000, R^2: 0.8687\n",
      " Test Error: loss: 1651691776.000000, R^2: 0.7358\n",
      "\n",
      "Epoch 345\n",
      "--------------------------------\n",
      "Train Error: loss: 689451328.000000, R^2: 0.8807\n",
      " Test Error: loss: 1630103936.000000, R^2: 0.7392\n",
      "\n",
      "Epoch 346\n",
      "--------------------------------\n",
      "Train Error: loss: 684564736.000000, R^2: 0.8855\n",
      " Test Error: loss: 1651271808.000000, R^2: 0.7359\n",
      "\n",
      "Epoch 347\n",
      "--------------------------------\n",
      "Train Error: loss: 748941376.000000, R^2: 0.8587\n",
      " Test Error: loss: 1654306176.000000, R^2: 0.7354\n",
      "\n",
      "Epoch 348\n",
      "--------------------------------\n",
      "Train Error: loss: 683138624.000000, R^2: 0.8825\n",
      " Test Error: loss: 1656769792.000000, R^2: 0.7350\n",
      "\n",
      "Epoch 349\n",
      "--------------------------------\n",
      "Train Error: loss: 942178240.000000, R^2: 0.8684\n",
      " Test Error: loss: 1626720896.000000, R^2: 0.7398\n",
      "\n",
      "Epoch 350\n",
      "--------------------------------\n",
      "Train Error: loss: 637451712.000000, R^2: 0.8922\n",
      " Test Error: loss: 1560050560.000000, R^2: 0.7504\n",
      "\n",
      "Epoch 351\n",
      "--------------------------------\n",
      "Train Error: loss: 665625664.000000, R^2: 0.8890\n",
      " Test Error: loss: 1608308480.000000, R^2: 0.7427\n",
      "\n",
      "Epoch 352\n",
      "--------------------------------\n",
      "Train Error: loss: 625697280.000000, R^2: 0.8838\n",
      " Test Error: loss: 1577350016.000000, R^2: 0.7477\n",
      "\n",
      "Epoch 353\n",
      "--------------------------------\n",
      "Train Error: loss: 642608128.000000, R^2: 0.8997\n",
      " Test Error: loss: 1579166080.000000, R^2: 0.7474\n",
      "\n",
      "Epoch 354\n",
      "--------------------------------\n",
      "Train Error: loss: 690650368.000000, R^2: 0.8739\n",
      " Test Error: loss: 1615965184.000000, R^2: 0.7415\n",
      "\n",
      "Epoch 355\n",
      "--------------------------------\n",
      "Train Error: loss: 686166720.000000, R^2: 0.8815\n",
      " Test Error: loss: 1600032896.000000, R^2: 0.7440\n",
      "\n",
      "Epoch 356\n",
      "--------------------------------\n",
      "Train Error: loss: 737497536.000000, R^2: 0.8695\n",
      " Test Error: loss: 1625148288.000000, R^2: 0.7400\n",
      "\n",
      "Epoch 357\n",
      "--------------------------------\n",
      "Train Error: loss: 658250240.000000, R^2: 0.8804\n",
      " Test Error: loss: 1553471616.000000, R^2: 0.7515\n",
      "\n",
      "Epoch 358\n",
      "--------------------------------\n",
      "Train Error: loss: 606358016.000000, R^2: 0.8993\n",
      " Test Error: loss: 1445010432.000000, R^2: 0.7688\n",
      "\n",
      "Epoch 359\n",
      "--------------------------------\n",
      "Train Error: loss: 642424320.000000, R^2: 0.8924\n",
      " Test Error: loss: 1488946944.000000, R^2: 0.7618\n",
      "\n",
      "Epoch 360\n",
      "--------------------------------\n",
      "Train Error: loss: 610808960.000000, R^2: 0.8856\n",
      " Test Error: loss: 1558597760.000000, R^2: 0.7507\n",
      "\n",
      "Epoch 361\n",
      "--------------------------------\n",
      "Train Error: loss: 637835136.000000, R^2: 0.8914\n",
      " Test Error: loss: 1597792384.000000, R^2: 0.7444\n",
      "\n",
      "Epoch 362\n",
      "--------------------------------\n",
      "Train Error: loss: 655028928.000000, R^2: 0.8984\n",
      " Test Error: loss: 1692393600.000000, R^2: 0.7293\n",
      "\n",
      "Epoch 363\n",
      "--------------------------------\n",
      "Train Error: loss: 629099904.000000, R^2: 0.8963\n",
      " Test Error: loss: 1584121728.000000, R^2: 0.7466\n",
      "\n",
      "Epoch 364\n",
      "--------------------------------\n",
      "Train Error: loss: 611372160.000000, R^2: 0.9017\n",
      " Test Error: loss: 1473798016.000000, R^2: 0.7642\n",
      "\n",
      "Epoch 365\n",
      "--------------------------------\n",
      "Train Error: loss: 784164032.000000, R^2: 0.8877\n",
      " Test Error: loss: 1528991744.000000, R^2: 0.7554\n",
      "\n",
      "Epoch 366\n",
      "--------------------------------\n",
      "Train Error: loss: 583709312.000000, R^2: 0.8961\n",
      " Test Error: loss: 1437836032.000000, R^2: 0.7700\n",
      "\n",
      "Epoch 367\n",
      "--------------------------------\n",
      "Train Error: loss: 606602688.000000, R^2: 0.8936\n",
      " Test Error: loss: 1442967808.000000, R^2: 0.7692\n",
      "\n",
      "Epoch 368\n",
      "--------------------------------\n",
      "Train Error: loss: 612145856.000000, R^2: 0.8825\n",
      " Test Error: loss: 1466243584.000000, R^2: 0.7655\n",
      "\n",
      "Epoch 369\n",
      "--------------------------------\n",
      "Train Error: loss: 599750208.000000, R^2: 0.9016\n",
      " Test Error: loss: 1466571392.000000, R^2: 0.7654\n",
      "\n",
      "Epoch 370\n",
      "--------------------------------\n",
      "Train Error: loss: 686888448.000000, R^2: 0.8901\n",
      " Test Error: loss: 1407119744.000000, R^2: 0.7749\n",
      "\n",
      "Epoch 371\n",
      "--------------------------------\n",
      "Train Error: loss: 670971200.000000, R^2: 0.8978\n",
      " Test Error: loss: 1482918784.000000, R^2: 0.7628\n",
      "\n",
      "Epoch 372\n",
      "--------------------------------\n",
      "Train Error: loss: 632251840.000000, R^2: 0.8961\n",
      " Test Error: loss: 1468812160.000000, R^2: 0.7650\n",
      "\n",
      "Epoch 373\n",
      "--------------------------------\n",
      "Train Error: loss: 645857984.000000, R^2: 0.8870\n",
      " Test Error: loss: 1448273024.000000, R^2: 0.7683\n",
      "\n",
      "Epoch 374\n",
      "--------------------------------\n",
      "Train Error: loss: 737847936.000000, R^2: 0.8461\n",
      " Test Error: loss: 1481272576.000000, R^2: 0.7630\n",
      "\n",
      "Epoch 375\n",
      "--------------------------------\n",
      "Train Error: loss: 817888960.000000, R^2: 0.8700\n",
      " Test Error: loss: 1401824256.000000, R^2: 0.7758\n",
      "\n",
      "Epoch 376\n",
      "--------------------------------\n",
      "Train Error: loss: 697839936.000000, R^2: 0.8711\n",
      " Test Error: loss: 1380797568.000000, R^2: 0.7791\n",
      "\n",
      "Epoch 377\n",
      "--------------------------------\n",
      "Train Error: loss: 744362176.000000, R^2: 0.8236\n",
      " Test Error: loss: 1405184384.000000, R^2: 0.7752\n",
      "\n",
      "Epoch 378\n",
      "--------------------------------\n",
      "Train Error: loss: 788840192.000000, R^2: 0.8740\n",
      " Test Error: loss: 1202365824.000000, R^2: 0.8077\n",
      "\n",
      "Epoch 379\n",
      "--------------------------------\n",
      "Train Error: loss: 706978752.000000, R^2: 0.8871\n",
      " Test Error: loss: 1331394176.000000, R^2: 0.7870\n",
      "\n",
      "Epoch 380\n",
      "--------------------------------\n",
      "Train Error: loss: 748745152.000000, R^2: 0.8698\n",
      " Test Error: loss: 1272918272.000000, R^2: 0.7964\n",
      "\n",
      "Epoch 381\n",
      "--------------------------------\n",
      "Train Error: loss: 710189056.000000, R^2: 0.8779\n",
      " Test Error: loss: 1228034176.000000, R^2: 0.8036\n",
      "\n",
      "Epoch 382\n",
      "--------------------------------\n",
      "Train Error: loss: 706510528.000000, R^2: 0.8694\n",
      " Test Error: loss: 1214453248.000000, R^2: 0.8057\n",
      "\n",
      "Epoch 383\n",
      "--------------------------------\n",
      "Train Error: loss: 1566828928.000000, R^2: 0.7144\n",
      " Test Error: loss: 1278952832.000000, R^2: 0.7954\n",
      "\n",
      "Epoch 384\n",
      "--------------------------------\n",
      "Train Error: loss: 1014634304.000000, R^2: 0.8529\n",
      " Test Error: loss: 1011591168.000000, R^2: 0.8382\n",
      "\n",
      "Epoch 385\n",
      "--------------------------------\n",
      "Train Error: loss: 776915648.000000, R^2: 0.8579\n",
      " Test Error: loss: 1175005696.000000, R^2: 0.8120\n",
      "\n",
      "Epoch 386\n",
      "--------------------------------\n",
      "Train Error: loss: 671594432.000000, R^2: 0.8841\n",
      " Test Error: loss: 1125298176.000000, R^2: 0.8200\n",
      "\n",
      "Epoch 387\n",
      "--------------------------------\n",
      "Train Error: loss: 748854784.000000, R^2: 0.8774\n",
      " Test Error: loss: 1193873664.000000, R^2: 0.8090\n",
      "\n",
      "Epoch 388\n",
      "--------------------------------\n",
      "Train Error: loss: 681375936.000000, R^2: 0.8871\n",
      " Test Error: loss: 1267451264.000000, R^2: 0.7973\n",
      "\n",
      "Epoch 389\n",
      "--------------------------------\n",
      "Train Error: loss: 769378240.000000, R^2: 0.8706\n",
      " Test Error: loss: 1222204800.000000, R^2: 0.8045\n",
      "\n",
      "Epoch 390\n",
      "--------------------------------\n",
      "Train Error: loss: 678200832.000000, R^2: 0.8882\n",
      " Test Error: loss: 1157716352.000000, R^2: 0.8148\n",
      "\n",
      "Epoch 391\n",
      "--------------------------------\n",
      "Train Error: loss: 757978368.000000, R^2: 0.8889\n",
      " Test Error: loss: 1436735360.000000, R^2: 0.7702\n",
      "\n",
      "Epoch 392\n",
      "--------------------------------\n",
      "Train Error: loss: 701491776.000000, R^2: 0.8848\n",
      " Test Error: loss: 1291505024.000000, R^2: 0.7934\n",
      "\n",
      "Epoch 393\n",
      "--------------------------------\n",
      "Train Error: loss: 746715264.000000, R^2: 0.8772\n",
      " Test Error: loss: 1188811392.000000, R^2: 0.8098\n",
      "\n",
      "Epoch 394\n",
      "--------------------------------\n",
      "Train Error: loss: 686943104.000000, R^2: 0.8819\n",
      " Test Error: loss: 1293104384.000000, R^2: 0.7931\n",
      "\n",
      "Epoch 395\n",
      "--------------------------------\n",
      "Train Error: loss: 652195328.000000, R^2: 0.8898\n",
      " Test Error: loss: 1332504320.000000, R^2: 0.7868\n",
      "\n",
      "Epoch 396\n",
      "--------------------------------\n",
      "Train Error: loss: 588843392.000000, R^2: 0.9052\n",
      " Test Error: loss: 1261900160.000000, R^2: 0.7981\n",
      "\n",
      "Epoch 397\n",
      "--------------------------------\n",
      "Train Error: loss: 602653376.000000, R^2: 0.8968\n",
      " Test Error: loss: 1300054912.000000, R^2: 0.7920\n",
      "\n",
      "Epoch 398\n",
      "--------------------------------\n",
      "Train Error: loss: 899076736.000000, R^2: 0.8398\n",
      " Test Error: loss: 1192634496.000000, R^2: 0.8092\n",
      "\n",
      "Epoch 399\n",
      "--------------------------------\n",
      "Train Error: loss: 686540480.000000, R^2: 0.8898\n",
      " Test Error: loss: 1137474688.000000, R^2: 0.8180\n",
      "\n",
      "Epoch 400\n",
      "--------------------------------\n",
      "Train Error: loss: 584892160.000000, R^2: 0.8888\n",
      " Test Error: loss: 1200360320.000000, R^2: 0.8080\n",
      "\n",
      "Epoch 401\n",
      "--------------------------------\n",
      "Train Error: loss: 596984064.000000, R^2: 0.8976\n",
      " Test Error: loss: 1170603136.000000, R^2: 0.8127\n",
      "\n",
      "Epoch 402\n",
      "--------------------------------\n",
      "Train Error: loss: 617615616.000000, R^2: 0.9068\n",
      " Test Error: loss: 1200646016.000000, R^2: 0.8079\n",
      "\n",
      "Epoch 403\n",
      "--------------------------------\n",
      "Train Error: loss: 582217664.000000, R^2: 0.8994\n",
      " Test Error: loss: 1247407616.000000, R^2: 0.8005\n",
      "\n",
      "Epoch 404\n",
      "--------------------------------\n",
      "Train Error: loss: 729244352.000000, R^2: 0.8782\n",
      " Test Error: loss: 1165204992.000000, R^2: 0.8136\n",
      "\n",
      "Epoch 405\n",
      "--------------------------------\n",
      "Train Error: loss: 729228736.000000, R^2: 0.8750\n",
      " Test Error: loss: 1226728448.000000, R^2: 0.8038\n",
      "\n",
      "Epoch 406\n",
      "--------------------------------\n",
      "Train Error: loss: 758231872.000000, R^2: 0.8742\n",
      " Test Error: loss: 1108331392.000000, R^2: 0.8227\n",
      "\n",
      "Epoch 407\n",
      "--------------------------------\n",
      "Train Error: loss: 747200448.000000, R^2: 0.8463\n",
      " Test Error: loss: 1010292288.000000, R^2: 0.8384\n",
      "\n",
      "Epoch 408\n",
      "--------------------------------\n",
      "Train Error: loss: 733617792.000000, R^2: 0.9004\n",
      " Test Error: loss: 1236997376.000000, R^2: 0.8021\n",
      "\n",
      "Epoch 409\n",
      "--------------------------------\n",
      "Train Error: loss: 803238528.000000, R^2: 0.8658\n",
      " Test Error: loss: 1113880832.000000, R^2: 0.8218\n",
      "\n",
      "Epoch 410\n",
      "--------------------------------\n",
      "Train Error: loss: 649019712.000000, R^2: 0.8874\n",
      " Test Error: loss: 1084607104.000000, R^2: 0.8265\n",
      "\n",
      "Epoch 411\n",
      "--------------------------------\n",
      "Train Error: loss: 685160640.000000, R^2: 0.8939\n",
      " Test Error: loss: 1093888512.000000, R^2: 0.8250\n",
      "\n",
      "Epoch 412\n",
      "--------------------------------\n",
      "Train Error: loss: 569817536.000000, R^2: 0.9023\n",
      " Test Error: loss: 1141843200.000000, R^2: 0.8173\n",
      "\n",
      "Epoch 413\n",
      "--------------------------------\n",
      "Train Error: loss: 560106304.000000, R^2: 0.8898\n",
      " Test Error: loss: 1096780032.000000, R^2: 0.8246\n",
      "\n",
      "Epoch 414\n",
      "--------------------------------\n",
      "Train Error: loss: 721942016.000000, R^2: 0.8774\n",
      " Test Error: loss: 1092932480.000000, R^2: 0.8252\n",
      "\n",
      "Epoch 415\n",
      "--------------------------------\n",
      "Train Error: loss: 628056384.000000, R^2: 0.8991\n",
      " Test Error: loss: 1088386944.000000, R^2: 0.8259\n",
      "\n",
      "Epoch 416\n",
      "--------------------------------\n",
      "Train Error: loss: 629102848.000000, R^2: 0.8962\n",
      " Test Error: loss: 1155060352.000000, R^2: 0.8152\n",
      "\n",
      "Epoch 417\n",
      "--------------------------------\n",
      "Train Error: loss: 619581376.000000, R^2: 0.8999\n",
      " Test Error: loss: 1130025600.000000, R^2: 0.8192\n",
      "\n",
      "Epoch 418\n",
      "--------------------------------\n",
      "Train Error: loss: 581436800.000000, R^2: 0.8972\n",
      " Test Error: loss: 1128096128.000000, R^2: 0.8195\n",
      "\n",
      "Epoch 419\n",
      "--------------------------------\n",
      "Train Error: loss: 636536192.000000, R^2: 0.8840\n",
      " Test Error: loss: 1107566720.000000, R^2: 0.8228\n",
      "\n",
      "Epoch 420\n",
      "--------------------------------\n",
      "Train Error: loss: 733167040.000000, R^2: 0.8694\n",
      " Test Error: loss: 1016983168.000000, R^2: 0.8373\n",
      "\n",
      "Epoch 421\n",
      "--------------------------------\n",
      "Train Error: loss: 631735232.000000, R^2: 0.8894\n",
      " Test Error: loss: 998813888.000000, R^2: 0.8402\n",
      "\n",
      "Epoch 422\n",
      "--------------------------------\n",
      "Train Error: loss: 588279488.000000, R^2: 0.9031\n",
      " Test Error: loss: 1031221056.000000, R^2: 0.8350\n",
      "\n",
      "Epoch 423\n",
      "--------------------------------\n",
      "Train Error: loss: 650951936.000000, R^2: 0.8983\n",
      " Test Error: loss: 1154350208.000000, R^2: 0.8153\n",
      "\n",
      "Epoch 424\n",
      "--------------------------------\n",
      "Train Error: loss: 629977088.000000, R^2: 0.8817\n",
      " Test Error: loss: 1105738112.000000, R^2: 0.8231\n",
      "\n",
      "Epoch 425\n",
      "--------------------------------\n",
      "Train Error: loss: 583910464.000000, R^2: 0.8943\n",
      " Test Error: loss: 1077137408.000000, R^2: 0.8277\n",
      "\n",
      "Epoch 426\n",
      "--------------------------------\n",
      "Train Error: loss: 572364928.000000, R^2: 0.9039\n",
      " Test Error: loss: 1060513408.000000, R^2: 0.8304\n",
      "\n",
      "Epoch 427\n",
      "--------------------------------\n",
      "Train Error: loss: 569459264.000000, R^2: 0.8979\n",
      " Test Error: loss: 1133757312.000000, R^2: 0.8186\n",
      "\n",
      "Epoch 428\n",
      "--------------------------------\n",
      "Train Error: loss: 596285376.000000, R^2: 0.8848\n",
      " Test Error: loss: 1094337408.000000, R^2: 0.8249\n",
      "\n",
      "Epoch 429\n",
      "--------------------------------\n",
      "Train Error: loss: 596269312.000000, R^2: 0.9005\n",
      " Test Error: loss: 931851968.000000, R^2: 0.8509\n",
      "\n",
      "Epoch 430\n",
      "--------------------------------\n",
      "Train Error: loss: 572565696.000000, R^2: 0.8931\n",
      " Test Error: loss: 965016000.000000, R^2: 0.8456\n",
      "\n",
      "Epoch 431\n",
      "--------------------------------\n",
      "Train Error: loss: 591041216.000000, R^2: 0.8826\n",
      " Test Error: loss: 1010057792.000000, R^2: 0.8384\n",
      "\n",
      "Epoch 432\n",
      "--------------------------------\n",
      "Train Error: loss: 645113344.000000, R^2: 0.8956\n",
      " Test Error: loss: 976594560.000000, R^2: 0.8438\n",
      "\n",
      "Epoch 433\n",
      "--------------------------------\n",
      "Train Error: loss: 598568256.000000, R^2: 0.8885\n",
      " Test Error: loss: 1008377152.000000, R^2: 0.8387\n",
      "\n",
      "Epoch 434\n",
      "--------------------------------\n",
      "Train Error: loss: 618046400.000000, R^2: 0.9034\n",
      " Test Error: loss: 973335040.000000, R^2: 0.8443\n",
      "\n",
      "Epoch 435\n",
      "--------------------------------\n",
      "Train Error: loss: 593191744.000000, R^2: 0.8975\n",
      " Test Error: loss: 952183744.000000, R^2: 0.8477\n",
      "\n",
      "Epoch 436\n",
      "--------------------------------\n",
      "Train Error: loss: 660906176.000000, R^2: 0.8841\n",
      " Test Error: loss: 970891584.000000, R^2: 0.8447\n",
      "\n",
      "Epoch 437\n",
      "--------------------------------\n",
      "Train Error: loss: 681430720.000000, R^2: 0.8785\n",
      " Test Error: loss: 952099136.000000, R^2: 0.8477\n",
      "\n",
      "Epoch 438\n",
      "--------------------------------\n",
      "Train Error: loss: 611195264.000000, R^2: 0.9027\n",
      " Test Error: loss: 949240256.000000, R^2: 0.8482\n",
      "\n",
      "Epoch 439\n",
      "--------------------------------\n",
      "Train Error: loss: 612351424.000000, R^2: 0.8949\n",
      " Test Error: loss: 981122624.000000, R^2: 0.8431\n",
      "\n",
      "Epoch 440\n",
      "--------------------------------\n",
      "Train Error: loss: 598434112.000000, R^2: 0.9010\n",
      " Test Error: loss: 979253184.000000, R^2: 0.8434\n",
      "\n",
      "Epoch 441\n",
      "--------------------------------\n",
      "Train Error: loss: 540378048.000000, R^2: 0.9086\n",
      " Test Error: loss: 997977920.000000, R^2: 0.8404\n",
      "\n",
      "Epoch 442\n",
      "--------------------------------\n",
      "Train Error: loss: 644227776.000000, R^2: 0.8978\n",
      " Test Error: loss: 999478528.000000, R^2: 0.8401\n",
      "\n",
      "Epoch 443\n",
      "--------------------------------\n",
      "Train Error: loss: 590454400.000000, R^2: 0.8994\n",
      " Test Error: loss: 977970496.000000, R^2: 0.8436\n",
      "\n",
      "Epoch 444\n",
      "--------------------------------\n",
      "Train Error: loss: 613668864.000000, R^2: 0.9023\n",
      " Test Error: loss: 961265344.000000, R^2: 0.8462\n",
      "\n",
      "Epoch 445\n",
      "--------------------------------\n",
      "Train Error: loss: 734504128.000000, R^2: 0.8875\n",
      " Test Error: loss: 1001882304.000000, R^2: 0.8397\n",
      "\n",
      "Epoch 446\n",
      "--------------------------------\n",
      "Train Error: loss: 571011136.000000, R^2: 0.9097\n",
      " Test Error: loss: 1010794752.000000, R^2: 0.8383\n",
      "\n",
      "Epoch 447\n",
      "--------------------------------\n",
      "Train Error: loss: 803655552.000000, R^2: 0.8685\n",
      " Test Error: loss: 906953280.000000, R^2: 0.8549\n",
      "\n",
      "Epoch 448\n",
      "--------------------------------\n",
      "Train Error: loss: 660679616.000000, R^2: 0.8833\n",
      " Test Error: loss: 805338176.000000, R^2: 0.8712\n",
      "\n",
      "Epoch 449\n",
      "--------------------------------\n",
      "Train Error: loss: 574037952.000000, R^2: 0.9043\n",
      " Test Error: loss: 884382144.000000, R^2: 0.8585\n",
      "\n",
      "Epoch 450\n",
      "--------------------------------\n",
      "Train Error: loss: 627017344.000000, R^2: 0.8761\n",
      " Test Error: loss: 875053184.000000, R^2: 0.8600\n",
      "\n",
      "Epoch 451\n",
      "--------------------------------\n",
      "Train Error: loss: 604299072.000000, R^2: 0.9050\n",
      " Test Error: loss: 948331520.000000, R^2: 0.8483\n",
      "\n",
      "Epoch 452\n",
      "--------------------------------\n",
      "Train Error: loss: 948700992.000000, R^2: 0.8262\n",
      " Test Error: loss: 1005550400.000000, R^2: 0.8391\n",
      "\n",
      "Epoch 453\n",
      "--------------------------------\n",
      "Train Error: loss: 856346304.000000, R^2: 0.8593\n",
      " Test Error: loss: 934864960.000000, R^2: 0.8505\n",
      "\n",
      "Epoch 454\n",
      "--------------------------------\n",
      "Train Error: loss: 785004992.000000, R^2: 0.8788\n",
      " Test Error: loss: 987002816.000000, R^2: 0.8421\n",
      "\n",
      "Epoch 455\n",
      "--------------------------------\n",
      "Train Error: loss: 665482880.000000, R^2: 0.8762\n",
      " Test Error: loss: 926423296.000000, R^2: 0.8518\n",
      "\n",
      "Epoch 456\n",
      "--------------------------------\n",
      "Train Error: loss: 620029120.000000, R^2: 0.9008\n",
      " Test Error: loss: 920090304.000000, R^2: 0.8528\n",
      "\n",
      "Epoch 457\n",
      "--------------------------------\n",
      "Train Error: loss: 696720064.000000, R^2: 0.8847\n",
      " Test Error: loss: 947705088.000000, R^2: 0.8484\n",
      "\n",
      "Epoch 458\n",
      "--------------------------------\n",
      "Train Error: loss: 654430912.000000, R^2: 0.9071\n",
      " Test Error: loss: 934057856.000000, R^2: 0.8506\n",
      "\n",
      "Epoch 459\n",
      "--------------------------------\n",
      "Train Error: loss: 698195328.000000, R^2: 0.8816\n",
      " Test Error: loss: 962985856.000000, R^2: 0.8460\n",
      "\n",
      "Epoch 460\n",
      "--------------------------------\n",
      "Train Error: loss: 674313088.000000, R^2: 0.8719\n",
      " Test Error: loss: 892960320.000000, R^2: 0.8572\n",
      "\n",
      "Epoch 461\n",
      "--------------------------------\n",
      "Train Error: loss: 706056320.000000, R^2: 0.8741\n",
      " Test Error: loss: 896254208.000000, R^2: 0.8566\n",
      "\n",
      "Epoch 462\n",
      "--------------------------------\n",
      "Train Error: loss: 770185216.000000, R^2: 0.8853\n",
      " Test Error: loss: 1032669632.000000, R^2: 0.8348\n",
      "\n",
      "Epoch 463\n",
      "--------------------------------\n",
      "Train Error: loss: 661898688.000000, R^2: 0.8885\n",
      " Test Error: loss: 964741760.000000, R^2: 0.8457\n",
      "\n",
      "Epoch 464\n",
      "--------------------------------\n",
      "Train Error: loss: 563115200.000000, R^2: 0.8967\n",
      " Test Error: loss: 896751168.000000, R^2: 0.8565\n",
      "\n",
      "Epoch 465\n",
      "--------------------------------\n",
      "Train Error: loss: 606285312.000000, R^2: 0.8931\n",
      " Test Error: loss: 898430976.000000, R^2: 0.8563\n",
      "\n",
      "Epoch 466\n",
      "--------------------------------\n",
      "Train Error: loss: 633896960.000000, R^2: 0.9062\n",
      " Test Error: loss: 990599616.000000, R^2: 0.8415\n",
      "\n",
      "Epoch 467\n",
      "--------------------------------\n",
      "Train Error: loss: 753390784.000000, R^2: 0.8740\n",
      " Test Error: loss: 946111040.000000, R^2: 0.8487\n",
      "\n",
      "Epoch 468\n",
      "--------------------------------\n",
      "Train Error: loss: 697114240.000000, R^2: 0.8839\n",
      " Test Error: loss: 922437248.000000, R^2: 0.8524\n",
      "\n",
      "Epoch 469\n",
      "--------------------------------\n",
      "Train Error: loss: 571979712.000000, R^2: 0.9022\n",
      " Test Error: loss: 880297536.000000, R^2: 0.8592\n",
      "\n",
      "Epoch 470\n",
      "--------------------------------\n",
      "Train Error: loss: 620786176.000000, R^2: 0.8950\n",
      " Test Error: loss: 919274944.000000, R^2: 0.8529\n",
      "\n",
      "Epoch 471\n",
      "--------------------------------\n",
      "Train Error: loss: 603898624.000000, R^2: 0.9101\n",
      " Test Error: loss: 1017652416.000000, R^2: 0.8372\n",
      "\n",
      "Epoch 472\n",
      "--------------------------------\n",
      "Train Error: loss: 583046208.000000, R^2: 0.9057\n",
      " Test Error: loss: 1070151040.000000, R^2: 0.8288\n",
      "\n",
      "Epoch 473\n",
      "--------------------------------\n",
      "Train Error: loss: 599661184.000000, R^2: 0.9014\n",
      " Test Error: loss: 991034048.000000, R^2: 0.8415\n",
      "\n",
      "Epoch 474\n",
      "--------------------------------\n",
      "Train Error: loss: 695047488.000000, R^2: 0.8791\n",
      " Test Error: loss: 935497024.000000, R^2: 0.8504\n",
      "\n",
      "Epoch 475\n",
      "--------------------------------\n",
      "Train Error: loss: 589092800.000000, R^2: 0.9001\n",
      " Test Error: loss: 896113664.000000, R^2: 0.8567\n",
      "\n",
      "Epoch 476\n",
      "--------------------------------\n",
      "Train Error: loss: 556396160.000000, R^2: 0.8890\n",
      " Test Error: loss: 876595072.000000, R^2: 0.8598\n",
      "\n",
      "Epoch 477\n",
      "--------------------------------\n",
      "Train Error: loss: 556469952.000000, R^2: 0.9013\n",
      " Test Error: loss: 933320832.000000, R^2: 0.8507\n",
      "\n",
      "Epoch 478\n",
      "--------------------------------\n",
      "Train Error: loss: 541678848.000000, R^2: 0.9091\n",
      " Test Error: loss: 932648896.000000, R^2: 0.8508\n",
      "\n",
      "Epoch 479\n",
      "--------------------------------\n",
      "Train Error: loss: 556441216.000000, R^2: 0.8996\n",
      " Test Error: loss: 911230272.000000, R^2: 0.8542\n",
      "\n",
      "Epoch 480\n",
      "--------------------------------\n",
      "Train Error: loss: 557676672.000000, R^2: 0.9122\n",
      " Test Error: loss: 919840000.000000, R^2: 0.8529\n",
      "\n",
      "Epoch 481\n",
      "--------------------------------\n",
      "Train Error: loss: 671165056.000000, R^2: 0.8787\n",
      " Test Error: loss: 874317504.000000, R^2: 0.8601\n",
      "\n",
      "Epoch 482\n",
      "--------------------------------\n",
      "Train Error: loss: 654213440.000000, R^2: 0.8925\n",
      " Test Error: loss: 839614592.000000, R^2: 0.8657\n",
      "\n",
      "Epoch 483\n",
      "--------------------------------\n",
      "Train Error: loss: 540835008.000000, R^2: 0.9077\n",
      " Test Error: loss: 856910016.000000, R^2: 0.8629\n",
      "\n",
      "Epoch 484\n",
      "--------------------------------\n",
      "Train Error: loss: 562258304.000000, R^2: 0.9067\n",
      " Test Error: loss: 885331968.000000, R^2: 0.8584\n",
      "\n",
      "Epoch 485\n",
      "--------------------------------\n",
      "Train Error: loss: 584151552.000000, R^2: 0.9032\n",
      " Test Error: loss: 879987200.000000, R^2: 0.8592\n",
      "\n",
      "Epoch 486\n",
      "--------------------------------\n",
      "Train Error: loss: 629569472.000000, R^2: 0.8999\n",
      " Test Error: loss: 972243648.000000, R^2: 0.8445\n",
      "\n",
      "Epoch 487\n",
      "--------------------------------\n",
      "Train Error: loss: 570364480.000000, R^2: 0.9004\n",
      " Test Error: loss: 940939840.000000, R^2: 0.8495\n",
      "\n",
      "Epoch 488\n",
      "--------------------------------\n",
      "Train Error: loss: 645693888.000000, R^2: 0.8858\n",
      " Test Error: loss: 906918720.000000, R^2: 0.8549\n",
      "\n",
      "Epoch 489\n",
      "--------------------------------\n",
      "Train Error: loss: 547749504.000000, R^2: 0.9034\n",
      " Test Error: loss: 854189376.000000, R^2: 0.8634\n",
      "\n",
      "Epoch 490\n",
      "--------------------------------\n",
      "Train Error: loss: 569699520.000000, R^2: 0.9060\n",
      " Test Error: loss: 896884992.000000, R^2: 0.8565\n",
      "\n",
      "Epoch 491\n",
      "--------------------------------\n",
      "Train Error: loss: 593419136.000000, R^2: 0.9045\n",
      " Test Error: loss: 897779328.000000, R^2: 0.8564\n",
      "\n",
      "Epoch 492\n",
      "--------------------------------\n",
      "Train Error: loss: 507464352.000000, R^2: 0.9034\n",
      " Test Error: loss: 956714048.000000, R^2: 0.8470\n",
      "\n",
      "Epoch 493\n",
      "--------------------------------\n",
      "Train Error: loss: 552723200.000000, R^2: 0.9016\n",
      " Test Error: loss: 965671168.000000, R^2: 0.8455\n",
      "\n",
      "Epoch 494\n",
      "--------------------------------\n",
      "Train Error: loss: 608811712.000000, R^2: 0.8931\n",
      " Test Error: loss: 944107328.000000, R^2: 0.8490\n",
      "\n",
      "Epoch 495\n",
      "--------------------------------\n",
      "Train Error: loss: 565973568.000000, R^2: 0.9078\n",
      " Test Error: loss: 962161152.000000, R^2: 0.8461\n",
      "\n",
      "Epoch 496\n",
      "--------------------------------\n",
      "Train Error: loss: 735641216.000000, R^2: 0.8664\n",
      " Test Error: loss: 907886720.000000, R^2: 0.8548\n",
      "\n",
      "Epoch 497\n",
      "--------------------------------\n",
      "Train Error: loss: 557586048.000000, R^2: 0.9000\n",
      " Test Error: loss: 865676032.000000, R^2: 0.8615\n",
      "\n",
      "Epoch 498\n",
      "--------------------------------\n",
      "Train Error: loss: 592165568.000000, R^2: 0.8984\n",
      " Test Error: loss: 863296768.000000, R^2: 0.8619\n",
      "\n",
      "Epoch 499\n",
      "--------------------------------\n",
      "Train Error: loss: 560830848.000000, R^2: 0.9090\n",
      " Test Error: loss: 889809024.000000, R^2: 0.8577\n",
      "\n",
      "Epoch 500\n",
      "--------------------------------\n",
      "Train Error: loss: 542449408.000000, R^2: 0.9101\n",
      " Test Error: loss: 915129536.000000, R^2: 0.8536\n",
      "\n",
      "Epoch 501\n",
      "--------------------------------\n",
      "Train Error: loss: 536169888.000000, R^2: 0.9101\n",
      " Test Error: loss: 929904832.000000, R^2: 0.8512\n",
      "\n",
      "Epoch 502\n",
      "--------------------------------\n",
      "Train Error: loss: 646189056.000000, R^2: 0.9034\n",
      " Test Error: loss: 917100096.000000, R^2: 0.8533\n",
      "\n",
      "Epoch 503\n",
      "--------------------------------\n",
      "Train Error: loss: 573004800.000000, R^2: 0.9023\n",
      " Test Error: loss: 889360512.000000, R^2: 0.8577\n",
      "\n",
      "Epoch 504\n",
      "--------------------------------\n",
      "Train Error: loss: 571695232.000000, R^2: 0.8921\n",
      " Test Error: loss: 852364608.000000, R^2: 0.8637\n",
      "\n",
      "Epoch 505\n",
      "--------------------------------\n",
      "Train Error: loss: 615825344.000000, R^2: 0.8958\n",
      " Test Error: loss: 898935488.000000, R^2: 0.8562\n",
      "\n",
      "Epoch 506\n",
      "--------------------------------\n",
      "Train Error: loss: 641738048.000000, R^2: 0.9017\n",
      " Test Error: loss: 892099392.000000, R^2: 0.8573\n",
      "\n",
      "Epoch 507\n",
      "--------------------------------\n",
      "Train Error: loss: 732353216.000000, R^2: 0.8961\n",
      " Test Error: loss: 808012160.000000, R^2: 0.8707\n",
      "\n",
      "Epoch 508\n",
      "--------------------------------\n",
      "Train Error: loss: 644187264.000000, R^2: 0.8881\n",
      " Test Error: loss: 796047232.000000, R^2: 0.8727\n",
      "\n",
      "Epoch 509\n",
      "--------------------------------\n",
      "Train Error: loss: 597831104.000000, R^2: 0.9006\n",
      " Test Error: loss: 779092096.000000, R^2: 0.8754\n",
      "\n",
      "Epoch 510\n",
      "--------------------------------\n",
      "Train Error: loss: 567603072.000000, R^2: 0.8982\n",
      " Test Error: loss: 899389952.000000, R^2: 0.8561\n",
      "\n",
      "Epoch 511\n",
      "--------------------------------\n",
      "Train Error: loss: 596573376.000000, R^2: 0.8858\n",
      " Test Error: loss: 874419456.000000, R^2: 0.8601\n",
      "\n",
      "Epoch 512\n",
      "--------------------------------\n",
      "Train Error: loss: 744630592.000000, R^2: 0.9018\n",
      " Test Error: loss: 893752000.000000, R^2: 0.8570\n",
      "\n",
      "Epoch 513\n",
      "--------------------------------\n",
      "Train Error: loss: 675952448.000000, R^2: 0.8868\n",
      " Test Error: loss: 895260672.000000, R^2: 0.8568\n",
      "\n",
      "Epoch 514\n",
      "--------------------------------\n",
      "Train Error: loss: 567535744.000000, R^2: 0.9067\n",
      " Test Error: loss: 906728512.000000, R^2: 0.8550\n",
      "\n",
      "Epoch 515\n",
      "--------------------------------\n",
      "Train Error: loss: 707833664.000000, R^2: 0.8948\n",
      " Test Error: loss: 847174976.000000, R^2: 0.8645\n",
      "\n",
      "Epoch 516\n",
      "--------------------------------\n",
      "Train Error: loss: 572494976.000000, R^2: 0.8952\n",
      " Test Error: loss: 895033216.000000, R^2: 0.8568\n",
      "\n",
      "Epoch 517\n",
      "--------------------------------\n",
      "Train Error: loss: 674272064.000000, R^2: 0.8750\n",
      " Test Error: loss: 866914560.000000, R^2: 0.8613\n",
      "\n",
      "Epoch 518\n",
      "--------------------------------\n",
      "Train Error: loss: 656716224.000000, R^2: 0.9001\n",
      " Test Error: loss: 878351872.000000, R^2: 0.8595\n",
      "\n",
      "Epoch 519\n",
      "--------------------------------\n",
      "Train Error: loss: 595904192.000000, R^2: 0.8993\n",
      " Test Error: loss: 899775360.000000, R^2: 0.8561\n",
      "\n",
      "Epoch 520\n",
      "--------------------------------\n",
      "Train Error: loss: 566973440.000000, R^2: 0.9039\n",
      " Test Error: loss: 819320640.000000, R^2: 0.8689\n",
      "\n",
      "Epoch 521\n",
      "--------------------------------\n",
      "Train Error: loss: 738218304.000000, R^2: 0.8718\n",
      " Test Error: loss: 754219904.000000, R^2: 0.8794\n",
      "\n",
      "Epoch 522\n",
      "--------------------------------\n",
      "Train Error: loss: 612988224.000000, R^2: 0.8986\n",
      " Test Error: loss: 770310912.000000, R^2: 0.8768\n",
      "\n",
      "Epoch 523\n",
      "--------------------------------\n",
      "Train Error: loss: 602318400.000000, R^2: 0.8993\n",
      " Test Error: loss: 855031168.000000, R^2: 0.8632\n",
      "\n",
      "Epoch 524\n",
      "--------------------------------\n",
      "Train Error: loss: 603320832.000000, R^2: 0.8992\n",
      " Test Error: loss: 907109824.000000, R^2: 0.8549\n",
      "\n",
      "Epoch 525\n",
      "--------------------------------\n",
      "Train Error: loss: 755805696.000000, R^2: 0.8844\n",
      " Test Error: loss: 869377984.000000, R^2: 0.8609\n",
      "\n",
      "Epoch 526\n",
      "--------------------------------\n",
      "Train Error: loss: 696659392.000000, R^2: 0.8823\n",
      " Test Error: loss: 831739648.000000, R^2: 0.8669\n",
      "\n",
      "Epoch 527\n",
      "--------------------------------\n",
      "Train Error: loss: 591980096.000000, R^2: 0.8981\n",
      " Test Error: loss: 872844224.000000, R^2: 0.8604\n",
      "\n",
      "Epoch 528\n",
      "--------------------------------\n",
      "Train Error: loss: 689622272.000000, R^2: 0.8847\n",
      " Test Error: loss: 820136512.000000, R^2: 0.8688\n",
      "\n",
      "Epoch 529\n",
      "--------------------------------\n",
      "Train Error: loss: 543112576.000000, R^2: 0.9119\n",
      " Test Error: loss: 812900096.000000, R^2: 0.8700\n",
      "\n",
      "Epoch 530\n",
      "--------------------------------\n",
      "Train Error: loss: 556028608.000000, R^2: 0.9094\n",
      " Test Error: loss: 813645888.000000, R^2: 0.8698\n",
      "\n",
      "Epoch 531\n",
      "--------------------------------\n",
      "Train Error: loss: 481677632.000000, R^2: 0.9206\n",
      " Test Error: loss: 868411264.000000, R^2: 0.8611\n",
      "\n",
      "Epoch 532\n",
      "--------------------------------\n",
      "Train Error: loss: 560978368.000000, R^2: 0.9083\n",
      " Test Error: loss: 829965824.000000, R^2: 0.8672\n",
      "\n",
      "Epoch 533\n",
      "--------------------------------\n",
      "Train Error: loss: 548286464.000000, R^2: 0.9087\n",
      " Test Error: loss: 824381056.000000, R^2: 0.8681\n",
      "\n",
      "Epoch 534\n",
      "--------------------------------\n",
      "Train Error: loss: 567090304.000000, R^2: 0.9063\n",
      " Test Error: loss: 789539264.000000, R^2: 0.8737\n",
      "\n",
      "Epoch 535\n",
      "--------------------------------\n",
      "Train Error: loss: 568697920.000000, R^2: 0.9021\n",
      " Test Error: loss: 795621184.000000, R^2: 0.8727\n",
      "\n",
      "Epoch 536\n",
      "--------------------------------\n",
      "Train Error: loss: 647689856.000000, R^2: 0.9023\n",
      " Test Error: loss: 867148224.000000, R^2: 0.8613\n",
      "\n",
      "Epoch 537\n",
      "--------------------------------\n",
      "Train Error: loss: 557670400.000000, R^2: 0.9018\n",
      " Test Error: loss: 1129220096.000000, R^2: 0.8194\n",
      "\n",
      "Epoch 538\n",
      "--------------------------------\n",
      "Train Error: loss: 1039953856.000000, R^2: 0.8540\n",
      " Test Error: loss: 922561472.000000, R^2: 0.8524\n",
      "\n",
      "Epoch 539\n",
      "--------------------------------\n",
      "Train Error: loss: 735760128.000000, R^2: 0.8594\n",
      " Test Error: loss: 817194432.000000, R^2: 0.8693\n",
      "\n",
      "Epoch 540\n",
      "--------------------------------\n",
      "Train Error: loss: 617057024.000000, R^2: 0.8946\n",
      " Test Error: loss: 834583424.000000, R^2: 0.8665\n",
      "\n",
      "Epoch 541\n",
      "--------------------------------\n",
      "Train Error: loss: 592160448.000000, R^2: 0.9004\n",
      " Test Error: loss: 850287744.000000, R^2: 0.8640\n",
      "\n",
      "Epoch 542\n",
      "--------------------------------\n",
      "Train Error: loss: 611822464.000000, R^2: 0.9040\n",
      " Test Error: loss: 831679040.000000, R^2: 0.8670\n",
      "\n",
      "Epoch 543\n",
      "--------------------------------\n",
      "Train Error: loss: 578979904.000000, R^2: 0.9030\n",
      " Test Error: loss: 851756160.000000, R^2: 0.8637\n",
      "\n",
      "Epoch 544\n",
      "--------------------------------\n",
      "Train Error: loss: 562264128.000000, R^2: 0.8777\n",
      " Test Error: loss: 786712000.000000, R^2: 0.8742\n",
      "\n",
      "Epoch 545\n",
      "--------------------------------\n",
      "Train Error: loss: 674737856.000000, R^2: 0.8891\n",
      " Test Error: loss: 741287488.000000, R^2: 0.8814\n",
      "\n",
      "Epoch 546\n",
      "--------------------------------\n",
      "Train Error: loss: 537298112.000000, R^2: 0.9086\n",
      " Test Error: loss: 759450624.000000, R^2: 0.8785\n",
      "\n",
      "Epoch 547\n",
      "--------------------------------\n",
      "Train Error: loss: 512745376.000000, R^2: 0.9186\n",
      " Test Error: loss: 776021952.000000, R^2: 0.8759\n",
      "\n",
      "Epoch 548\n",
      "--------------------------------\n",
      "Train Error: loss: 489822016.000000, R^2: 0.9157\n",
      " Test Error: loss: 790981568.000000, R^2: 0.8735\n",
      "\n",
      "Epoch 549\n",
      "--------------------------------\n",
      "Train Error: loss: 603921728.000000, R^2: 0.9058\n",
      " Test Error: loss: 856328192.000000, R^2: 0.8630\n",
      "\n",
      "Epoch 550\n",
      "--------------------------------\n",
      "Train Error: loss: 576105152.000000, R^2: 0.8874\n",
      " Test Error: loss: 784449920.000000, R^2: 0.8745\n",
      "\n",
      "Epoch 551\n",
      "--------------------------------\n",
      "Train Error: loss: 555589952.000000, R^2: 0.9064\n",
      " Test Error: loss: 778555648.000000, R^2: 0.8755\n",
      "\n",
      "Epoch 552\n",
      "--------------------------------\n",
      "Train Error: loss: 577680832.000000, R^2: 0.9066\n",
      " Test Error: loss: 723662400.000000, R^2: 0.8842\n",
      "\n",
      "Epoch 553\n",
      "--------------------------------\n",
      "Train Error: loss: 479014048.000000, R^2: 0.9171\n",
      " Test Error: loss: 743021632.000000, R^2: 0.8811\n",
      "\n",
      "Epoch 554\n",
      "--------------------------------\n",
      "Train Error: loss: 574333120.000000, R^2: 0.9081\n",
      " Test Error: loss: 834069184.000000, R^2: 0.8666\n",
      "\n",
      "Epoch 555\n",
      "--------------------------------\n",
      "Train Error: loss: 536305056.000000, R^2: 0.9150\n",
      " Test Error: loss: 808967168.000000, R^2: 0.8706\n",
      "\n",
      "Epoch 556\n",
      "--------------------------------\n",
      "Train Error: loss: 692889472.000000, R^2: 0.8914\n",
      " Test Error: loss: 815175168.000000, R^2: 0.8696\n",
      "\n",
      "Epoch 557\n",
      "--------------------------------\n",
      "Train Error: loss: 679491392.000000, R^2: 0.8860\n",
      " Test Error: loss: 739108544.000000, R^2: 0.8818\n",
      "\n",
      "Epoch 558\n",
      "--------------------------------\n",
      "Train Error: loss: 650478336.000000, R^2: 0.8896\n",
      " Test Error: loss: 758653056.000000, R^2: 0.8786\n",
      "\n",
      "Epoch 559\n",
      "--------------------------------\n",
      "Train Error: loss: 538921856.000000, R^2: 0.9080\n",
      " Test Error: loss: 788952064.000000, R^2: 0.8738\n",
      "\n",
      "Epoch 560\n",
      "--------------------------------\n",
      "Train Error: loss: 560769984.000000, R^2: 0.8931\n",
      " Test Error: loss: 843216448.000000, R^2: 0.8651\n",
      "\n",
      "Epoch 561\n",
      "--------------------------------\n",
      "Train Error: loss: 724519232.000000, R^2: 0.8773\n",
      " Test Error: loss: 811662464.000000, R^2: 0.8702\n",
      "\n",
      "Epoch 562\n",
      "--------------------------------\n",
      "Train Error: loss: 530722048.000000, R^2: 0.9072\n",
      " Test Error: loss: 758746560.000000, R^2: 0.8786\n",
      "\n",
      "Epoch 563\n",
      "--------------------------------\n",
      "Train Error: loss: 581783744.000000, R^2: 0.9038\n",
      " Test Error: loss: 743761408.000000, R^2: 0.8810\n",
      "\n",
      "Epoch 564\n",
      "--------------------------------\n",
      "Train Error: loss: 543611904.000000, R^2: 0.9004\n",
      " Test Error: loss: 771544384.000000, R^2: 0.8766\n",
      "\n",
      "Epoch 565\n",
      "--------------------------------\n",
      "Train Error: loss: 578132928.000000, R^2: 0.9042\n",
      " Test Error: loss: 743461440.000000, R^2: 0.8811\n",
      "\n",
      "Epoch 566\n",
      "--------------------------------\n",
      "Train Error: loss: 553106752.000000, R^2: 0.9109\n",
      " Test Error: loss: 741495744.000000, R^2: 0.8814\n",
      "\n",
      "Epoch 567\n",
      "--------------------------------\n",
      "Train Error: loss: 625632128.000000, R^2: 0.8955\n",
      " Test Error: loss: 703641664.000000, R^2: 0.8874\n",
      "\n",
      "Epoch 568\n",
      "--------------------------------\n",
      "Train Error: loss: 625373376.000000, R^2: 0.8820\n",
      " Test Error: loss: 713310336.000000, R^2: 0.8859\n",
      "\n",
      "Epoch 569\n",
      "--------------------------------\n",
      "Train Error: loss: 676117440.000000, R^2: 0.8890\n",
      " Test Error: loss: 698425984.000000, R^2: 0.8883\n",
      "\n",
      "Epoch 570\n",
      "--------------------------------\n",
      "Train Error: loss: 608368576.000000, R^2: 0.8938\n",
      " Test Error: loss: 685844032.000000, R^2: 0.8903\n",
      "\n",
      "Epoch 571\n",
      "--------------------------------\n",
      "Train Error: loss: 647852480.000000, R^2: 0.8899\n",
      " Test Error: loss: 756005312.000000, R^2: 0.8791\n",
      "\n",
      "Epoch 572\n",
      "--------------------------------\n",
      "Train Error: loss: 540342976.000000, R^2: 0.9094\n",
      " Test Error: loss: 782715328.000000, R^2: 0.8748\n",
      "\n",
      "Epoch 573\n",
      "--------------------------------\n",
      "Train Error: loss: 639929536.000000, R^2: 0.8969\n",
      " Test Error: loss: 757918336.000000, R^2: 0.8788\n",
      "\n",
      "Epoch 574\n",
      "--------------------------------\n",
      "Train Error: loss: 642072320.000000, R^2: 0.8918\n",
      " Test Error: loss: 711568320.000000, R^2: 0.8862\n",
      "\n",
      "Epoch 575\n",
      "--------------------------------\n",
      "Train Error: loss: 497059328.000000, R^2: 0.9162\n",
      " Test Error: loss: 726054400.000000, R^2: 0.8839\n",
      "\n",
      "Epoch 576\n",
      "--------------------------------\n",
      "Train Error: loss: 584558912.000000, R^2: 0.8998\n",
      " Test Error: loss: 698799488.000000, R^2: 0.8882\n",
      "\n",
      "Epoch 577\n",
      "--------------------------------\n",
      "Train Error: loss: 610022400.000000, R^2: 0.9082\n",
      " Test Error: loss: 708293568.000000, R^2: 0.8867\n",
      "\n",
      "Epoch 578\n",
      "--------------------------------\n",
      "Train Error: loss: 555163584.000000, R^2: 0.8760\n",
      " Test Error: loss: 756271168.000000, R^2: 0.8790\n",
      "\n",
      "Epoch 579\n",
      "--------------------------------\n",
      "Train Error: loss: 546688064.000000, R^2: 0.9072\n",
      " Test Error: loss: 715026624.000000, R^2: 0.8856\n",
      "\n",
      "Epoch 580\n",
      "--------------------------------\n",
      "Train Error: loss: 522198496.000000, R^2: 0.9118\n",
      " Test Error: loss: 705046912.000000, R^2: 0.8872\n",
      "\n",
      "Epoch 581\n",
      "--------------------------------\n",
      "Train Error: loss: 551976128.000000, R^2: 0.9072\n",
      " Test Error: loss: 747385664.000000, R^2: 0.8804\n",
      "\n",
      "Epoch 582\n",
      "--------------------------------\n",
      "Train Error: loss: 574190848.000000, R^2: 0.9077\n",
      " Test Error: loss: 828082048.000000, R^2: 0.8675\n",
      "\n",
      "Epoch 583\n",
      "--------------------------------\n",
      "Train Error: loss: 525851104.000000, R^2: 0.9032\n",
      " Test Error: loss: 814986688.000000, R^2: 0.8696\n",
      "\n",
      "Epoch 584\n",
      "--------------------------------\n",
      "Train Error: loss: 570169728.000000, R^2: 0.9005\n",
      " Test Error: loss: 802955968.000000, R^2: 0.8716\n",
      "\n",
      "Epoch 585\n",
      "--------------------------------\n",
      "Train Error: loss: 533201664.000000, R^2: 0.9111\n",
      " Test Error: loss: 776738816.000000, R^2: 0.8757\n",
      "\n",
      "Epoch 586\n",
      "--------------------------------\n",
      "Train Error: loss: 573213568.000000, R^2: 0.9050\n",
      " Test Error: loss: 808361856.000000, R^2: 0.8707\n",
      "\n",
      "Epoch 587\n",
      "--------------------------------\n",
      "Train Error: loss: 517123296.000000, R^2: 0.9089\n",
      " Test Error: loss: 828978688.000000, R^2: 0.8674\n",
      "\n",
      "Epoch 588\n",
      "--------------------------------\n",
      "Train Error: loss: 545625920.000000, R^2: 0.9068\n",
      " Test Error: loss: 807839552.000000, R^2: 0.8708\n",
      "\n",
      "Epoch 589\n",
      "--------------------------------\n",
      "Train Error: loss: 520580512.000000, R^2: 0.8909\n",
      " Test Error: loss: 830386496.000000, R^2: 0.8672\n",
      "\n",
      "Epoch 590\n",
      "--------------------------------\n",
      "Train Error: loss: 548025152.000000, R^2: 0.8982\n",
      " Test Error: loss: 793784320.000000, R^2: 0.8730\n",
      "\n",
      "Epoch 591\n",
      "--------------------------------\n",
      "Train Error: loss: 628593472.000000, R^2: 0.8910\n",
      " Test Error: loss: 755859328.000000, R^2: 0.8791\n",
      "\n",
      "Epoch 592\n",
      "--------------------------------\n",
      "Train Error: loss: 516046688.000000, R^2: 0.9078\n",
      " Test Error: loss: 738050048.000000, R^2: 0.8819\n",
      "\n",
      "Epoch 593\n",
      "--------------------------------\n",
      "Train Error: loss: 591505856.000000, R^2: 0.8935\n",
      " Test Error: loss: 739796736.000000, R^2: 0.8817\n",
      "\n",
      "Epoch 594\n",
      "--------------------------------\n",
      "Train Error: loss: 561001344.000000, R^2: 0.9063\n",
      " Test Error: loss: 799301504.000000, R^2: 0.8721\n",
      "\n",
      "Epoch 595\n",
      "--------------------------------\n",
      "Train Error: loss: 581894848.000000, R^2: 0.9017\n",
      " Test Error: loss: 774665152.000000, R^2: 0.8761\n",
      "\n",
      "Epoch 596\n",
      "--------------------------------\n",
      "Train Error: loss: 569113728.000000, R^2: 0.9093\n",
      " Test Error: loss: 757196480.000000, R^2: 0.8789\n",
      "\n",
      "Epoch 597\n",
      "--------------------------------\n",
      "Train Error: loss: 608546816.000000, R^2: 0.8866\n",
      " Test Error: loss: 779358272.000000, R^2: 0.8753\n",
      "\n",
      "Epoch 598\n",
      "--------------------------------\n",
      "Train Error: loss: 589333952.000000, R^2: 0.8950\n",
      " Test Error: loss: 764730688.000000, R^2: 0.8777\n",
      "\n",
      "Epoch 599\n",
      "--------------------------------\n",
      "Train Error: loss: 565268928.000000, R^2: 0.8935\n",
      " Test Error: loss: 773444736.000000, R^2: 0.8763\n",
      "\n",
      "Epoch 600\n",
      "--------------------------------\n",
      "Train Error: loss: 542436416.000000, R^2: 0.9120\n",
      " Test Error: loss: 882516672.000000, R^2: 0.8588\n",
      "\n",
      "Epoch 601\n",
      "--------------------------------\n",
      "Train Error: loss: 575814784.000000, R^2: 0.9032\n",
      " Test Error: loss: 802265216.000000, R^2: 0.8717\n",
      "\n",
      "Epoch 602\n",
      "--------------------------------\n",
      "Train Error: loss: 646834880.000000, R^2: 0.8950\n",
      " Test Error: loss: 726369280.000000, R^2: 0.8838\n",
      "\n",
      "Epoch 603\n",
      "--------------------------------\n",
      "Train Error: loss: 488475040.000000, R^2: 0.9160\n",
      " Test Error: loss: 696367232.000000, R^2: 0.8886\n",
      "\n",
      "Epoch 604\n",
      "--------------------------------\n",
      "Train Error: loss: 595264960.000000, R^2: 0.8910\n",
      " Test Error: loss: 692459648.000000, R^2: 0.8892\n",
      "\n",
      "Epoch 605\n",
      "--------------------------------\n",
      "Train Error: loss: 481339712.000000, R^2: 0.9234\n",
      " Test Error: loss: 736180608.000000, R^2: 0.8822\n",
      "\n",
      "Epoch 606\n",
      "--------------------------------\n",
      "Train Error: loss: 537815488.000000, R^2: 0.9001\n",
      " Test Error: loss: 772156608.000000, R^2: 0.8765\n",
      "\n",
      "Epoch 607\n",
      "--------------------------------\n",
      "Train Error: loss: 509232032.000000, R^2: 0.9035\n",
      " Test Error: loss: 769579904.000000, R^2: 0.8769\n",
      "\n",
      "Epoch 608\n",
      "--------------------------------\n",
      "Train Error: loss: 609078272.000000, R^2: 0.8891\n",
      " Test Error: loss: 761472128.000000, R^2: 0.8782\n",
      "\n",
      "Epoch 609\n",
      "--------------------------------\n",
      "Train Error: loss: 567797376.000000, R^2: 0.9052\n",
      " Test Error: loss: 740535168.000000, R^2: 0.8815\n",
      "\n",
      "Epoch 610\n",
      "--------------------------------\n",
      "Train Error: loss: 523515360.000000, R^2: 0.8985\n",
      " Test Error: loss: 732444160.000000, R^2: 0.8828\n",
      "\n",
      "Epoch 611\n",
      "--------------------------------\n",
      "Train Error: loss: 548017088.000000, R^2: 0.9049\n",
      " Test Error: loss: 755309440.000000, R^2: 0.8792\n",
      "\n",
      "Epoch 612\n",
      "--------------------------------\n",
      "Train Error: loss: 595929280.000000, R^2: 0.8961\n",
      " Test Error: loss: 740318528.000000, R^2: 0.8816\n",
      "\n",
      "Epoch 613\n",
      "--------------------------------\n",
      "Train Error: loss: 601186560.000000, R^2: 0.8969\n",
      " Test Error: loss: 746161920.000000, R^2: 0.8806\n",
      "\n",
      "Epoch 614\n",
      "--------------------------------\n",
      "Train Error: loss: 545702592.000000, R^2: 0.9090\n",
      " Test Error: loss: 804057856.000000, R^2: 0.8714\n",
      "\n",
      "Epoch 615\n",
      "--------------------------------\n",
      "Train Error: loss: 545810432.000000, R^2: 0.9072\n",
      " Test Error: loss: 780511360.000000, R^2: 0.8751\n",
      "\n",
      "Epoch 616\n",
      "--------------------------------\n",
      "Train Error: loss: 570636224.000000, R^2: 0.8978\n",
      " Test Error: loss: 773521152.000000, R^2: 0.8763\n",
      "\n",
      "Epoch 617\n",
      "--------------------------------\n",
      "Train Error: loss: 549969088.000000, R^2: 0.8897\n",
      " Test Error: loss: 757976832.000000, R^2: 0.8787\n",
      "\n",
      "Epoch 618\n",
      "--------------------------------\n",
      "Train Error: loss: 515620416.000000, R^2: 0.9171\n",
      " Test Error: loss: 773008640.000000, R^2: 0.8763\n",
      "\n",
      "Epoch 619\n",
      "--------------------------------\n",
      "Train Error: loss: 514230848.000000, R^2: 0.9005\n",
      " Test Error: loss: 761126016.000000, R^2: 0.8782\n",
      "\n",
      "Epoch 620\n",
      "--------------------------------\n",
      "Train Error: loss: 546026752.000000, R^2: 0.9061\n",
      " Test Error: loss: 786200064.000000, R^2: 0.8742\n",
      "\n",
      "Epoch 621\n",
      "--------------------------------\n",
      "Train Error: loss: 567959616.000000, R^2: 0.9042\n",
      " Test Error: loss: 835751168.000000, R^2: 0.8663\n",
      "\n",
      "Epoch 622\n",
      "--------------------------------\n",
      "Train Error: loss: 533110848.000000, R^2: 0.8970\n",
      " Test Error: loss: 818436800.000000, R^2: 0.8691\n",
      "\n",
      "Epoch 623\n",
      "--------------------------------\n",
      "Train Error: loss: 628837696.000000, R^2: 0.9021\n",
      " Test Error: loss: 833252992.000000, R^2: 0.8667\n",
      "\n",
      "Epoch 624\n",
      "--------------------------------\n",
      "Train Error: loss: 585934784.000000, R^2: 0.8965\n",
      " Test Error: loss: 755005888.000000, R^2: 0.8792\n",
      "\n",
      "Epoch 625\n",
      "--------------------------------\n",
      "Train Error: loss: 613045568.000000, R^2: 0.9026\n",
      " Test Error: loss: 740888320.000000, R^2: 0.8815\n",
      "\n",
      "Epoch 626\n",
      "--------------------------------\n",
      "Train Error: loss: 513636352.000000, R^2: 0.9156\n",
      " Test Error: loss: 751893056.000000, R^2: 0.8797\n",
      "\n",
      "Epoch 627\n",
      "--------------------------------\n",
      "Train Error: loss: 507788288.000000, R^2: 0.9038\n",
      " Test Error: loss: 726978752.000000, R^2: 0.8837\n",
      "\n",
      "Epoch 628\n",
      "--------------------------------\n",
      "Train Error: loss: 632781376.000000, R^2: 0.8989\n",
      " Test Error: loss: 709892800.000000, R^2: 0.8864\n",
      "\n",
      "Epoch 629\n",
      "--------------------------------\n",
      "Train Error: loss: 535002432.000000, R^2: 0.9031\n",
      " Test Error: loss: 759980160.000000, R^2: 0.8784\n",
      "\n",
      "Epoch 630\n",
      "--------------------------------\n",
      "Train Error: loss: 661378368.000000, R^2: 0.8902\n",
      " Test Error: loss: 713592256.000000, R^2: 0.8858\n",
      "\n",
      "Epoch 631\n",
      "--------------------------------\n",
      "Train Error: loss: 632553152.000000, R^2: 0.8937\n",
      " Test Error: loss: 686734016.000000, R^2: 0.8901\n",
      "\n",
      "Epoch 632\n",
      "--------------------------------\n",
      "Train Error: loss: 622990400.000000, R^2: 0.8986\n",
      " Test Error: loss: 734827712.000000, R^2: 0.8825\n",
      "\n",
      "Epoch 633\n",
      "--------------------------------\n",
      "Train Error: loss: 532768768.000000, R^2: 0.9021\n",
      " Test Error: loss: 719280832.000000, R^2: 0.8849\n",
      "\n",
      "Epoch 634\n",
      "--------------------------------\n",
      "Train Error: loss: 589321856.000000, R^2: 0.8969\n",
      " Test Error: loss: 742394368.000000, R^2: 0.8812\n",
      "\n",
      "Epoch 635\n",
      "--------------------------------\n",
      "Train Error: loss: 495833696.000000, R^2: 0.9199\n",
      " Test Error: loss: 733394752.000000, R^2: 0.8827\n",
      "\n",
      "Epoch 636\n",
      "--------------------------------\n",
      "Train Error: loss: 522894176.000000, R^2: 0.9154\n",
      " Test Error: loss: 752867904.000000, R^2: 0.8796\n",
      "\n",
      "Epoch 637\n",
      "--------------------------------\n",
      "Train Error: loss: 543768768.000000, R^2: 0.9096\n",
      " Test Error: loss: 772348800.000000, R^2: 0.8765\n",
      "\n",
      "Epoch 638\n",
      "--------------------------------\n",
      "Train Error: loss: 491745280.000000, R^2: 0.9149\n",
      " Test Error: loss: 752026752.000000, R^2: 0.8797\n",
      "\n",
      "Epoch 639\n",
      "--------------------------------\n",
      "Train Error: loss: 527933088.000000, R^2: 0.9080\n",
      " Test Error: loss: 727407744.000000, R^2: 0.8836\n",
      "\n",
      "Epoch 640\n",
      "--------------------------------\n",
      "Train Error: loss: 518956352.000000, R^2: 0.9131\n",
      " Test Error: loss: 714343616.000000, R^2: 0.8857\n",
      "\n",
      "Epoch 641\n",
      "--------------------------------\n",
      "Train Error: loss: 540740864.000000, R^2: 0.9058\n",
      " Test Error: loss: 708712896.000000, R^2: 0.8866\n",
      "\n",
      "Epoch 642\n",
      "--------------------------------\n",
      "Train Error: loss: 509781312.000000, R^2: 0.9043\n",
      " Test Error: loss: 735594688.000000, R^2: 0.8823\n",
      "\n",
      "Epoch 643\n",
      "--------------------------------\n",
      "Train Error: loss: 486678688.000000, R^2: 0.9096\n",
      " Test Error: loss: 805385792.000000, R^2: 0.8712\n",
      "\n",
      "Epoch 644\n",
      "--------------------------------\n",
      "Train Error: loss: 502003712.000000, R^2: 0.9125\n",
      " Test Error: loss: 747118272.000000, R^2: 0.8805\n",
      "\n",
      "Epoch 645\n",
      "--------------------------------\n",
      "Train Error: loss: 526856192.000000, R^2: 0.8982\n",
      " Test Error: loss: 744584320.000000, R^2: 0.8809\n",
      "\n",
      "Epoch 646\n",
      "--------------------------------\n",
      "Train Error: loss: 473959936.000000, R^2: 0.9146\n",
      " Test Error: loss: 733324288.000000, R^2: 0.8827\n",
      "\n",
      "Epoch 647\n",
      "--------------------------------\n",
      "Train Error: loss: 584483264.000000, R^2: 0.8999\n",
      " Test Error: loss: 741653184.000000, R^2: 0.8814\n",
      "\n",
      "Epoch 648\n",
      "--------------------------------\n",
      "Train Error: loss: 568069824.000000, R^2: 0.8869\n",
      " Test Error: loss: 770569344.000000, R^2: 0.8767\n",
      "\n",
      "Epoch 649\n",
      "--------------------------------\n",
      "Train Error: loss: 492185344.000000, R^2: 0.9147\n",
      " Test Error: loss: 747252864.000000, R^2: 0.8805\n",
      "\n",
      "Epoch 650\n",
      "--------------------------------\n",
      "Train Error: loss: 601210496.000000, R^2: 0.9000\n",
      " Test Error: loss: 703938560.000000, R^2: 0.8874\n",
      "\n",
      "Epoch 651\n",
      "--------------------------------\n",
      "Train Error: loss: 558456000.000000, R^2: 0.9055\n",
      " Test Error: loss: 702937984.000000, R^2: 0.8876\n",
      "\n",
      "Epoch 652\n",
      "--------------------------------\n",
      "Train Error: loss: 555222400.000000, R^2: 0.9082\n",
      " Test Error: loss: 694980416.000000, R^2: 0.8888\n",
      "\n",
      "Epoch 653\n",
      "--------------------------------\n",
      "Train Error: loss: 585394176.000000, R^2: 0.8855\n",
      " Test Error: loss: 722384384.000000, R^2: 0.8844\n",
      "\n",
      "Epoch 654\n",
      "--------------------------------\n",
      "Train Error: loss: 542507904.000000, R^2: 0.9096\n",
      " Test Error: loss: 704507520.000000, R^2: 0.8873\n",
      "\n",
      "Epoch 655\n",
      "--------------------------------\n",
      "Train Error: loss: 591857664.000000, R^2: 0.8852\n",
      " Test Error: loss: 672584768.000000, R^2: 0.8924\n",
      "\n",
      "Epoch 656\n",
      "--------------------------------\n",
      "Train Error: loss: 551799296.000000, R^2: 0.9158\n",
      " Test Error: loss: 705869504.000000, R^2: 0.8871\n",
      "\n",
      "Epoch 657\n",
      "--------------------------------\n",
      "Train Error: loss: 592043200.000000, R^2: 0.9163\n",
      " Test Error: loss: 798602176.000000, R^2: 0.8723\n",
      "\n",
      "Epoch 658\n",
      "--------------------------------\n",
      "Train Error: loss: 555439424.000000, R^2: 0.9087\n",
      " Test Error: loss: 685189440.000000, R^2: 0.8904\n",
      "\n",
      "Epoch 659\n",
      "--------------------------------\n",
      "Train Error: loss: 703750272.000000, R^2: 0.8810\n",
      " Test Error: loss: 647283520.000000, R^2: 0.8965\n",
      "\n",
      "Epoch 660\n",
      "--------------------------------\n",
      "Train Error: loss: 566690752.000000, R^2: 0.9060\n",
      " Test Error: loss: 679414976.000000, R^2: 0.8913\n",
      "\n",
      "Epoch 661\n",
      "--------------------------------\n",
      "Train Error: loss: 581389952.000000, R^2: 0.9053\n",
      " Test Error: loss: 672958336.000000, R^2: 0.8923\n",
      "\n",
      "Epoch 662\n",
      "--------------------------------\n",
      "Train Error: loss: 485840288.000000, R^2: 0.9184\n",
      " Test Error: loss: 703771584.000000, R^2: 0.8874\n",
      "\n",
      "Epoch 663\n",
      "--------------------------------\n",
      "Train Error: loss: 467604288.000000, R^2: 0.9209\n",
      " Test Error: loss: 683054976.000000, R^2: 0.8907\n",
      "\n",
      "Epoch 664\n",
      "--------------------------------\n",
      "Train Error: loss: 551143040.000000, R^2: 0.9052\n",
      " Test Error: loss: 696378240.000000, R^2: 0.8886\n",
      "\n",
      "Epoch 665\n",
      "--------------------------------\n",
      "Train Error: loss: 574946688.000000, R^2: 0.8938\n",
      " Test Error: loss: 745168768.000000, R^2: 0.8808\n",
      "\n",
      "Epoch 666\n",
      "--------------------------------\n",
      "Train Error: loss: 671565056.000000, R^2: 0.8915\n",
      " Test Error: loss: 707379968.000000, R^2: 0.8868\n",
      "\n",
      "Epoch 667\n",
      "--------------------------------\n",
      "Train Error: loss: 497787360.000000, R^2: 0.9194\n",
      " Test Error: loss: 695250304.000000, R^2: 0.8888\n",
      "\n",
      "Epoch 668\n",
      "--------------------------------\n",
      "Train Error: loss: 481323744.000000, R^2: 0.9141\n",
      " Test Error: loss: 712426048.000000, R^2: 0.8860\n",
      "\n",
      "Epoch 669\n",
      "--------------------------------\n",
      "Train Error: loss: 557402368.000000, R^2: 0.9109\n",
      " Test Error: loss: 696336256.000000, R^2: 0.8886\n",
      "\n",
      "Epoch 670\n",
      "--------------------------------\n",
      "Train Error: loss: 558771520.000000, R^2: 0.9007\n",
      " Test Error: loss: 732198464.000000, R^2: 0.8829\n",
      "\n",
      "Epoch 671\n",
      "--------------------------------\n",
      "Train Error: loss: 549625536.000000, R^2: 0.9003\n",
      " Test Error: loss: 754704704.000000, R^2: 0.8793\n",
      "\n",
      "Epoch 672\n",
      "--------------------------------\n",
      "Train Error: loss: 553767552.000000, R^2: 0.9106\n",
      " Test Error: loss: 747272128.000000, R^2: 0.8805\n",
      "\n",
      "Epoch 673\n",
      "--------------------------------\n",
      "Train Error: loss: 495213120.000000, R^2: 0.9177\n",
      " Test Error: loss: 763842816.000000, R^2: 0.8778\n",
      "\n",
      "Epoch 674\n",
      "--------------------------------\n",
      "Train Error: loss: 551944320.000000, R^2: 0.9032\n",
      " Test Error: loss: 747356736.000000, R^2: 0.8804\n",
      "\n",
      "Epoch 675\n",
      "--------------------------------\n",
      "Train Error: loss: 524726848.000000, R^2: 0.9148\n",
      " Test Error: loss: 753297344.000000, R^2: 0.8795\n",
      "\n",
      "Epoch 676\n",
      "--------------------------------\n",
      "Train Error: loss: 516178144.000000, R^2: 0.9053\n",
      " Test Error: loss: 803897024.000000, R^2: 0.8714\n",
      "\n",
      "Epoch 677\n",
      "--------------------------------\n",
      "Train Error: loss: 493879904.000000, R^2: 0.9188\n",
      " Test Error: loss: 782762688.000000, R^2: 0.8748\n",
      "\n",
      "Epoch 678\n",
      "--------------------------------\n",
      "Train Error: loss: 498666752.000000, R^2: 0.9130\n",
      " Test Error: loss: 741968128.000000, R^2: 0.8813\n",
      "\n",
      "Epoch 679\n",
      "--------------------------------\n",
      "Train Error: loss: 490864096.000000, R^2: 0.9146\n",
      " Test Error: loss: 744532608.000000, R^2: 0.8809\n",
      "\n",
      "Epoch 680\n",
      "--------------------------------\n",
      "Train Error: loss: 465008032.000000, R^2: 0.9221\n",
      " Test Error: loss: 742978112.000000, R^2: 0.8811\n",
      "\n",
      "Epoch 681\n",
      "--------------------------------\n",
      "Train Error: loss: 487974304.000000, R^2: 0.9182\n",
      " Test Error: loss: 770466368.000000, R^2: 0.8768\n",
      "\n",
      "Epoch 682\n",
      "--------------------------------\n",
      "Train Error: loss: 555108992.000000, R^2: 0.9055\n",
      " Test Error: loss: 780016512.000000, R^2: 0.8752\n",
      "\n",
      "Epoch 683\n",
      "--------------------------------\n",
      "Train Error: loss: 527988288.000000, R^2: 0.9102\n",
      " Test Error: loss: 741768768.000000, R^2: 0.8813\n",
      "\n",
      "Epoch 684\n",
      "--------------------------------\n",
      "Train Error: loss: 753904704.000000, R^2: 0.8552\n",
      " Test Error: loss: 740912896.000000, R^2: 0.8815\n",
      "\n",
      "Epoch 685\n",
      "--------------------------------\n",
      "Train Error: loss: 535050144.000000, R^2: 0.9139\n",
      " Test Error: loss: 769597120.000000, R^2: 0.8769\n",
      "\n",
      "Epoch 686\n",
      "--------------------------------\n",
      "Train Error: loss: 581975872.000000, R^2: 0.9024\n",
      " Test Error: loss: 810539712.000000, R^2: 0.8703\n",
      "\n",
      "Epoch 687\n",
      "--------------------------------\n",
      "Train Error: loss: 622893056.000000, R^2: 0.8924\n",
      " Test Error: loss: 815672384.000000, R^2: 0.8695\n",
      "\n",
      "Epoch 688\n",
      "--------------------------------\n",
      "Train Error: loss: 522533216.000000, R^2: 0.9163\n",
      " Test Error: loss: 846097216.000000, R^2: 0.8647\n",
      "\n",
      "Epoch 689\n",
      "--------------------------------\n",
      "Train Error: loss: 502998592.000000, R^2: 0.9124\n",
      " Test Error: loss: 819845056.000000, R^2: 0.8689\n",
      "\n",
      "Epoch 690\n",
      "--------------------------------\n",
      "Train Error: loss: 533739264.000000, R^2: 0.9113\n",
      " Test Error: loss: 814028800.000000, R^2: 0.8698\n",
      "\n",
      "Epoch 691\n",
      "--------------------------------\n",
      "Train Error: loss: 625412608.000000, R^2: 0.9057\n",
      " Test Error: loss: 795158528.000000, R^2: 0.8728\n",
      "\n",
      "Epoch 692\n",
      "--------------------------------\n",
      "Train Error: loss: 536921792.000000, R^2: 0.9111\n",
      " Test Error: loss: 820069376.000000, R^2: 0.8688\n",
      "\n",
      "Epoch 693\n",
      "--------------------------------\n",
      "Train Error: loss: 549141440.000000, R^2: 0.9046\n",
      " Test Error: loss: 813727168.000000, R^2: 0.8698\n",
      "\n",
      "Epoch 694\n",
      "--------------------------------\n",
      "Train Error: loss: 578243776.000000, R^2: 0.9028\n",
      " Test Error: loss: 785650944.000000, R^2: 0.8743\n",
      "\n",
      "Epoch 695\n",
      "--------------------------------\n",
      "Train Error: loss: 536076640.000000, R^2: 0.9049\n",
      " Test Error: loss: 769547392.000000, R^2: 0.8769\n",
      "\n",
      "Epoch 696\n",
      "--------------------------------\n",
      "Train Error: loss: 496897248.000000, R^2: 0.9156\n",
      " Test Error: loss: 848990016.000000, R^2: 0.8642\n",
      "\n",
      "Epoch 697\n",
      "--------------------------------\n",
      "Train Error: loss: 557534016.000000, R^2: 0.8886\n",
      " Test Error: loss: 802306496.000000, R^2: 0.8717\n",
      "\n",
      "Epoch 698\n",
      "--------------------------------\n",
      "Train Error: loss: 508451136.000000, R^2: 0.9120\n",
      " Test Error: loss: 819866816.000000, R^2: 0.8688\n",
      "\n",
      "Epoch 699\n",
      "--------------------------------\n",
      "Train Error: loss: 551267520.000000, R^2: 0.9056\n",
      " Test Error: loss: 758056256.000000, R^2: 0.8787\n",
      "\n",
      "Epoch 700\n",
      "--------------------------------\n",
      "Train Error: loss: 633592576.000000, R^2: 0.8929\n",
      " Test Error: loss: 697758208.000000, R^2: 0.8884\n",
      "\n",
      "CPU times: total: 43.6 s\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_losses, train_r2s, test_losses, test_r2s = common_train(\n",
    "    epochs=700,\n",
    "    model=net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=DEVICE,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x700 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_test(train_losses[5:], train_r2s[5:], test_losses[5:], test_r2s[5:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R^2: 0.888382\n",
      "  MSE: 697758336.000000\n",
      " RMSE: 26415.115234\n",
      "  MAE: 18370.394531\n",
      " MAPE: 0.113613\n",
      "RMSLE: 0.150505\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader, DEVICE)\n",
    "\n",
    "r2 = metrics.r2_score(y_true, y_pred)\n",
    "mse = metrics.mean_squared_error(y_true, y_pred)  # тоже самое что и nn.MSELoss\n",
    "rmse = np.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "rmsle = np.sqrt(metrics.mean_squared_log_error(y_true, y_pred))\n",
    "print(f\"  R^2: {r2:.6f}\")\n",
    "print(f\"  MSE: {mse:.6f}\")\n",
    "print(f\" RMSE: {rmse:.6f}\")\n",
    "print(f\"  MAE: {mae:.6f}\")\n",
    "print(f\" MAPE: {mape:.6f}\")\n",
    "print(f\"RMSLE: {rmsle:.6f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_y_true_y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplot_y_true_y_pred\u001B[49m(y_true[:\u001B[38;5;241m100\u001B[39m], y_pred[:\u001B[38;5;241m100\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plot_y_true_y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "plot_y_true_y_pred(y_true[:100], y_pred[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:   tensor([ 0.6663,  0.2584,  1.1062,  0.3007,  2.4455,  0.5949,  2.0000,  2.0000,\n",
      "         2.0000, -0.1037,  3.0000, 20.0000,  7.0000,  4.0000])\n",
      "Target:  275000.000000\n",
      "Predict: 257002.078125\n",
      "\n",
      "Input:   tensor([ 0.6663,  1.4568, -0.2671,  0.3007, -0.3389,  0.5949,  2.0000,  2.0000,\n",
      "         2.0000,  1.0492,  0.0000,  8.0000,  5.0000,  4.0000])\n",
      "Target:  236000.000000\n",
      "Predict: 236515.609375\n",
      "\n",
      "Input:   tensor([-0.0686,  1.3491, -0.8859,  0.3007, -1.0246,  0.5949,  1.0000,  2.0000,\n",
      "         2.0000,  3.9473,  0.0000,  7.0000,  7.0000,  2.0000])\n",
      "Target:  274970.000000\n",
      "Predict: 186982.875000\n",
      "\n",
      "Input:   tensor([-0.8035, -0.7891, -1.6745, -1.0544, -0.2268, -0.9618,  1.0000,  4.0000,\n",
      "         3.0000, -0.4639,  3.0000, 12.0000,  7.0000,  4.0000])\n",
      "Target:  139000.000000\n",
      "Predict: 112669.289062\n",
      "\n",
      "Input:   tensor([-0.8035, -0.7402, -0.1264, -1.0544,  0.3195, -0.9618,  1.0000,  4.0000,\n",
      "         3.0000, -0.7441,  3.0000, 12.0000,  2.0000,  3.0000])\n",
      "Target:  135000.000000\n",
      "Predict: 117122.085938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "for i in torch.randperm(len(test_dataset))[:5]:\n",
    "    x, y = test_dataset[i]\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    pred = net(x.unsqueeze(0)).squeeze(0)\n",
    "    print(f\"Input:   {x.cpu()}\")\n",
    "    print(f\"Target:  {y.item():.6f}\")\n",
    "    print(f\"Predict: {pred.item():.6f}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
