{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "torch.set_warn_always(True)\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/\")\n",
    "\n",
    "CUDA = \"cuda\"\n",
    "CPU = \"cpu\"\n",
    "DEVICE = CUDA if torch.cuda.is_available() else CPU\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def na_stat(df: pd.DataFrame) -> pd.Series:\n",
    "    stat = df.isna().sum()\n",
    "    return stat[stat > 0]\n",
    "\n",
    "\n",
    "def duplicates_stat(df: pd.DataFrame) -> pd.Series:\n",
    "    return df[df.duplicated()].value_counts()\n",
    "\n",
    "\n",
    "def get_categorical_columns(df: pd.DataFrame) -> pd.Index:\n",
    "    return df.select_dtypes(object).columns\n",
    "\n",
    "\n",
    "def get_numerical_columns(df: pd.DataFrame) -> pd.Index:\n",
    "    return df.select_dtypes(np.number).columns\n",
    "\n",
    "\n",
    "def count_categories(df: pd.DataFrame) -> pd.Series:\n",
    "    return df[get_categorical_columns(df)].nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# вставить код из datasets.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        test_dataloader: DataLoader,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[t.List[float], t.List[float], t.List[float], t.List[float]]:\n",
    "    train_losses, train_r2s = [], []\n",
    "    test_losses, test_r2s = [], []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "\n",
    "        train_loss, train_r2 = train_loop(train_dataloader, model, loss_fn, optimizer, verbose=verbose, device=device)\n",
    "        print(f\"Train Error: loss: {train_loss:.6f}, R^2: {train_r2:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_r2s.append(train_r2)\n",
    "\n",
    "        test_loss, test_r2 = test_loop(test_dataloader, model, loss_fn, device=device)\n",
    "        print(f\" Test Error: loss: {test_loss:.6f}, R^2: {test_r2:.4f}\\n\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_r2s.append(test_r2)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses, train_r2s, test_losses, test_r2s\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, avg_r2 = 0, 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        r2 = metrics.r2_score(y.detach().cpu(), pred.detach().cpu())\n",
    "        avg_loss += loss\n",
    "        avg_r2 += r2\n",
    "        if verbose and batch % verbose == 0:\n",
    "            print(f\"[{batch * len(x):>4d}/{size:>4d}]: loss: {loss:.6f}, R^2: {r2:.4f}\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return (avg_loss / num_batches).item(), avg_r2 / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(model, dataloader, device)\n",
    "    return loss_fn(y_pred, y_true).item(), metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_true_y_pred(\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.flatten(torch.vstack(y_test)).cpu(), torch.flatten(torch.vstack(y_pred)).cpu()\n",
    "\n",
    "\n",
    "def plot_train_test(\n",
    "        train_losses: t.List[float],\n",
    "        train_r2s: t.List[float],\n",
    "        test_losses: t.List[float],\n",
    "        test_r2s: t.List[float],\n",
    ") -> None:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 7))\n",
    "    epochs = torch.arange(len(train_losses))\n",
    "\n",
    "    axes[0].plot(epochs, train_losses)\n",
    "    axes[0].plot(epochs, test_losses)\n",
    "    axes[0].set_ylabel(\"loss\")\n",
    "    axes[0].legend([\"train\", \"test\"])\n",
    "\n",
    "    axes[1].plot(epochs, train_r2s)\n",
    "    axes[1].plot(epochs, test_r2s)\n",
    "    axes[1].set_xlabel(\"epoch\")\n",
    "    axes[1].set_ylabel(\"$R^2$\")\n",
    "\n",
    "\n",
    "def plot_y_true_y_pred(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    x = torch.arange(len(y_pred))\n",
    "    plt.plot(x, y_true)\n",
    "    plt.plot(x, y_pred)\n",
    "    plt.legend([\"true\", \"pred\"])\n",
    "\n",
    "\n",
    "def print_y_true_y_pred(x: torch.Tensor, y: torch.Tensor, model: nn.Module, device: str = CPU) -> None:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    pred = model(x.unsqueeze(0)).squeeze(0)\n",
    "    print(f\"Input:   {x.cpu()}\")\n",
    "    print(f\"Target:  {y.item():.6f}\")\n",
    "    print(f\"Predict: {pred.item():.6f}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.mlp(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m net \u001B[38;5;241m=\u001B[39m Regression(in_features\u001B[38;5;241m=\u001B[39m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241m.\u001B[39mn_features)\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m      4\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[0;32m      5\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(net\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.003\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = Regression(in_features=train_dataset.n_features).to(DEVICE)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.003)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_losses, train_r2s, test_losses, test_r2s = common_train(\n",
    "    epochs=200,\n",
    "    model=net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=DEVICE,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_test(train_losses[5:], train_r2s[5:], test_losses[5:], test_r2s[5:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader, DEVICE)\n",
    "\n",
    "r2 = metrics.r2_score(y_true, y_pred)\n",
    "mse = metrics.mean_squared_error(y_true, y_pred)  # тоже самое что и nn.MSELoss\n",
    "rmse = np.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "rmsle = np.sqrt(metrics.mean_squared_log_error(y_true, y_pred))\n",
    "print(f\"  R^2: {r2:.6f}\")\n",
    "print(f\"  MSE: {mse:.6f}\")\n",
    "print(f\" RMSE: {rmse:.6f}\")\n",
    "print(f\"  MAE: {mae:.6f}\")\n",
    "print(f\" MAPE: {mape:.6f}\")\n",
    "print(f\"RMSLE: {rmsle:.6f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_y_true_y_pred(y_true[:100], y_pred[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net.eval()\n",
    "for i in torch.randperm(len(test_dataset))[:5]:\n",
    "    x, y = test_dataset[i]\n",
    "    print_y_true_y_pred(x, y, net, DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
