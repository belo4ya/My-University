{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "%matplotlib inline\n",
    "# @formatter:on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "torch.set_warn_always(True)\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/\")\n",
    "\n",
    "CUDA = \"cuda\"\n",
    "CPU = \"cpu\"\n",
    "DEVICE = CUDA if torch.cuda.is_available() else CPU\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def wordnet_lemmatizer(token: str) -> str:\n",
    "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
    "\n",
    "\n",
    "RE_URL = re.compile(r\"\\w+://\\S+\", flags=re.MULTILINE)\n",
    "RE_HASHTAG = re.compile(r\"#\\S+\", flags=re.MULTILINE)\n",
    "RE_TW_USERNAME = re.compile(r\"@\\S+\", flags=re.MULTILINE)\n",
    "RE_NOT_ASCII_LOW = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def preprocess_tweet(\n",
    "        text: str,\n",
    "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
    "        min_word_len: int = 0,\n",
    ") -> str:\n",
    "    text = text.lower()\n",
    "    for pat in [RE_URL, RE_HASHTAG, RE_TW_USERNAME, RE_NOT_ASCII_LOW]:\n",
    "        text = pat.sub(\" \", text)\n",
    "\n",
    "    words = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "            if not lemmatizer_or_stemmer:\n",
    "                words.append(word)\n",
    "                continue\n",
    "            word = lemmatizer_or_stemmer(word)\n",
    "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "                words.append(word)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "class WordVocab:\n",
    "    pad = \"<PAD>\"\n",
    "    unknown = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, texts: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for text in texts:\n",
    "            words = nltk.word_tokenize(text)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
    "        unknown_idx = w2i[self.unknown]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, text: str) -> torch.Tensor:\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(text)]\n",
    "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \" \".join(self.alphabet[i] for i in indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class TweetCatDataset(Dataset):\n",
    "    DATA_COL = \"text\"\n",
    "    TARGET_COL = \"type\"\n",
    "\n",
    "    raw_texts: t.List[str]\n",
    "    texts: t.List[str]\n",
    "\n",
    "    encoder: LabelEncoder\n",
    "    classes: t.List[str]\n",
    "\n",
    "    vocab: WordVocab\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, vocab: WordVocab = None, encoder: LabelEncoder = None):\n",
    "        self.raw_texts = df[self.DATA_COL].tolist()\n",
    "        with tqdm(total=len(df)) as pbar:\n",
    "            self._pbar, self._i, self._n = pbar, 0, 100\n",
    "            self.texts = [self.preprocess_text(text) for text in self.raw_texts]\n",
    "        self.vocab = vocab or WordVocab(self.texts)\n",
    "\n",
    "        if encoder:\n",
    "            self.encoder = encoder\n",
    "            encode = self.encoder.transform\n",
    "        else:\n",
    "            self.encoder = LabelEncoder()\n",
    "            encode = self.encoder.fit_transform\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(text) for text in self.texts])\n",
    "        targets = encode(df[self.TARGET_COL])\n",
    "        self.classes = [str(cls) for cls in self.encoder.classes_]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        self._i += 1\n",
    "        if self._i % self._n == 0:\n",
    "            self._pbar.update(self._n)\n",
    "        return preprocess_tweet(text, lemmatizer_or_stemmer=wordnet_lemmatizer, min_word_len=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics         345\n",
      "medical          299\n",
      "entertainment    260\n",
      "sports           258\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 300x250 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_cat_df = pd.read_csv(DATA_DIR / \"nlp/tweet_cat.csv\")\n",
    "vc = tweet_cat_df[\"type\"].value_counts()\n",
    "print(vc)\n",
    "tweet_cat_df[\"type\"].value_counts().plot.bar(rot=30, figsize=(3, 2.5));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/929 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(tweet_cat_df, test_size=0.2, random_state=1)\n",
    "\n",
    "train_dataset = TweetCatDataset(train_df)\n",
    "test_dataset = TweetCatDataset(\n",
    "    test_df,\n",
    "    vocab=train_dataset.vocab,\n",
    "    encoder=train_dataset.encoder,\n",
    ")\n",
    "print(len(train_dataset.vocab), train_dataset.vocab.max_len)\n",
    "len(train_dataset), len(test_dataset), train_dataset.classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_weights(targets: torch.Tensor) -> torch.Tensor:\n",
    "    _, counts = targets.unique(return_counts=True)\n",
    "    return counts.max() / counts\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        test_dataloader: DataLoader,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[t.List[float], t.List[float], t.List[float], t.List[float]]:\n",
    "    train_losses, train_accuracy_list = [], []\n",
    "    test_losses, test_accuracy_list = [], []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "\n",
    "        train_loss, train_accuracy = train_loop(train_dataloader, model, loss_fn, optimizer, verbose, device)\n",
    "        print(f\"Train Error: loss: {train_loss:.6f}, accuracy: {train_accuracy:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "        test_loss, test_accuracy = test_loop(test_dataloader, model, loss_fn, device)\n",
    "        print(f\" Test Error: loss: {test_loss:.6f}, accuracy: {test_accuracy:.4f}\\n\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses, train_accuracy_list, test_losses, test_accuracy_list\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, avg_accuracy = 0, 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true = torch.flatten(y).detach().cpu()\n",
    "        y_pred = torch.flatten(pred.argmax(1)).detach().cpu()\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "        avg_loss += loss\n",
    "        avg_accuracy += accuracy\n",
    "        if verbose and batch % verbose == 0:\n",
    "            print(f\"[{batch * len(x):>4d}/{size:>4d}]: loss: {loss:.6f}, accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return (avg_loss / num_batches).item(), avg_accuracy / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(model, dataloader, device)\n",
    "    return loss_fn(y_pred, y_true).item(), metrics.accuracy_score(y_true.cpu(), y_pred.argmax(1).cpu())\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_true_y_pred(\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.flatten(torch.vstack(y_test)), torch.vstack(y_pred)\n",
    "\n",
    "\n",
    "def plot_train_test(\n",
    "        train_losses: t.List[float],\n",
    "        train_accuracy: t.List[float],\n",
    "        test_losses: t.List[float],\n",
    "        test_accuracy: t.List[float],\n",
    ") -> None:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 7))\n",
    "    epochs = torch.arange(len(train_losses))\n",
    "\n",
    "    axes[0].plot(epochs, train_losses)\n",
    "    axes[0].plot(epochs, test_losses)\n",
    "    axes[0].set_ylabel(\"loss\")\n",
    "    axes[0].legend([\"train\", \"test\"])\n",
    "\n",
    "    axes[1].plot(epochs, train_accuracy)\n",
    "    axes[1].plot(epochs, test_accuracy)\n",
    "    axes[1].set_xlabel(\"epoch\")\n",
    "    axes[1].set_ylabel(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TweetCatRNNClassifier(nn.Module):\n",
    "    _STATE_T = t.Union[t.Optional[torch.Tensor], t.Optional[t.Tuple[torch.Tensor, torch.Tensor]]]\n",
    "    rnn_state: _STATE_T\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=rnn_hidden_size, num_layers=2, dropout=0.5, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.75),\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "        self.reset_rnn_state()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x, rnn_state = self.rnn(x, self.rnn_state)\n",
    "        self.keep_rnn_state(rnn_state)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.rnn_state = None\n",
    "\n",
    "    def keep_rnn_state(self, state: _STATE_T):\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            self.rnn_state = (state[0].detach(), state[1].detach())\n",
    "        else:\n",
    "            self.rnn_state = state.detach()\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        self.reset_rnn_state()\n",
    "        return super().train(mode)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = TweetCatRNNClassifier(\n",
    "    num_embeddings=len(train_dataset.vocab),\n",
    "    embedding_dim=512,\n",
    "    rnn_hidden_size=128,\n",
    "    vector_size=train_dataset.vocab.max_len,\n",
    "    num_classes=len(train_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=get_weights(train_dataset.targets).to(DEVICE))\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_losses, train_accuracy, test_losses, test_accuracy = common_train(\n",
    "    epochs=10,\n",
    "    model=net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=DEVICE,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_test(train_losses, train_accuracy, test_losses, test_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader, DEVICE)\n",
    "y_true, y_pred = y_true.cpu(), y_pred.argmax(1).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    display_labels=test_dataset.classes,\n",
    "    colorbar=False,\n",
    "    xticks_rotation=0,\n",
    "    cmap=sns.color_palette('light:b', as_cmap=True)\n",
    ")\n",
    "cm_display.ax_.grid(False)\n",
    "cm_display.figure_.set_size_inches(3.5, 3.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, target_names=test_dataset.classes, zero_division=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net.eval()\n",
    "for i in torch.randperm(len(test_dataset))[:5]:\n",
    "    x, y = test_dataset[i]\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    pred = net(x.unsqueeze(0))\n",
    "\n",
    "    pred_proba, pred_label_indices = torch.softmax(pred, 1).topk(min(len(test_dataset.classes), 3), dim=1)\n",
    "    pred_labels = test_dataset.encoder.inverse_transform(pred_label_indices.squeeze().cpu())\n",
    "    predicts = \", \".join([f\"{label} ({prob:.2f})\" for (label, prob) in zip(pred_labels, pred_proba.squeeze())])\n",
    "\n",
    "    text = test_dataset.texts[i]\n",
    "    text = text if len(text) < 80 else text[:80] + \"...\"\n",
    "    target = test_dataset.encoder.inverse_transform([y.cpu()])[0]\n",
    "\n",
    "    print(f\"Input:   {text}\")\n",
    "    print(f\"Target:  {target}\")\n",
    "    print(f\"Predict: {predicts}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
