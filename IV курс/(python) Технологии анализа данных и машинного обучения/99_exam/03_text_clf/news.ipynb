{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "%matplotlib inline\n",
    "# @formatter:on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "torch.set_warn_always(True)\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/\")\n",
    "\n",
    "CUDA = \"cuda\"\n",
    "CPU = \"cpu\"\n",
    "DEVICE = CUDA if torch.cuda.is_available() else CPU\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def wordnet_lemmatizer(token: str) -> str:\n",
    "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
    "\n",
    "\n",
    "RE_URL = re.compile(r\"\\w+://\\S+\", flags=re.MULTILINE)\n",
    "RE_NOT_ASCII_LOW = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def preprocess_text(\n",
    "        text: str,\n",
    "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
    "        min_word_len: int = 0,\n",
    ") -> str:\n",
    "    text = text.lower()\n",
    "    for pat in [RE_URL, RE_NOT_ASCII_LOW]:\n",
    "        text = pat.sub(\" \", text)\n",
    "\n",
    "    words = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "            if not lemmatizer_or_stemmer:\n",
    "                words.append(word)\n",
    "                continue\n",
    "            word = lemmatizer_or_stemmer(word)\n",
    "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "                words.append(word)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "class WordVocab:\n",
    "    pad = \"<PAD>\"\n",
    "    unknown = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, texts: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for text in texts:\n",
    "            words = nltk.word_tokenize(text)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
    "        unknown_idx = w2i[self.unknown]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, text: str) -> torch.Tensor:\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(text)]\n",
    "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \" \".join(self.alphabet[i] for i in indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    DATA_COL = \"Description\"  # или Title\n",
    "    TARGET_COL = \"Class Index\"\n",
    "\n",
    "    raw_texts: t.List[str]\n",
    "    texts: t.List[str]\n",
    "\n",
    "    encoder: LabelEncoder\n",
    "    classes: t.List[str]\n",
    "\n",
    "    vocab: WordVocab\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, vocab: WordVocab = None, encoder: LabelEncoder = None):\n",
    "        self.raw_texts = df[self.DATA_COL].tolist()\n",
    "        with tqdm(total=len(df)) as pbar:\n",
    "            self._pbar, self._i, self._n = pbar, 0, 100\n",
    "            self.texts = [self.preprocess_text(text) for text in self.raw_texts]\n",
    "        self.vocab = vocab or WordVocab(self.texts)\n",
    "\n",
    "        if encoder:\n",
    "            self.encoder = encoder\n",
    "            encode = self.encoder.transform\n",
    "        else:\n",
    "            self.encoder = LabelEncoder()\n",
    "            encode = self.encoder.fit_transform\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(text) for text in self.texts])\n",
    "        targets = encode(df[self.TARGET_COL])\n",
    "        self.classes = [str(cls) for cls in self.encoder.classes_]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        self._i += 1\n",
    "        if self._i % self._n == 0:\n",
    "            self._pbar.update(self._n)\n",
    "        return preprocess_text(text, lemmatizer_or_stemmer=wordnet_lemmatizer, min_word_len=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2575\n",
      "4    2489\n",
      "3    2475\n",
      "2    2461\n",
      "Name: Class Index, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 300x250 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df = pd.read_csv(DATA_DIR / \"nlp/news.csv\")\n",
    "vc = news_df[\"Class Index\"].value_counts()\n",
    "print(vc)\n",
    "news_df[\"Class Index\"].value_counts().plot.bar(rot=0, figsize=(3, 2.5));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [01:35<00:00, 83.95it/s] \n",
      "100%|██████████| 2000/2000 [00:19<00:00, 100.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15247 68\n"
     ]
    },
    {
     "data": {
      "text/plain": "(8000, 2000, ['1', '2', '3', '4'])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(news_df, test_size=0.2, random_state=0)\n",
    "\n",
    "train_dataset = NewsDataset(train_df)\n",
    "test_dataset = NewsDataset(\n",
    "    test_df,\n",
    "    vocab=train_dataset.vocab,\n",
    "    encoder=train_dataset.encoder,\n",
    ")\n",
    "print(len(train_dataset.vocab), train_dataset.vocab.max_len)\n",
    "len(train_dataset), len(test_dataset), train_dataset.classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_weights(targets: torch.Tensor) -> torch.Tensor:\n",
    "    _, counts = targets.unique(return_counts=True)\n",
    "    return counts.max() / counts\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        test_dataloader: DataLoader,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[t.List[float], t.List[float], t.List[float], t.List[float]]:\n",
    "    train_losses, train_accuracy_list = [], []\n",
    "    test_losses, test_accuracy_list = [], []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "\n",
    "        train_loss, train_accuracy = train_loop(train_dataloader, model, loss_fn, optimizer, verbose, device)\n",
    "        print(f\"Train Error: loss: {train_loss:.6f}, accuracy: {train_accuracy:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "        test_loss, test_accuracy = test_loop(test_dataloader, model, loss_fn, device)\n",
    "        print(f\" Test Error: loss: {test_loss:.6f}, accuracy: {test_accuracy:.4f}\\n\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses, train_accuracy_list, test_losses, test_accuracy_list\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, avg_accuracy = 0, 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true = torch.flatten(y).detach().cpu()\n",
    "        y_pred = torch.flatten(pred.argmax(1)).detach().cpu()\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "        avg_loss += loss\n",
    "        avg_accuracy += accuracy\n",
    "        if verbose and batch % verbose == 0:\n",
    "            print(f\"[{batch * len(x):>4d}/{size:>4d}]: loss: {loss:.6f}, accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return (avg_loss / num_batches).item(), avg_accuracy / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(model, dataloader, device)\n",
    "    return loss_fn(y_pred, y_true).item(), metrics.accuracy_score(y_true.cpu(), y_pred.argmax(1).cpu())\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_true_y_pred(\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.flatten(torch.vstack(y_test)), torch.vstack(y_pred)\n",
    "\n",
    "\n",
    "def plot_train_test(\n",
    "        train_losses: t.List[float],\n",
    "        train_accuracy: t.List[float],\n",
    "        test_losses: t.List[float],\n",
    "        test_accuracy: t.List[float],\n",
    ") -> None:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 7))\n",
    "    epochs = torch.arange(len(train_losses))\n",
    "\n",
    "    axes[0].plot(epochs, train_losses)\n",
    "    axes[0].plot(epochs, test_losses)\n",
    "    axes[0].set_ylabel(\"loss\")\n",
    "    axes[0].legend([\"train\", \"test\"])\n",
    "\n",
    "    axes[1].plot(epochs, train_accuracy)\n",
    "    axes[1].plot(epochs, test_accuracy)\n",
    "    axes[1].set_xlabel(\"epoch\")\n",
    "    axes[1].set_ylabel(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class NewsCNNClassifier(nn.Module):\n",
    "    LAST_CONV_OUT_CHANNELS = 128\n",
    "    ADAPTIVE_AVG_POOL = 16\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=64, kernel_size=2),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=self.LAST_CONV_OUT_CHANNELS, kernel_size=2),\n",
    "            nn.BatchNorm1d(num_features=self.LAST_CONV_OUT_CHANNELS),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(self.ADAPTIVE_AVG_POOL)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.LAST_CONV_OUT_CHANNELS * self.ADAPTIVE_AVG_POOL, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = torch.permute(x, dims=(0, 2, 1))\n",
    "\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "NewsCNNClassifier(\n  (embedding): Embedding(15247, 256, padding_idx=0)\n  (features): Sequential(\n    (0): Conv1d(256, 64, kernel_size=(2,), stride=(1,))\n    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.5, inplace=False)\n    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): ReLU()\n    (8): Dropout(p=0.5, inplace=False)\n    (9): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool1d(output_size=16)\n  (classifier): Sequential(\n    (0): Linear(in_features=2048, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=256, out_features=4, bias=True)\n  )\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = NewsCNNClassifier(\n",
    "    num_embeddings=len(train_dataset.vocab),\n",
    "    embedding_dim=256,\n",
    "    num_classes=len(train_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=get_weights(train_dataset.targets).to(DEVICE))\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, drop_last=True)\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_losses, train_accuracy, test_losses, test_accuracy = common_train(\n",
    "    epochs=10,\n",
    "    model=net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=DEVICE,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_test(train_losses, train_accuracy, test_losses, test_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader, DEVICE)\n",
    "y_true, y_pred = y_true.cpu(), y_pred.argmax(1).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    display_labels=test_dataset.classes,\n",
    "    colorbar=False,\n",
    "    xticks_rotation=0,\n",
    "    cmap=sns.color_palette('light:b', as_cmap=True)\n",
    ")\n",
    "cm_display.ax_.grid(False)\n",
    "cm_display.figure_.set_size_inches(3.5, 3.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, target_names=test_dataset.classes, zero_division=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net.eval()\n",
    "for i in torch.randperm(len(test_dataset))[:5]:\n",
    "    x, y = test_dataset[i]\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    pred = net(x.unsqueeze(0))\n",
    "\n",
    "    pred_proba, pred_label_indices = torch.softmax(pred, 1).topk(min(len(test_dataset.classes), 3), dim=1)\n",
    "    pred_labels = test_dataset.encoder.inverse_transform(pred_label_indices.squeeze().cpu())\n",
    "    predicts = \", \".join([f\"{label} ({prob:.2f})\" for (label, prob) in zip(pred_labels, pred_proba.squeeze())])\n",
    "\n",
    "    text = test_dataset.texts[i]\n",
    "    text = text if len(text) < 80 else text[:80] + \"...\"\n",
    "    target = test_dataset.encoder.inverse_transform([y.cpu()])[0]\n",
    "\n",
    "    print(f\"Input:   {text}\")\n",
    "    print(f\"Target:  {target}\")\n",
    "    print(f\"Predict: {predicts}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
