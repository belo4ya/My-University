{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "%matplotlib inline\n",
    "# @formatter:on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.set_warn_always(True)\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/\")\n",
    "\n",
    "CUDA = \"cuda\"\n",
    "CPU = \"cpu\"\n",
    "DEVICE = CUDA if torch.cuda.is_available() else CPU\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предобработка данных и подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess_images(dataset: ImageFolder, save_dir: Path) -> None:\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    for cls in dataset.classes:\n",
    "        (save_dir / cls).mkdir(exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        img, target = dataset[i]\n",
    "        img.save(save_dir / dataset.classes[target] / Path(dataset.imgs[i][0]).name)\n",
    "\n",
    "\n",
    "def show_sample_images(dataset: ImageFolder, cols: int = 3, rows: int = 3) -> None:\n",
    "    _, axes = plt.subplots(cols, rows, figsize=(6, 6))\n",
    "    for i, ax in zip(torch.randperm(len(dataset)), axes.flatten()):\n",
    "        img, target = dataset[i]\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(dataset.classes[target])\n",
    "        if img.mode == \"RGB\":\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "\n",
    "\n",
    "def torch_train_test_split(dataset: t.Union[Dataset, t.Sized], test_size: float) -> t.Tuple[Subset, Subset]:\n",
    "    test_size = round(test_size * len(dataset))\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))\n",
    "    return train_dataset, test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 682/2860 [00:15<00:36, 59.81it/s]"
     ]
    }
   ],
   "source": [
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(28, 28)),\n",
    "    transforms.Grayscale(),\n",
    "])\n",
    "\n",
    "letters_dataset = ImageFolder(DATA_DIR / \"images/eng_handwritten\", transform=base_transform)\n",
    "save_dataset_dir = DATA_DIR / \"images/eng_handwritten_48\"\n",
    "preprocess_images(letters_dataset, save_dataset_dir)\n",
    "letters_dataset = ImageFolder(save_dataset_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vc = pd.value_counts(letters_dataset.targets)\n",
    "vc.index = [letters_dataset.classes[i] for i in vc.index]\n",
    "vc.plot.bar(rot=0, figsize=(5, 3));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "show_sample_images(letters_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    *base_transform.transforms,\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomVerticalFlip(p=0.25),\n",
    "    transforms.RandomRotation(degrees=(-30, 30)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    *base_transform.transforms,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "])\n",
    "\n",
    "train_dataset, test_dataset = torch_train_test_split(letters_dataset, test_size=0.2)\n",
    "train_dataset.dataset = copy.deepcopy(train_dataset.dataset)\n",
    "train_dataset.dataset.transform = train_transform\n",
    "test_dataset.dataset = copy.deepcopy(test_dataset.dataset)\n",
    "test_dataset.dataset.transform = test_transform\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Построение и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_weights(targets: torch.Tensor) -> torch.Tensor:\n",
    "    _, counts = targets.unique(return_counts=True)\n",
    "    return counts.max() / counts\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        test_dataloader: DataLoader,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[t.List[float], t.List[float], t.List[float], t.List[float]]:\n",
    "    train_losses, train_accuracy_list = [], []\n",
    "    test_losses, test_accuracy_list = [], []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "\n",
    "        train_loss, train_accuracy = train_loop(train_dataloader, model, loss_fn, optimizer, verbose, device)\n",
    "        print(f\"Train Error: loss: {train_loss:.6f}, accuracy: {train_accuracy:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "        test_loss, test_accuracy = test_loop(test_dataloader, model, loss_fn, device)\n",
    "        print(f\" Test Error: loss: {test_loss:.6f}, accuracy: {test_accuracy:.4f}\\n\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses, train_accuracy_list, test_losses, test_accuracy_list\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = None,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, avg_accuracy = 0, 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true = torch.flatten(y).detach().cpu()\n",
    "        y_pred = torch.flatten(pred.argmax(1)).detach().cpu()\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "        avg_loss += loss\n",
    "        avg_accuracy += accuracy\n",
    "        if verbose and batch % verbose == 0:\n",
    "            print(f\"[{batch * len(x):>4d}/{size:>4d}]: loss: {loss:.6f}, accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return (avg_loss / num_batches).item(), avg_accuracy / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[float, float]:\n",
    "    model.eval()\n",
    "    y_true, y_pred = get_y_true_y_pred(model, dataloader, device)\n",
    "    return loss_fn(y_pred, y_true).item(), metrics.accuracy_score(y_true.cpu(), y_pred.argmax(1).cpu())\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_true_y_pred(\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: str = CPU,\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        y_test.append(y.unsqueeze(1))\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.flatten(torch.vstack(y_test)), torch.vstack(y_pred)\n",
    "\n",
    "\n",
    "def plot_train_test(\n",
    "        train_losses: t.List[float],\n",
    "        train_accuracy: t.List[float],\n",
    "        test_losses: t.List[float],\n",
    "        test_accuracy: t.List[float],\n",
    ") -> None:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 7))\n",
    "    epochs = torch.arange(len(train_losses))\n",
    "\n",
    "    axes[0].plot(epochs, train_losses)\n",
    "    axes[0].plot(epochs, test_losses)\n",
    "    axes[0].set_ylabel(\"loss\")\n",
    "    axes[0].legend([\"train\", \"test\"])\n",
    "\n",
    "    axes[1].plot(epochs, train_accuracy)\n",
    "    axes[1].plot(epochs, test_accuracy)\n",
    "    axes[1].set_xlabel(\"epoch\")\n",
    "    axes[1].set_ylabel(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CharsClassifier(nn.Module):\n",
    "    LAST_CONV_OUT_CHANNELS = 64\n",
    "    ADAPTIVE_AVG_POOL = 4\n",
    "\n",
    "    def __init__(self, num_channels: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=self.LAST_CONV_OUT_CHANNELS, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.LAST_CONV_OUT_CHANNELS),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((self.ADAPTIVE_AVG_POOL, self.ADAPTIVE_AVG_POOL))\n",
    "        self.classifier = nn.Linear(\n",
    "            self.LAST_CONV_OUT_CHANNELS * self.ADAPTIVE_AVG_POOL * self.ADAPTIVE_AVG_POOL,\n",
    "            num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = CharsClassifier(\n",
    "    num_channels=train_dataset[0][0].size(0),\n",
    "    num_classes=len(letters_dataset.classes),\n",
    ").to(DEVICE)\n",
    "weights = get_weights(torch.tensor([target for _, target in train_dataset], device=DEVICE))\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, num_workers=2)\n",
    "\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_losses, train_accuracy, test_losses, test_accuracy = common_train(\n",
    "        epochs=40,\n",
    "        model=net,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        device=DEVICE,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка и выводы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_train_test(train_losses, train_accuracy, test_losses, test_accuracy)  # noqa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true, y_pred = get_y_true_y_pred(net, test_dataloader, DEVICE)\n",
    "y_true, y_pred = y_true.cpu(), y_pred.argmax(1).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    display_labels=letters_dataset.classes,\n",
    "    colorbar=False,\n",
    "    xticks_rotation=0,\n",
    "    cmap=sns.color_palette('light:b', as_cmap=True)\n",
    ")\n",
    "cm_display.ax_.grid(False)\n",
    "cm_display.figure_.set_size_inches(8, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, target_names=letters_dataset.classes, zero_division=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "_, axes = plt.subplots(3, 3, figsize=(6, 7))\n",
    "for i, ax in zip(torch.randperm(len(test_dataset)), axes.flatten()):\n",
    "    img, _ = letters_dataset[test_dataset.indices[i]]  # картинка до нормализации\n",
    "\n",
    "    x, target = test_dataset[i]\n",
    "    pred = net(x.unsqueeze(0).to(DEVICE))\n",
    "\n",
    "    pred_proba = torch.max(torch.softmax(pred, 1))\n",
    "    pred_label = pred.argmax(1).item()\n",
    "    ax.set_title(\n",
    "        f\"pred: {letters_dataset.classes[pred_label]} ({pred_proba:.2f})\"\n",
    "        f\"\\ntrue: {letters_dataset.classes[target]}\", loc=\"left\"\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "    if img.mode == \"RGB\":\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        ax.imshow(img, cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
