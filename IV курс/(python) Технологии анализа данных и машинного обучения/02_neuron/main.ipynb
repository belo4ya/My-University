{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Создание нейронной сети без использования готовых решений\n",
    "\n",
    "__Автор__: Никита Владимирович Блохин (NVBlokhin@fa.ru)\n",
    "\n",
    "Финансовый университет, 2020 г. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "id": "PqC4R7SGseKa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J2RM8f5wP33"
   },
   "source": [
    "## 1. Создание нейронов и полносвязных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2ArJn_nsdZC"
   },
   "source": [
    "1.1. Используя операции над матрицами и векторами из библиотеки `torch`, реализовать нейрон с заданными весами `weights` и `bias`. Прогнать вектор `inputs` через нейрон и вывести результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "id": "f4agkY9WqPwe"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return torch.matmul(self.weights, inputs) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "id": "HJRkSkHHsb7u"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n",
    "bias = torch.tensor(3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron.forward: 4.840000152587891\n",
      "functional.linear: 4.840000152587891\n"
     ]
    }
   ],
   "source": [
    "neuron = Neuron(weights, bias)\n",
    "print(f'Neuron.forward: {neuron.forward(inputs)}')\n",
    "print(f'functional.linear: {F.linear(inputs, weights, bias)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qJvnwiyty37"
   },
   "source": [
    "1.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой с заданными весами `weights` и `biases`. Прогнать вектор `inputs` через слой и вывести результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "id": "fVWF3a9vtx90"
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return torch.matmul(inputs, self.weights.T) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "id": "Fo-JFnHPuFCS"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "weights = torch.tensor([[-0.2, 0.3, -0.5, 0.7],\n",
    "                        [0.5, -0.91, 0.26, -0.5],\n",
    "                        [-0.26, -0.27, 0.17, 0.87]])  # .T - здесь точно Транспонирование нужно?\n",
    "\n",
    "biases = torch.tensor([3.14, 2.71, 7.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear.forward:\n",
      "tensor([ 4.8400,  0.1700, 10.3900])\n",
      "\n",
      "functional.linear:\n",
      "tensor([ 4.8400,  0.1700, 10.3900])\n"
     ]
    }
   ],
   "source": [
    "m = Linear(weights, biases)\n",
    "print(f'Linear.forward:\\n{m.forward(inputs)}')\n",
    "print(f'\\nfunctional.linear:\\n{F.linear(inputs, weights, biases)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQtsJzcxuyGd"
   },
   "source": [
    "1.3 Реализовать полносвязный слой из __1.2__ таким образом, чтобы он мог принимать на вход матрицу (батч) с данными. Продемонстрировать работу.\n",
    "Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "id": "Z8IizmtsuhO1"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear.forward:\n",
      "tensor([[ 3.7900,  0.9200,  9.0850],\n",
      "        [ 6.1400, -2.1000,  6.9000],\n",
      "        [ 2.0400,  0.7610,  6.7260]])\n",
      "\n",
      "functional.linear:\n",
      "tensor([[ 3.7900,  0.9200,  9.0850],\n",
      "        [ 6.1400, -2.1000,  6.9000],\n",
      "        [ 2.0400,  0.7610,  6.7260]])\n"
     ]
    }
   ],
   "source": [
    "m = Linear(weights, biases)\n",
    "print(f'Linear.forward:\\n{m.forward(inputs)}')\n",
    "print(f'\\nfunctional.linear:\\n{F.linear(inputs, weights, biases)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ2OxH4_vBLu"
   },
   "source": [
    "1.4 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения). Прогнать вектор `inputs` через слой и вывести результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "id": "IOv52EdovASs"
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, n_features, n_neurons):\n",
    "        self.n_features = n_features\n",
    "        self.n_neurons = n_neurons\n",
    "\n",
    "        self.weights = torch.randn(n_neurons, n_features)\n",
    "        self.biases = torch.randn(n_neurons)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return torch.matmul(inputs, self.weights.T) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ -5.0178,   0.5240,  -3.9319],\n        [  4.0738,  -6.7887,  -3.5657],\n        [-11.6052,  -0.3882,  -3.1959]])"
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "m = Linear(4, 3)\n",
    "m.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ -5.0178,   0.5240,  -3.9319],\n        [  4.0738,  -6.7887,  -3.5657],\n        [-11.6052,  -0.3882,  -3.1959]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка\n",
    "nn_m = nn.Linear(4, 3)\n",
    "nn_m.weight = nn.Parameter(m.weights)\n",
    "nn_m.bias = nn.Parameter(m.biases)\n",
    "nn_m.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPG4UqL4wajI"
   },
   "source": [
    "1.5 Используя решение из __1.4__, создать 2 полносвязных слоя и пропустить матрицу `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выбрать произвольно, количество нейронов во втором слое выбрать так, чтобы результатом прогона являлась матрица (3x7). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "RjjQIQlTxJE6"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.h1 = Linear(4, 3)\n",
    "        self.o1 = Linear(3, 7)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.o1.forward(self.h1.forward(inputs))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  5.1553,   1.1916,  -4.7817,   3.6611,  -9.6546,   0.1692,   5.8099],\n        [ -0.8347,   0.0913,   3.1227,   3.5542,   5.4400,   4.9157,   8.2533],\n        [  8.8057,  -1.1342,  -7.8488,   6.7415, -11.1044,   5.1500,   5.6152]])"
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "m = NeuralNetwork()\n",
    "m.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDgJRHjuyArfKO8ZT68MsS",
   "name": "02_NN_blocks_backprop_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
