{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π\n",
    "\n",
    "__–ê–≤—Ç–æ—Ä__: –ù–∏–∫–∏—Ç–∞ –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á –ë–ª–æ—Ö–∏–Ω (NVBlokhin@fa.ru)\n",
    "\n",
    "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç, 2020 –≥. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "PqC4R7SGseKa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "torch.set_warn_always(True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J2RM8f5wP33"
   },
   "source": [
    "## 1. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–æ–≤ –∏ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ–µ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2ArJn_nsdZC"
   },
   "source": [
    "1.1. –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ `weights` –∏ `bias`. –ü—Ä–æ–≥–Ω–∞—Ç—å –≤–µ–∫—Ç–æ—Ä `inputs` —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "f4agkY9WqPwe"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, weights: torch.Tensor, bias: torch.Tensor):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(inputs * self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "HJRkSkHHsb7u"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n",
    "bias = torch.tensor(3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron.forward: 4.840000152587891\n",
      "functional.linear: 4.840000152587891\n"
     ]
    }
   ],
   "source": [
    "neuron = Neuron(weights, bias)\n",
    "print(f'Neuron.forward: {neuron.forward(inputs)}')\n",
    "print(f'functional.linear: {F.linear(inputs, weights, bias)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qJvnwiyty37"
   },
   "source": [
    "1.2 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ `weights` –∏ `biases`. –ü—Ä–æ–≥–Ω–∞—Ç—å –≤–µ–∫—Ç–æ—Ä `inputs` —á–µ—Ä–µ–∑ —Å–ª–æ–π –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "fVWF3a9vtx90"
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, weights: torch.Tensor, biases: torch.Tensor):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(inputs, self.weights.T) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "Fo-JFnHPuFCS"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "weights = torch.tensor([[-0.2, 0.3, -0.5, 0.7],\n",
    "                        [0.5, -0.91, 0.26, -0.5],\n",
    "                        [-0.26, -0.27, 0.17, 0.87]])  # —É–±—Ä–∞–ª .T\n",
    "\n",
    "biases = torch.tensor([3.14, 2.71, 7.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear.forward:\n",
      "tensor([ 4.8400,  0.1700, 10.3900])\n",
      "\n",
      "functional.linear:\n",
      "tensor([ 4.8400,  0.1700, 10.3900])\n"
     ]
    }
   ],
   "source": [
    "m = Linear(weights, biases)\n",
    "print(f'Linear.forward:\\n{m.forward(inputs)}')\n",
    "print(f'\\nfunctional.linear:\\n{F.linear(inputs, weights, biases)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQtsJzcxuyGd"
   },
   "source": [
    "1.3 –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π –∏–∑ __2.1.2__ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –æ–Ω –º–æ–≥ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É (–±–∞—Ç—á) —Å –¥–∞–Ω–Ω—ã–º–∏. –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É.\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø—Ä–æ–≥–æ–Ω–∞ —Å–∫–≤–æ–∑—å —Å–ª–æ–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ `batch_size` x `n_neurons`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "Z8IizmtsuhO1"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear.forward:\n",
      "tensor([[ 3.7900,  0.9200,  9.0850],\n",
      "        [ 6.1400, -2.1000,  6.9000],\n",
      "        [ 2.0400,  0.7610,  6.7260]])\n",
      "\n",
      "functional.linear:\n",
      "tensor([[ 3.7900,  0.9200,  9.0850],\n",
      "        [ 6.1400, -2.1000,  6.9000],\n",
      "        [ 2.0400,  0.7610,  6.7260]])\n"
     ]
    }
   ],
   "source": [
    "m = Linear(weights, biases)\n",
    "print(f'Linear.forward:\\n{m.forward(inputs)}')\n",
    "print(f'\\nfunctional.linear:\\n{F.linear(inputs, weights, biases)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ2OxH4_vBLu"
   },
   "source": [
    "1.4 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π –∏–∑ `n_neurons` –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å `n_features` –≤–µ—Å–∞–º–∏ —É –∫–∞–∂–¥–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–∞ (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è). –ü—Ä–æ–≥–Ω–∞—Ç—å –≤–µ–∫—Ç–æ—Ä `inputs` —á–µ—Ä–µ–∑ —Å–ª–æ–π –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø—Ä–æ–≥–æ–Ω–∞ —Å–∫–≤–æ–∑—å —Å–ª–æ–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ `batch_size` x `n_neurons`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "IOv52EdovASs"
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.weights = torch.randn(out_features, in_features, requires_grad=True)\n",
    "        self.biases = torch.randn(out_features, requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(inputs, self.weights.T) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ -5.0178,   0.5240,  -3.9319],\n        [  4.0738,  -6.7887,  -3.5657],\n        [-11.6052,  -0.3882,  -3.1959]], grad_fn=<AddBackward0>)"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "m = Linear(4, 3)\n",
    "m.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ -5.0178,   0.5240,  -3.9319],\n        [  4.0738,  -6.7887,  -3.5657],\n        [-11.6052,  -0.3882,  -3.1959]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "nn_m = nn.Linear(4, 3)\n",
    "nn_m.weight = nn.Parameter(m.weights)\n",
    "nn_m.bias = nn.Parameter(m.biases)\n",
    "nn_m.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPG4UqL4wajI"
   },
   "source": [
    "1.5 –ò—Å–ø–æ–ª—å–∑—É—è —Ä–µ—à–µ–Ω–∏–µ –∏–∑ __1.4__, —Å–æ–∑–¥–∞—Ç—å 2 –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ—è –∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É `inputs` –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ —ç—Ç–∏ –¥–≤–∞ —Å–ª–æ—è. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ –≤—ã–±—Ä–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤–æ –≤—Ç–æ—Ä–æ–º —Å–ª–æ–µ –≤—ã–±—Ä–∞—Ç—å —Ç–∞–∫, —á—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø—Ä–æ–≥–æ–Ω–∞ —è–≤–ª—è–ª–∞—Å—å –º–∞—Ç—Ä–∏—Ü–∞ (3x7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input = Linear(4, 3)\n",
    "        self.output = Linear(3, 7)\n",
    "\n",
    "    def forward(self, inputs) -> torch.Tensor:\n",
    "        return self.output.forward(self.input.forward(inputs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  5.1553,   1.1916,  -4.7817,   3.6611,  -9.6546,   0.1692,   5.8099],\n        [ -0.8347,   0.0913,   3.1227,   3.5542,   5.4400,   4.9157,   8.2533],\n        [  8.8057,  -1.1342,  -7.8488,   6.7415, -11.1044,   5.1500,   5.6152]],\n       grad_fn=<AddBackward0>)"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "m = NeuralNet()\n",
    "m.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRVH_2K7xTBC"
   },
   "source": [
    "## 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "def randn(*size: int, seed: int = 0) -> torch.Tensor:\n",
    "    torch.manual_seed(seed)\n",
    "    return torch.randn(*size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9kngE6Fxs9D"
   },
   "source": [
    "2.1 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ReLU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n",
    "\n",
    "–°–æ–∑–¥–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Ä–∞–∑–º–µ—Ä–∞ (4,3), –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—É—é —á–∏—Å–ª–∞–º–∏ –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "jZLvMRByxSTC"
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.maximum(inputs, torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.5410, -0.2934, -2.1788],\n        [ 0.5684, -1.0845, -1.3986],\n        [ 0.4033,  0.8380, -0.7193],\n        [-0.4033, -0.5966,  0.1820]])"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = randn(4, 3)\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU:\n",
      "tensor([[1.5410, 0.0000, 0.0000],\n",
      "        [0.5684, 0.0000, 0.0000],\n",
      "        [0.4033, 0.8380, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1820]])\n",
      "\n",
      "nn.ReLU:\n",
      "tensor([[1.5410, 0.0000, 0.0000],\n",
      "        [0.5684, 0.0000, 0.0000],\n",
      "        [0.4033, 0.8380, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1820]])\n"
     ]
    }
   ],
   "source": [
    "relu = ReLU()\n",
    "nn_relu = nn.ReLU()\n",
    "print(f'ReLU:\\n{relu.forward(inputs)}')\n",
    "print(f'\\nnn.ReLU:\\n{nn_relu.forward(inputs)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puExCWiKyTtb"
   },
   "source": [
    "2.2 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ softmax:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n",
    "\n",
    "–°–æ–∑–¥–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Ä–∞–∑–º–µ—Ä–∞ (4,3), –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—É—é —á–∏—Å–ª–∞–º–∏ –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. –°—Ç—Ä–æ–∫–∏ –º–∞—Ç—Ä–∏—Ü—ã —Ç—Ä–∞–∫—Ç–æ–≤–∞—Ç—å –∫–∞–∫ –≤—ã—Ö–æ–¥—ã –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è 4 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "fXNcFlqqyKHl"
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "\n",
    "    def __init__(self, dim: int = 0):\n",
    "        assert dim == 0 or dim == 1\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        exp = torch.exp(inputs)\n",
    "        return exp / torch.sum(exp, dim=self.dim).unsqueeze(self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.5410, -0.2934, -2.1788],\n        [ 0.5684, -1.0845, -1.3986],\n        [ 0.4033,  0.8380, -0.7193],\n        [-0.4033, -0.5966,  0.1820]])"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = randn(4, 3)\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax:\n",
      "tensor([[0.8446, 0.1349, 0.0205],\n",
      "        [0.7511, 0.1438, 0.1051],\n",
      "        [0.3484, 0.5382, 0.1134],\n",
      "        [0.2762, 0.2277, 0.4961]])\n",
      "\n",
      "nn.Softmax:\n",
      "tensor([[0.8446, 0.1349, 0.0205],\n",
      "        [0.7511, 0.1438, 0.1051],\n",
      "        [0.3484, 0.5382, 0.1134],\n",
      "        [0.2762, 0.2277, 0.4961]])\n"
     ]
    }
   ],
   "source": [
    "softmax = Softmax(dim=1)\n",
    "nn_softmax = nn.Softmax(dim=1)\n",
    "print(f'Softmax:\\n{softmax.forward(inputs)}')\n",
    "print(f'\\nnn.Softmax:\\n{nn_softmax.forward(inputs)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxVK2TYez_Ye"
   },
   "source": [
    "2.3 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ELU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n",
    "\n",
    "–°–æ–∑–¥–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Ä–∞–∑–º–µ—Ä–∞ (4,3), –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—É—é —á–∏—Å–ª–∞–º–∏ –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "NzMz7HDLySxK"
   },
   "outputs": [],
   "source": [
    "class ELU:\n",
    "\n",
    "    def __init__(self, alpha: float = 1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.where(inputs > 0, inputs, self.alpha * (torch.exp(inputs) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.5410, -0.2934, -2.1788],\n        [ 0.5684, -1.0845, -1.3986],\n        [ 0.4033,  0.8380, -0.7193],\n        [-0.4033, -0.5966,  0.1820]])"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = randn(4, 3)\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELU:\n",
      "tensor([[ 1.5410, -0.3583, -1.2495],\n",
      "        [ 0.5684, -0.9327, -1.0611],\n",
      "        [ 0.4033,  0.8380, -0.7227],\n",
      "        [-0.4677, -0.6331,  0.1820]])\n",
      "\n",
      "nn.ELU:\n",
      "tensor([[ 1.5410, -0.3583, -1.2495],\n",
      "        [ 0.5684, -0.9327, -1.0611],\n",
      "        [ 0.4033,  0.8380, -0.7227],\n",
      "        [-0.4677, -0.6331,  0.1820]])\n"
     ]
    }
   ],
   "source": [
    "elu = ELU(alpha=1.409)\n",
    "nn_elu = nn.ELU(alpha=1.409)\n",
    "print(f'ELU:\\n{elu.forward(inputs)}')\n",
    "print(f'\\nnn.ELU:\\n{nn_elu.forward(inputs)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0peh8r-20Pof"
   },
   "source": [
    "## 3. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY-k3eEs0f7f"
   },
   "source": [
    "3.1 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å MSE:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n",
    "\n",
    "–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å 1 –Ω–µ–π—Ä–æ–Ω–æ–º, –ø—Ä–æ–≥–Ω–∞—Ç—å —á–µ—Ä–µ–∑ –Ω–µ–≥–æ –±–∞—Ç—á `inputs` –∏ –ø–æ—Å—á–∏—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ MSE, —Ç—Ä–∞–∫—Ç—É—è –≤–µ–∫—Ç–æ—Ä `y` –∫–∞–∫ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "f9-wdj5Tz-br"
   },
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "id": "NAyuDU9F1Vuz"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "y = torch.tensor([2, 3, 4]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "layer = Linear(4, 1)\n",
    "y_pred = layer.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss:\n",
      "101.30004119873047\n",
      "\n",
      "nn.MSELoss:\n",
      "101.30004119873047\n"
     ]
    }
   ],
   "source": [
    "mse = MSELoss()\n",
    "nn_mse = nn.MSELoss()\n",
    "print(f'MSELoss:\\n{mse.forward(y_pred, y)}')\n",
    "print(f'\\nnn.MSELoss:\\n{nn_mse.forward(y_pred, y)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaR7rILd1eWR"
   },
   "source": [
    "3.2 –ò—Å–ø–æ–ª—å–∑—É—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `torch`, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å Categorical Cross-Entropy:\n",
    "\n",
    "<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n",
    "\n",
    "–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å 3 –Ω–µ–π—Ä–æ–Ω–∞–º–∏ –∏ –ø—Ä–æ–≥–Ω–∞—Ç—å —á–µ—Ä–µ–∑ –Ω–µ–≥–æ –±–∞—Ç—á `inputs`. –ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ softmax. –ü–æ—Å—á–∏—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ CCE, —Ç—Ä–∞–∫—Ç—É—è –≤–µ–∫—Ç–æ—Ä `y` –∫–∞–∫ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "hQl8pJsT3HcF"
   },
   "outputs": [],
   "source": [
    "class CategoricalCrossEntropyLoss:\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.sum(y_true * torch.log(y_pred), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "s7Qoupfo1ZGJ"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "y = torch.tensor([1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "layer = Linear(4, 3)\n",
    "softmax = Softmax()\n",
    "y_pred = softmax.forward(layer.forward(inputs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([9.0918e+00, 1.1272e-04, 1.5679e+01], grad_fn=<NegBackward0>)"
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce = CategoricalCrossEntropyLoss()\n",
    "cce.forward(y_pred, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.3 –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å 2.3.1, –¥–æ–±–∞–≤–∏–≤ L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é.\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d92ca2429275bfdc0474523babbafe014ca8b580)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "class MSELossL2:\n",
    "\n",
    "    def __init__(self, lambda_: float, weights: torch.Tensor):\n",
    "        self.lambda_ = lambda_\n",
    "        self.weights = weights\n",
    "\n",
    "    def data_loss(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum((y_true - y_pred) ** 2)\n",
    "\n",
    "    def reg_loss(self) -> torch.Tensor:\n",
    "        return self.lambda_ * torch.sum(self.weights ** 2)\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.data_loss(y_pred, y_true) + self.reg_loss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "y = torch.tensor([2, 3, 4]).unsqueeze(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "layer = Linear(4, 1)\n",
    "y_pred = layer.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(314.5113, grad_fn=<AddBackward0>)"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_l2 = MSELossL2(lambda_=1.409, weights=layer.weights)\n",
    "mse_l2.forward(y_pred, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.1 –ò—Å–ø–æ–ª—å–∑—É—è –æ–¥–∏–Ω –Ω–µ–π—Ä–æ–Ω –∏ SGD (1 –ø—Ä–∏–º–µ—Ä –∑–∞ —à–∞–≥), —Ä–µ—à–∏—Ç–µ –∑–∞–¥–∞—á—É —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y, coef = make_regression(n_features=4, n_informative=4, coef=True, bias=0.5, random_state=0)\n",
    "# X.dtype == float64 - –Ω–µ—Ç —Å–º—ã—Å–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å torch.from_numpy\n",
    "# —Ç.–∫. –ø–æ—Å–ª–µ–¥—É—é—â–µ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ Tensor.type(torch.float32) –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[–ì—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏](https://i.ibb.co/2dhDxZx/photo-2021-02-15-17-18-04.jpg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.1.1 –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å `MSELoss` –∏–∑ __2.3.1__, —Ä–µ–∞–ª–∏–∑–æ–≤–∞–≤ —Ä–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–ª–æ—è\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return (y_pred - y_true) ** 2  # –∫–æ–≥–¥–∞ MSE (mean squared error) –±–µ–∑ mean\n",
    "\n",
    "    def backward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        # –∑–¥—Ä–∞–≤–∞—è –º—ã—Å–ª—å - –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é MSE, —Ç–æ–ª—å–∫–æ mean –ø–æ—Ç–µ—Ä—è–ª–∞—Å—å,\n",
    "        # —Ç.–∫. –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –æ–¥–Ω–æ–º—É –æ—Ç–≤–µ—Ç—É –∑–∞ —à–∞–≥\n",
    "        return 2 * (y_pred - y_true)  # df/dc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.1.2. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å `Neuron` –∏–∑ __2.1.1__:\n",
    "\n",
    "  1) –°–¥–µ–ª–∞–π—Ç–µ —Ç–∞–∫, —á—Ç–æ–±—ã –≤–µ—Å–∞ –Ω–µ–π—Ä–æ–Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "\n",
    "  2) –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ä–∞—Å—á–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤–µ—Å–æ–≤ `weights` –∏ `bias`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "L0KqxPJU9kAN"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, in_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.weights = torch.randn(self.in_features)\n",
    "        self.bias = torch.randn(1)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(inputs * self.weights) + self.bias\n",
    "\n",
    "    def backward(self, dvalue: torch.Tensor, inputs: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        dweights = dvalue * 1  # df/dw\n",
    "        dbias = dvalue * 1  # df/db\n",
    "        dinputs = dbias * self.weights  # df/dx\n",
    "        return dvalue * inputs, dvalue  # —Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç (—Ç–∏–ø–∞ –Ω–∞ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–µ–º —Å–ª–æ–µ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKcO4zOLACxM"
   },
   "source": [
    "4.1.3 –î–æ–ø–∏—à–∏—Ç–µ —Ü–∏–∫–ª –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Å–æ–≤ –Ω–µ–π—Ä–æ–Ω–∞\n",
    "\n",
    "[SGD](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA)\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/dda3670f8a8996a0d3bf80856bb4a166cc8db6d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "def pretty_train_log(epoch: int, **kwargs) -> None:\n",
    "    params = '\\n\\t'.join([f'{k} = {v}' for k, v in kwargs.items()])\n",
    "    print(f'epoch {epoch:03} |' + '-' * 50 + f'\\n\\t{params}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "_g_FvwvmALJd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([ 5.8937,  3.4480,  8.5208, -6.0718])\n",
      "\tdw = tensor([ -43.5271,  -37.4140, -106.9956,   66.4020])\n",
      "\tbias = tensor([-9.6251])\n",
      "\tdb = tensor([85.4055])\n",
      "\tloss = tensor([1823.5259])\n",
      "\n",
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([21.6376, 36.3937, 65.8168, 88.4170])\n",
      "\tdw = tensor([9.4374, 2.5177, 7.3150, 2.5319])\n",
      "\tbias = tensor([1.1639])\n",
      "\tdb = tensor([7.9437])\n",
      "\tloss = tensor([15.7756])\n",
      "\n",
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.5037, 34.1982, 67.6044, 87.9179])\n",
      "\tdw = tensor([ 0.0004,  0.0003, -0.0005,  0.0003])\n",
      "\tbias = tensor([0.4687])\n",
      "\tdb = tensor([0.0006])\n",
      "\tloss = tensor([1.0514e-07])\n",
      "\n",
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4878, 34.1696, 67.6197, 87.9236])\n",
      "\tdw = tensor([-0.0058,  0.0145,  0.0002,  0.0066])\n",
      "\tbias = tensor([0.5022])\n",
      "\tdb = tensor([-0.0090])\n",
      "\tloss = tensor([2.0193e-05])\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10])\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235])\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11])\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12])\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([0., -0., -0., -0.])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.])\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10])\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235])\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11])\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12])\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([0., -0., -0., -0.])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.])\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10])\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235])\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11])\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12])\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([0., -0., -0., -0.])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.])\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10])\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235])\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11])\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12])\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235])\n",
      "\tdw = tensor([0., -0., -0., -0.])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([20.4924, 34.1698, 67.6242, 87.9235]),\n array([20.4923687 , 34.16981149, 67.62424823, 87.9234763 ]))"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ —á–∞—Å—ã üïì...\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_inputs = X.size(1)  # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—ã–±–æ—Ä–∫–∏\n",
    "learning_rate = 0.1  #  —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è\n",
    "n_epoch = 100  #  –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "\n",
    "y_true = y.unsqueeze(1)\n",
    "\n",
    "neuron = Neuron(n_inputs)\n",
    "loss = MSELoss()\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    for i, (x_example, y_example) in enumerate(zip(X, y_true), start=1):\n",
    "        # forward pass\n",
    "        y_pred = neuron.forward(x_example)  # –ø—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω\n",
    "        curr_loss = loss.forward(y_pred, y_example)  # –ø—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å\n",
    "\n",
    "        # backprop\n",
    "        # –≤—ã–∑–æ–≤ –º–µ—Ç–æ–¥–æ–≤ backward\n",
    "        dw, db = neuron.backward(loss.backward(y_pred, y_example), x_example)\n",
    "        # –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–∑–æ–≤–æ–≤: –æ—Ç –∫–æ–Ω—Ü–∞ –∫ –Ω–∞—á–∞–ª—É\n",
    "\n",
    "        # —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≤–µ—Å–æ–≤ (weights –∏ bias) –Ω–µ–π—Ä–æ–Ω–∞\n",
    "        neuron.weights -= learning_rate * dw\n",
    "        neuron.bias -= learning_rate * db\n",
    "\n",
    "        if (epoch - 1) % 20 == 0 and (i - 1) % 30 == 0:\n",
    "            pretty_train_log(epoch, i=i, weights=neuron.weights, dw=dw, bias=neuron.bias, db=db, loss=curr_loss)\n",
    "\n",
    "neuron.weights, coef"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "–°—É–¥—è –ø–æ –≤—ã–≤–æ–¥—É –∑–∞–¥–∞—á–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –±—ã–ª–∞ —Ä–µ—à–µ–Ω–∞ –µ—â–µ –≤ –∫–æ–Ω—Ü–µ 1-–æ–π —ç–ø–æ—Ö–∏ (–ø–µ—Ä–≤–æ–±—ã—Ç–Ω–æ—Å—Ç–∏).\n",
    "–ó–∞—á–µ–º —Ç–æ–≥–¥–∞ –ø–∞–∫–µ—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫, –µ—Å–ª–∏ —ç—Ç–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ?\n",
    "\n",
    "–ó–∞—á–µ–º –º—ã —ç—Ç–æ –≤—Å–µ –¥–µ–ª–∞–ª–∏ –∏ –ø–æ—á–µ–º—É –Ω–∞–∑—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ–º, –µ—Å–ª–∏ —É–∂–µ –∑–Ω–∞–µ–º –≤—Å—é –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**–ü—Ä–æ–≤–µ—Ä–∫–∞**\n",
    "\n",
    "–°–¥–µ–ª–∞–µ–º —Ç–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ –ø—É—Å—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é –ø–æ—Å—á–∏—Ç–∞–µ—Ç pytorch (—á–µ—Å—Ç–Ω–æ, –±—É–¥—Ç–æ –Ω–µ –∑–Ω–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é —Å–ª–æ–∂–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._last_forward: torch.Tensor | None = None\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        self._last_forward = (y_pred - y_true) ** 2\n",
    "        return self._last_forward\n",
    "\n",
    "    def backward(self) -> None:\n",
    "        self._last_forward.backward()\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "\n",
    "    def __init__(self, in_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.weights = torch.randn(self.in_features, requires_grad=True)\n",
    "        self.bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(inputs * self.weights) + self.bias\n",
    "\n",
    "    def backward(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        dw = self.weights.grad.clone().detach()\n",
    "        db = self.bias.grad.clone().detach()\n",
    "        self.weights.grad.zero_()\n",
    "        self.bias.grad.zero_()\n",
    "        return dw, db\n",
    "\n",
    "    def update_weights(self, lr: float, dw: torch.Tensor, db: torch.Tensor) -> None:\n",
    "        with torch.no_grad():\n",
    "            self.weights -= lr * dw\n",
    "            self.bias -= lr * db"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([ 5.8937,  3.4480,  8.5208, -6.0718], requires_grad=True)\n",
      "\tdw = tensor([ -43.5271,  -37.4140, -106.9956,   66.4020])\n",
      "\tbias = tensor([-9.6251], requires_grad=True)\n",
      "\tdb = tensor([85.4055])\n",
      "\tloss = tensor([1823.5259], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([21.6376, 36.3937, 65.8168, 88.4170], requires_grad=True)\n",
      "\tdw = tensor([9.4374, 2.5177, 7.3150, 2.5319])\n",
      "\tbias = tensor([1.1639], requires_grad=True)\n",
      "\tdb = tensor([7.9437])\n",
      "\tloss = tensor([15.7756], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.5037, 34.1982, 67.6044, 87.9179], requires_grad=True)\n",
      "\tdw = tensor([ 0.0004,  0.0003, -0.0005,  0.0003])\n",
      "\tbias = tensor([0.4687], requires_grad=True)\n",
      "\tdb = tensor([0.0006])\n",
      "\tloss = tensor([1.0514e-07], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 001 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4878, 34.1696, 67.6197, 87.9236], requires_grad=True)\n",
      "\tdw = tensor([-0.0058,  0.0145,  0.0002,  0.0066])\n",
      "\tbias = tensor([0.5022], requires_grad=True)\n",
      "\tdb = tensor([-0.0090])\n",
      "\tloss = tensor([2.0193e-05], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 021 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([0., 0., 0., 0.])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 041 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([0., 0., 0., 0.])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 061 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([0., 0., 0., 0.])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 1\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.3330e-05, -2.0053e-05, -5.7348e-05,  3.5591e-05])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([4.5776e-05])\n",
      "\tloss = tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 31\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6242, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-1.8128e-05, -4.8362e-06, -1.4051e-05, -4.8634e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-1.5259e-05])\n",
      "\tloss = tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 61\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([-2.5646e-06, -1.5543e-06,  2.9370e-06, -2.0571e-06])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([-3.8147e-06])\n",
      "\tloss = tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 081 |--------------------------------------------------\n",
      "\ti = 91\n",
      "\tweights = tensor([20.4924, 34.1698, 67.6243, 87.9235], requires_grad=True)\n",
      "\tdw = tensor([0., 0., 0., 0.])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.], grad_fn=<PowBackward0>)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([20.4924, 34.1698, 67.6242, 87.9235], requires_grad=True),\n array([20.4923687 , 34.16981149, 67.62424823, 87.9234763 ]))"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "y_true = y.unsqueeze(1)\n",
    "\n",
    "neuron = Neuron(X.size(1))\n",
    "mse = MSELoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for i, (x_example, y_example) in enumerate(zip(X, y_true), start=1):\n",
    "        # feed forward\n",
    "        y_pred = neuron.forward(x_example)\n",
    "        loss = mse.forward(y_pred, y_example)\n",
    "\n",
    "        # backward\n",
    "        mse.backward()\n",
    "        dw, db = neuron.backward()\n",
    "\n",
    "        # optimize step\n",
    "        neuron.update_weights(learning_rate, dw, db)\n",
    "\n",
    "        if (epoch - 1) % 20 == 0 and (i - 1) % 30 == 0:\n",
    "            pretty_train_log(epoch, i=i, weights=neuron.weights, dw=dw, bias=neuron.bias, db=db, loss=loss)\n",
    "\n",
    "neuron.weights, coef"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._last_forward: torch.Tensor | None = None\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        self._last_forward = torch.mean((y_pred - y_true) ** 2)\n",
    "        return self._last_forward\n",
    "\n",
    "    def backward(self) -> None:\n",
    "        self._last_forward.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, in_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.weights = torch.randn(self.in_features, requires_grad=True)\n",
    "        self.bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(inputs * self.weights) + self.bias\n",
    "\n",
    "    def backward(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        dw = self.weights.grad.clone().detach()\n",
    "        db = self.bias.grad.clone().detach()\n",
    "        self.weights.grad.zero_()\n",
    "        self.bias.grad.zero_()\n",
    "        return dw, db\n",
    "\n",
    "    def update_weights(self, lr: float, dw: torch.Tensor, db: torch.Tensor) -> None:\n",
    "        with torch.no_grad():\n",
    "            self.weights -= lr * dw\n",
    "            self.bias -= lr * db"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10:\n",
      "\tdw = tensor([  0.0946,  -5.0925, -19.5831, -23.7725])\n",
      "\tw = tensor([22.8361, 35.1808, 56.8774, 77.7312], requires_grad=True)\n",
      "\tdb = tensor([-1.1937])\n",
      "\tb = tensor([-0.3279], requires_grad=True)\n",
      "\tloss = 273.2061462402344\n",
      "\n",
      "epoch 20:\n",
      "\tdw = tensor([ 1.2022,  1.0444, -3.6096, -2.9211])\n",
      "\tw = tensor([21.3865, 35.2819, 65.2723, 86.5805], requires_grad=True)\n",
      "\tdb = tensor([-0.2879])\n",
      "\tb = tensor([0.2734], requires_grad=True)\n",
      "\tloss = 8.566176414489746\n",
      "\n",
      "epoch 30:\n",
      "\tdw = tensor([ 0.3433,  0.4741, -0.8571, -0.4070])\n",
      "\tw = tensor([20.7266, 34.5308, 67.0295, 87.7218], requires_grad=True)\n",
      "\tdb = tensor([-0.0849])\n",
      "\tb = tensor([0.4255], requires_grad=True)\n",
      "\tloss = 0.48739707469940186\n",
      "\n",
      "epoch 40:\n",
      "\tdw = tensor([ 0.0871,  0.1401, -0.2223, -0.0644])\n",
      "\tw = tensor([20.5520, 34.2695, 67.4672, 87.8893], requires_grad=True)\n",
      "\tdb = tensor([-0.0294])\n",
      "\tb = tensor([0.4750], requires_grad=True)\n",
      "\tloss = 0.032591093331575394\n",
      "\n",
      "epoch 50:\n",
      "\tdw = tensor([ 0.0222,  0.0377, -0.0591, -0.0114])\n",
      "\tw = tensor([20.5077, 34.1962, 67.5823, 87.9171], requires_grad=True)\n",
      "\tdb = tensor([-0.0099])\n",
      "\tb = tensor([0.4920], requires_grad=True)\n",
      "\tloss = 0.002265702001750469\n",
      "\n",
      "epoch 60:\n",
      "\tdw = tensor([ 0.0057,  0.0099, -0.0158, -0.0022])\n",
      "\tw = tensor([20.4964, 34.1767, 67.6130, 87.9222], requires_grad=True)\n",
      "\tdb = tensor([-0.0031])\n",
      "\tb = tensor([0.4976], requires_grad=True)\n",
      "\tloss = 0.00015940135926939547\n",
      "\n",
      "epoch 70:\n",
      "\tdw = tensor([ 0.0015,  0.0026, -0.0042, -0.0005])\n",
      "\tw = tensor([20.4934, 34.1716, 67.6212, 87.9232], requires_grad=True)\n",
      "\tdb = tensor([-0.0009])\n",
      "\tb = tensor([0.4993], requires_grad=True)\n",
      "\tloss = 1.1334186638123356e-05\n",
      "\n",
      "epoch 80:\n",
      "\tdw = tensor([ 0.0004,  0.0007, -0.0011, -0.0001])\n",
      "\tw = tensor([20.4926, 34.1703, 67.6234, 87.9234], requires_grad=True)\n",
      "\tdb = tensor([-0.0003])\n",
      "\tb = tensor([0.4998], requires_grad=True)\n",
      "\tloss = 8.034064649109496e-07\n",
      "\n",
      "epoch 90:\n",
      "\tdw = tensor([ 1.0860e-04,  1.7978e-04, -3.0411e-04, -2.9911e-05])\n",
      "\tw = tensor([20.4924, 34.1699, 67.6240, 87.9235], requires_grad=True)\n",
      "\tdb = tensor([-7.3667e-05])\n",
      "\tb = tensor([0.4999], requires_grad=True)\n",
      "\tloss = 5.771409661292637e-08\n",
      "\n",
      "epoch 100:\n",
      "\tdw = tensor([ 2.4684e-05,  4.2315e-05, -9.1560e-05, -2.5875e-05])\n",
      "\tw = tensor([20.4924, 34.1698, 67.6242, 87.9235], requires_grad=True)\n",
      "\tdb = tensor([-2.1472e-05])\n",
      "\tb = tensor([0.5000], requires_grad=True)\n",
      "\tloss = 4.774629580595047e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "y_true = y.unsqueeze(1)\n",
    "\n",
    "neuron = Neuron(X.size(1))\n",
    "mse = MSELoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    y_pred = torch.empty(y_true.size())\n",
    "    for i, x in enumerate(X):\n",
    "        y_pred[i, 0] = neuron.forward(x)\n",
    "\n",
    "    loss = mse.forward(y_pred, y_true)\n",
    "\n",
    "    mse.backward()\n",
    "    dw, db = neuron.backward()\n",
    "    neuron.update_weights(learning_rate, dw, db)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch}:\\n'\n",
    "              f'\\tdw = {dw}\\n'\n",
    "              f'\\tw = {neuron.weights}\\n'\n",
    "              f'\\tdb = {db}\\n'\n",
    "              f'\\tb = {neuron.bias}\\n'\n",
    "              f'\\tloss = {loss}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–æ–π –∏–∑ 1 –Ω–µ–π—Ä–æ–Ω–∞ –∏ –ø–æ—á—Ç–∏ –≤—Å–µ –æ—Ç–¥–∞–µ–º pytorch –∫—Ä–æ–º–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50:\n",
      "\tdw = tensor([[ -6.0558, -15.0842, -33.4915, -42.9164]])\n",
      "\tw = tensor([[21.5726, 31.4347, 47.8225, 66.2012]], requires_grad=True)\n",
      "\tdb = tensor([-1.3325])\n",
      "\tb = tensor([-0.7389], requires_grad=True)\n",
      "\tloss = 838.6507568359375\n",
      "\n",
      "epoch 100:\n",
      "\tdw = tensor([[  1.1853,  -0.8189,  -9.8127, -10.7610]])\n",
      "\tw = tensor([[22.2123, 35.4245, 61.0621, 82.3018]], requires_grad=True)\n",
      "\tdb = tensor([-0.6651])\n",
      "\tb = tensor([-0.0315], requires_grad=True)\n",
      "\tloss = 64.63803100585938\n",
      "\n",
      "epoch 150:\n",
      "\tdw = tensor([[ 0.9964,  0.7865, -3.3318, -2.8093]])\n",
      "\tw = tensor([[21.3588, 35.1799, 65.2005, 86.4030]], requires_grad=True)\n",
      "\tdb = tensor([-0.2642])\n",
      "\tb = tensor([0.2715], requires_grad=True)\n",
      "\tloss = 7.178253650665283\n",
      "\n",
      "epoch 200:\n",
      "\tdw = tensor([[ 0.4676,  0.5566, -1.2485, -0.7666]])\n",
      "\tw = tensor([[20.8615, 34.6863, 66.6720, 87.4926]], requires_grad=True)\n",
      "\tdb = tensor([-0.1130])\n",
      "\tb = tensor([0.3947], requires_grad=True)\n",
      "\tloss = 1.0145002603530884\n",
      "\n",
      "epoch 250:\n",
      "\tdw = tensor([[ 0.1950,  0.2764, -0.4942, -0.2191]])\n",
      "\tw = tensor([[20.6428, 34.4022, 67.2383, 87.7956]], requires_grad=True)\n",
      "\tdb = tensor([-0.0529])\n",
      "\tb = tensor([0.4498], requires_grad=True)\n",
      "\tloss = 0.16036461293697357\n",
      "\n",
      "epoch 300:\n",
      "\tdw = tensor([[ 0.0789,  0.1229, -0.2010, -0.0655]])\n",
      "\tw = tensor([[20.5531, 34.2691, 67.4655, 87.8838]], requires_grad=True)\n",
      "\tdb = tensor([-0.0256])\n",
      "\tb = tensor([0.4760], requires_grad=True)\n",
      "\tloss = 0.026530513539910316\n",
      "\n",
      "epoch 350:\n",
      "\tdw = tensor([[ 0.0318,  0.0522, -0.0828, -0.0205]])\n",
      "\tw = tensor([[20.5170, 34.2113, 67.5586, 87.9107]], requires_grad=True)\n",
      "\tdb = tensor([-0.0123])\n",
      "\tb = tensor([0.4888], requires_grad=True)\n",
      "\tloss = 0.00447244755923748\n",
      "\n",
      "epoch 400:\n",
      "\tdw = tensor([[ 0.0129,  0.0217, -0.0343, -0.0066]])\n",
      "\tw = tensor([[20.5024, 34.1869, 67.5970, 87.9192]], requires_grad=True)\n",
      "\tdb = tensor([-0.0058])\n",
      "\tb = tensor([0.4948], requires_grad=True)\n",
      "\tloss = 0.0007608865853399038\n",
      "\n",
      "epoch 450:\n",
      "\tdw = tensor([[ 0.0052,  0.0090, -0.0143, -0.0022]])\n",
      "\tw = tensor([[20.4965, 34.1768, 67.6129, 87.9220]], requires_grad=True)\n",
      "\tdb = tensor([-0.0027])\n",
      "\tb = tensor([0.4977], requires_grad=True)\n",
      "\tloss = 0.00013008964015170932\n",
      "\n",
      "epoch 500:\n",
      "\tdw = tensor([[ 0.0021,  0.0037, -0.0059, -0.0008]])\n",
      "\tw = tensor([[20.4940, 34.1727, 67.6195, 87.9230]], requires_grad=True)\n",
      "\tdb = tensor([-0.0012])\n",
      "\tb = tensor([0.4990], requires_grad=True)\n",
      "\tloss = 2.2297730538411997e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "Y = y.unsqueeze(1)\n",
    "\n",
    "layer = Linear(X.size(1), 1)\n",
    "mse = MSELoss()\n",
    "\n",
    "learning_rate = 0.01409\n",
    "\n",
    "epochs = 500\n",
    "for epoch in range(1, epochs + 1):\n",
    "    y_pred = layer.forward(X)\n",
    "    loss = mse.forward(y_pred, Y)\n",
    "\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        layer.weights -= learning_rate * layer.weights.grad\n",
    "        layer.biases -= learning_rate * layer.biases.grad\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'epoch {epoch}:\\n'\n",
    "              f'\\tdw = {layer.weights.grad}\\n'\n",
    "              f'\\tw = {layer.weights}\\n'\n",
    "              f'\\tdb = {layer.biases.grad}\\n'\n",
    "              f'\\tb = {layer.biases}\\n'\n",
    "              f'\\tloss = {loss}\\n')\n",
    "\n",
    "    layer.weights.grad.zero_()\n",
    "    layer.biases.grad.zero_()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebibge9VEgF7"
   },
   "source": [
    "4.2 –†–µ—à–∏—Ç–µ –∑–∞–¥–∞—á—É 2.4.1, –∏—Å–ø–æ–ª—å–∑—É—è –ø–∞–∫–µ—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as-QeWSdOELd"
   },
   "source": [
    "–í—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏: \n",
    "[1](https://i.ibb.co/rmtQT6P/photo-2021-02-15-18-00-43.jpg)\n",
    "[2](https://i.ibb.co/NmCFVnQ/photo-2021-02-15-18-01-17.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr9qq4H_J3zt"
   },
   "source": [
    "4.2.1 –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å `MSELoss` –∏–∑ __3.1__, —Ä–µ–∞–ª–∏–∑–æ–≤–∞–≤ —Ä–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–ª–æ—è —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ —Ç–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞ –≤–µ–¥–µ—Ç—Å—è —Å –±–∞—Ç—á–∞–º–∏, –∞ –Ω–µ —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "L8wjk9iPMQ4x"
   },
   "outputs": [],
   "source": [
    "# –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ mean –≤ –º–µ—Ç–æ–¥–∞—Ö –≤—ã–∑—ã–≤–∞–µ—Ç –¥–æ–≤–µ—Ä–∏–µ –∫ –∏–º–µ–Ω–∏ –∫–ª–∞—Å—Å–∞\n",
    "class MSELoss:\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def backward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return 2 * (y_pred - y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3fSHCEtJjX8"
   },
   "source": [
    "4.2.2. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å `Neuron` –∏–∑ __4.1.2__:\n",
    "\n",
    "  1) –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ç–æ–¥ `forward` —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –æ–Ω –º–æ–≥ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É (–±–∞—Ç—á) —Å –¥–∞–Ω–Ω—ã–º–∏. \n",
    "\n",
    "  2) –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ä–∞—Å—á–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤–µ—Å–æ–≤ `weights` –∏ `bias` —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ —Ç–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞ –≤–µ–¥–µ—Ç—Å—è —Å –±–∞—Ç—á–∞–º–∏, –∞ –Ω–µ —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "# –∞ —ç—Ç–æ —Ç–æ—á–Ω–æ –µ—â–µ –Ω–µ–π—Ä–æ–Ω, –∞ –Ω–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π –∏–∑ –æ–¥–Ω–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–∞ —Å in_features –≤—Ö–æ–¥–∞–º–∏?\n",
    "class Neuron:\n",
    "\n",
    "    def __init__(self, in_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.weights = torch.randn(1, in_features)\n",
    "        self.bias = torch.randn(1)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(inputs, self.weights.T) + self.bias\n",
    "\n",
    "    def backward(self, dvalue: torch.Tensor, inputs: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return torch.mean(dvalue * inputs, dim=0), torch.mean(dvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO-NZrgKMBFx"
   },
   "source": [
    "4.2.3 –î–æ–ø–∏—à–∏—Ç–µ —Ü–∏–∫–ª –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Å–æ–≤ –Ω–µ–π—Ä–æ–Ω–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 010 |--------------------------------------------------\n",
      "\tweights = tensor([[22.8361, 35.1808, 56.8774, 77.7312]])\n",
      "\tdw = tensor([  0.0946,  -5.0925, -19.5831, -23.7725])\n",
      "\tbias = tensor([-0.3279])\n",
      "\tdb = -1.1936815977096558\n",
      "\tloss = 273.2061462402344\n",
      "\n",
      "epoch 020 |--------------------------------------------------\n",
      "\tweights = tensor([[21.3865, 35.2819, 65.2723, 86.5805]])\n",
      "\tdw = tensor([ 1.2022,  1.0444, -3.6096, -2.9211])\n",
      "\tbias = tensor([0.2734])\n",
      "\tdb = -0.28787899017333984\n",
      "\tloss = 8.566173553466797\n",
      "\n",
      "epoch 030 |--------------------------------------------------\n",
      "\tweights = tensor([[20.7266, 34.5308, 67.0295, 87.7218]])\n",
      "\tdw = tensor([ 0.3433,  0.4741, -0.8571, -0.4070])\n",
      "\tbias = tensor([0.4255])\n",
      "\tdb = -0.08487050980329514\n",
      "\tloss = 0.4873894155025482\n",
      "\n",
      "epoch 040 |--------------------------------------------------\n",
      "\tweights = tensor([[20.5520, 34.2695, 67.4672, 87.8893]])\n",
      "\tdw = tensor([ 0.0871,  0.1401, -0.2223, -0.0644])\n",
      "\tbias = tensor([0.4750])\n",
      "\tdb = -0.029402075335383415\n",
      "\tloss = 0.03259115293622017\n",
      "\n",
      "epoch 050 |--------------------------------------------------\n",
      "\tweights = tensor([[20.5077, 34.1962, 67.5823, 87.9171]])\n",
      "\tdw = tensor([ 0.0222,  0.0377, -0.0591, -0.0114])\n",
      "\tbias = tensor([0.4920])\n",
      "\tdb = -0.00987914577126503\n",
      "\tloss = 0.0022657406516373158\n",
      "\n",
      "epoch 060 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4964, 34.1767, 67.6130, 87.9222]])\n",
      "\tdw = tensor([ 0.0057,  0.0099, -0.0158, -0.0022])\n",
      "\tbias = tensor([0.4976])\n",
      "\tdb = -0.0031090069096535444\n",
      "\tloss = 0.00015939045988488942\n",
      "\n",
      "epoch 070 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4934, 34.1716, 67.6212, 87.9232]])\n",
      "\tdw = tensor([ 0.0015,  0.0026, -0.0042, -0.0005])\n",
      "\tbias = tensor([0.4993])\n",
      "\tdb = -0.0009288120199926198\n",
      "\tloss = 1.1334587725286838e-05\n",
      "\n",
      "epoch 080 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4926, 34.1703, 67.6234, 87.9234]])\n",
      "\tdw = tensor([ 0.0004,  0.0007, -0.0011, -0.0001])\n",
      "\tbias = tensor([0.4998])\n",
      "\tdb = -0.0002657222794368863\n",
      "\tloss = 8.040325951697014e-07\n",
      "\n",
      "epoch 090 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4924, 34.1699, 67.6240, 87.9235]])\n",
      "\tdw = tensor([ 1.0864e-04,  1.7909e-04, -3.0577e-04, -3.1768e-05])\n",
      "\tbias = tensor([0.4999])\n",
      "\tdb = -7.373333210125566e-05\n",
      "\tloss = 5.807940084423535e-08\n",
      "\n",
      "epoch 100 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4924, 34.1698, 67.6242, 87.9235]])\n",
      "\tdw = tensor([ 2.8378e-05,  4.4850e-05, -7.9438e-05, -2.4782e-05])\n",
      "\tbias = tensor([0.5000])\n",
      "\tdb = -2.0513534764177166e-05\n",
      "\tloss = 4.089672600571248e-09\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[20.4924, 34.1698, 67.6242, 87.9235]]),\n array([20.4923687 , 34.16981149, 67.62424823, 87.9234763 ]))"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "y_true = y.unsqueeze(1)\n",
    "neuron = Neuron(X.size(1))\n",
    "mse = MSELoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    y_pred = neuron.forward(X)\n",
    "    loss = mse.forward(y_pred, y_true)\n",
    "\n",
    "    dw, db = neuron.backward(mse.backward(y_pred, y_true), X)\n",
    "\n",
    "    neuron.weights -= learning_rate * dw\n",
    "    neuron.bias -= learning_rate * db\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        pretty_train_log(epoch, weights=neuron.weights, dw=dw, bias=neuron.bias, db=db, loss=loss)\n",
    "\n",
    "neuron.weights, coef"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16VtP159OdMk"
   },
   "source": [
    "4.3 –ò—Å–ø–æ–ª—å–∑—É—è –æ–¥–∏–Ω –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π –∏ –ø–∞–∫–µ—Ç–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫, —Ä–µ—à–∏—Ç–µ –∑–∞–¥–∞—á—É —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏–∑ __2.4.1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj5febreSSZ7"
   },
   "source": [
    "4.3.1 –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å `Linear` –∏–∑ __1.4__. ([–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤](https://i.ibb.co/kgVR6m6/photo-2021-02-15-21-30-28.jpg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "# –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ üßê –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –Ω–µ–π—Ä–æ–Ω (–ø—Ä–æ—Å—Ç–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)\n",
    "class Linear:\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.weights = torch.randn(out_features, in_features)\n",
    "        self.biases = torch.randn(out_features)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(inputs, self.weights.T) + self.biases\n",
    "\n",
    "    def backward(self, dvalue: torch.Tensor, inputs: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return torch.mean(dvalue * inputs, dim=0), torch.mean(dvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3w1hT9MS_Lt"
   },
   "source": [
    "4.3.2 –°–æ–∑–¥–∞–π—Ç–µ —Å–ª–æ–π —Å –æ–¥–Ω–∏–º –Ω–µ–π—Ä–æ–Ω–æ–º. –ò—Å–ø–æ–ª—å–∑—É—è –∫–ª–∞—Å—Å MSELoss –∏–∑ 2.4.2, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 010 |--------------------------------------------------\n",
      "\tweights = tensor([[22.8361, 35.1808, 56.8774, 77.7312]])\n",
      "\tdw = tensor([  0.0946,  -5.0925, -19.5831, -23.7725])\n",
      "\tbiases = tensor([-0.3279])\n",
      "\tdb = -1.1936815977096558\n",
      "\tloss = 273.2061462402344\n",
      "\n",
      "epoch 020 |--------------------------------------------------\n",
      "\tweights = tensor([[21.3865, 35.2819, 65.2723, 86.5805]])\n",
      "\tdw = tensor([ 1.2022,  1.0444, -3.6096, -2.9211])\n",
      "\tbiases = tensor([0.2734])\n",
      "\tdb = -0.28787899017333984\n",
      "\tloss = 8.566173553466797\n",
      "\n",
      "epoch 030 |--------------------------------------------------\n",
      "\tweights = tensor([[20.7266, 34.5308, 67.0295, 87.7218]])\n",
      "\tdw = tensor([ 0.3433,  0.4741, -0.8571, -0.4070])\n",
      "\tbiases = tensor([0.4255])\n",
      "\tdb = -0.08487050980329514\n",
      "\tloss = 0.4873894155025482\n",
      "\n",
      "epoch 040 |--------------------------------------------------\n",
      "\tweights = tensor([[20.5520, 34.2695, 67.4672, 87.8893]])\n",
      "\tdw = tensor([ 0.0871,  0.1401, -0.2223, -0.0644])\n",
      "\tbiases = tensor([0.4750])\n",
      "\tdb = -0.029402075335383415\n",
      "\tloss = 0.03259115293622017\n",
      "\n",
      "epoch 050 |--------------------------------------------------\n",
      "\tweights = tensor([[20.5077, 34.1962, 67.5823, 87.9171]])\n",
      "\tdw = tensor([ 0.0222,  0.0377, -0.0591, -0.0114])\n",
      "\tbiases = tensor([0.4920])\n",
      "\tdb = -0.00987914577126503\n",
      "\tloss = 0.0022657406516373158\n",
      "\n",
      "epoch 060 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4964, 34.1767, 67.6130, 87.9222]])\n",
      "\tdw = tensor([ 0.0057,  0.0099, -0.0158, -0.0022])\n",
      "\tbiases = tensor([0.4976])\n",
      "\tdb = -0.0031090069096535444\n",
      "\tloss = 0.00015939045988488942\n",
      "\n",
      "epoch 070 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4934, 34.1716, 67.6212, 87.9232]])\n",
      "\tdw = tensor([ 0.0015,  0.0026, -0.0042, -0.0005])\n",
      "\tbiases = tensor([0.4993])\n",
      "\tdb = -0.0009288120199926198\n",
      "\tloss = 1.1334587725286838e-05\n",
      "\n",
      "epoch 080 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4926, 34.1703, 67.6234, 87.9234]])\n",
      "\tdw = tensor([ 0.0004,  0.0007, -0.0011, -0.0001])\n",
      "\tbiases = tensor([0.4998])\n",
      "\tdb = -0.0002657222794368863\n",
      "\tloss = 8.040325951697014e-07\n",
      "\n",
      "epoch 090 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4924, 34.1699, 67.6240, 87.9235]])\n",
      "\tdw = tensor([ 1.0864e-04,  1.7909e-04, -3.0577e-04, -3.1768e-05])\n",
      "\tbiases = tensor([0.4999])\n",
      "\tdb = -7.373333210125566e-05\n",
      "\tloss = 5.807940084423535e-08\n",
      "\n",
      "epoch 100 |--------------------------------------------------\n",
      "\tweights = tensor([[20.4924, 34.1698, 67.6242, 87.9235]])\n",
      "\tdw = tensor([ 2.8378e-05,  4.4850e-05, -7.9438e-05, -2.4782e-05])\n",
      "\tbiases = tensor([0.5000])\n",
      "\tdb = -2.0513534764177166e-05\n",
      "\tloss = 4.089672600571248e-09\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[20.4924, 34.1698, 67.6242, 87.9235]]),\n array([20.4923687 , 34.16981149, 67.62424823, 87.9234763 ]))"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "y_true = y.unsqueeze(1)\n",
    "layer = Linear(X.size(1), 1)\n",
    "mse = MSELoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    y_pred = layer.forward(X)\n",
    "    loss = mse.forward(y_pred, y_true)\n",
    "\n",
    "    dw, db = layer.backward(mse.backward(y_pred, y_true), X)\n",
    "\n",
    "    layer.weights -= learning_rate * dw\n",
    "    layer.biases -= learning_rate * db\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        pretty_train_log(epoch, weights=layer.weights, dw=dw, biases=layer.biases, db=db, loss=loss)\n",
    "\n",
    "neuron.weights, coef"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**–ü—Ä–æ–≤–µ—Ä–∫–∞**\n",
    "\n",
    "–ê pytorch —Ç–æ—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 010 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[22.8361, 35.1808, 56.8774, 77.7312]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([-0.3279], requires_grad=True)\n",
      "\tloss = 273.20623779296875\n",
      "\n",
      "epoch 020 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[21.3865, 35.2819, 65.2723, 86.5805]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.2734], requires_grad=True)\n",
      "\tloss = 8.566173553466797\n",
      "\n",
      "epoch 030 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.7266, 34.5308, 67.0295, 87.7218]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4255], requires_grad=True)\n",
      "\tloss = 0.4873894155025482\n",
      "\n",
      "epoch 040 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.5520, 34.2695, 67.4672, 87.8893]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4750], requires_grad=True)\n",
      "\tloss = 0.03259115293622017\n",
      "\n",
      "epoch 050 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.5077, 34.1962, 67.5823, 87.9171]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4920], requires_grad=True)\n",
      "\tloss = 0.0022657406516373158\n",
      "\n",
      "epoch 060 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.4964, 34.1767, 67.6130, 87.9222]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4976], requires_grad=True)\n",
      "\tloss = 0.00015939045988488942\n",
      "\n",
      "epoch 070 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.4934, 34.1716, 67.6212, 87.9232]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4993], requires_grad=True)\n",
      "\tloss = 1.1334587725286838e-05\n",
      "\n",
      "epoch 080 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.4926, 34.1703, 67.6234, 87.9234]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4998], requires_grad=True)\n",
      "\tloss = 8.040325951697014e-07\n",
      "\n",
      "epoch 090 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.4924, 34.1699, 67.6240, 87.9235]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.4999], requires_grad=True)\n",
      "\tloss = 5.807940084423535e-08\n",
      "\n",
      "epoch 100 |--------------------------------------------------\n",
      "\tweight = Parameter containing:\n",
      "tensor([[20.4924, 34.1698, 67.6242, 87.9235]], requires_grad=True)\n",
      "\tbias = Parameter containing:\n",
      "tensor([0.5000], requires_grad=True)\n",
      "\tloss = 4.089672600571248e-09\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[20.4924, 34.1698, 67.6242, 87.9235]]),\n array([20.4923687 , 34.16981149, 67.62424823, 87.9234763 ]))"
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "weights = torch.randn(1, 4)\n",
    "bias = torch.randn(1)\n",
    "\n",
    "y_true = y.unsqueeze(1)\n",
    "layer = nn.Linear(X.size(1), 1)\n",
    "layer.weight = nn.Parameter(weights, requires_grad=True)\n",
    "layer.bias = nn.Parameter(bias, requires_grad=True)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD([layer.weight, layer.bias], lr=learning_rate)\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    y_pred = layer.forward(X)\n",
    "    loss = mse.forward(y_pred, y_true)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        pretty_train_log(epoch, weight=layer.weight, bias=layer.bias, loss=loss)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "neuron.weights, coef"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTkJV-F8TVuN"
   },
   "source": [
    "4.4 –ò—Å–ø–æ–ª—å–∑—É—è –Ω–∞—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ 2.4, —Å–æ–∑–¥–∞–π—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏ —Ä–µ—à–∏—Ç–µ –∑–∞–¥–∞—á—É —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.\n",
    "\n",
    "–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: \n",
    "1. –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å 10 –Ω–µ–π—Ä–æ–Ω–∞–º–∏\n",
    "2. –ê–∫—Ç–∏–≤–∞—Ü–∏—è ReLU\n",
    "3. –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å 1 –Ω–µ–π—Ä–æ–Ω–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "axUjpPz-SvS1"
   },
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 100).view(-1, 1)\n",
    "y = X.pow(2) + 0.2 * torch.rand(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "id": "LXoiNxkpTziV"
   },
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = inputs.clip(min=0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.clone()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "tXhspwW6T44T"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1143161818.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [289]\u001B[1;36m\u001B[0m\n\u001B[1;33m    data_loss =  # <–ø—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å>\u001B[0m\n\u001B[1;37m                 ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–µ—Ç–∏\n",
    "# fc1 = \n",
    "# relu1 = \n",
    "# fc2 = \n",
    "\n",
    "loss = MSELoss()\n",
    "lr = 0.02\n",
    "\n",
    "ys = []\n",
    "for epoch in range(2001):\n",
    "    # <forward pass>\n",
    "    # fc1 > relu1 > fc2 > loss\n",
    "\n",
    "    data_loss =  # <–ø—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å>\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f'epoch {epoch} mean loss {data_loss}')\n",
    "        ys.append(out)\n",
    "\n",
    "    # <backprop>\n",
    "    # loss > fc2 > relu1 > fc1\n",
    "\n",
    "    # <—à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è fc1>\n",
    "\n",
    "    # <—à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è fc2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpKi0OfoUkwk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(len(ys), 1, figsize=(10, 40))\n",
    "for ax, y_ in zip(axs, ys):\n",
    "    ax.scatter(X.numpy(), y.numpy(), color=\"orange\")\n",
    "    ax.plot(X.numpy(), y_.numpy(), 'g-', lw=3)\n",
    "    ax.set_xlim(-1.05, 1.5)\n",
    "    ax.set_ylim(-0.25, 1.25)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDgJRHjuyArfKO8ZT68MsS",
   "name": "02_NN_blocks_backprop_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
