{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Создание нейронной сети при помощи пакета `torch`. Dataset и Dataloader.\n",
    "\n",
    "__Автор__: Никита Владимирович Блохин (NVBlokhin@fa.ru)\n",
    "\n",
    "Финансовый университет, 2020 г. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6ktSXdQVb9Li"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L7Inb1JbiDy"
   },
   "source": [
    "## 1. Автоматическое дифференцирование в `torch`"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 Воспользовавшись классами `Neuron` и `MSELoss` из задачи 2.4.1 и автоматическим дифференцированием, которое предоставляет `torch`, решить задачу регрессии. Для оптимизации использовать стохастический градиетный спуск."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y, coef = make_regression(n_features=4, n_informative=4, coef=True, bias=0.5)\n",
    "X = torch.from_numpy(X).to(dtype=torch.float32)\n",
    "y = torch.from_numpy(y).to(dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def pretty_train_log(epoch: int, **kwargs) -> None:\n",
    "    params = '\\n\\t'.join([f'{k} = {v}' for k, v in kwargs.items()])\n",
    "    print(f'epoch {epoch:03} |' + '-' * 50 + f'\\n\\t{params}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, in_features: int):\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.weights = torch.randn(self.in_features, requires_grad=True)\n",
    "        self.bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(self.weights * inputs) + self.bias\n",
    "\n",
    "\n",
    "class SELoss:\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return (y_pred - y_true) ** 2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 |--------------------------------------------------\n",
      "\ti = 0\n",
      "\tweights = tensor([ 2.3885, -0.6152,  0.9567,  0.4048], requires_grad=True)\n",
      "\tdw = tensor([ -8.4751,   3.2173, -31.3549,   1.6363])\n",
      "\tbias = tensor([2.4158], requires_grad=True)\n",
      "\tdb = tensor([-35.0033])\n",
      "\tloss = tensor([306.3077], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 000 |--------------------------------------------------\n",
      "\ti = 50\n",
      "\tweights = tensor([68.9588,  2.2578,  1.2310, 76.4627], requires_grad=True)\n",
      "\tdw = tensor([ 1.1491, -3.6380, -0.0116,  1.4666])\n",
      "\tbias = tensor([0.5364], requires_grad=True)\n",
      "\tdb = tensor([2.6421])\n",
      "\tloss = tensor([1.7451], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 005 |--------------------------------------------------\n",
      "\ti = 0\n",
      "\tweights = tensor([69.2648,  2.6558,  1.5509, 76.5135], requires_grad=True)\n",
      "\tdw = tensor([ 4.1563e-06, -1.5778e-06,  1.5377e-05, -8.0247e-07])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([1.7166e-05])\n",
      "\tloss = tensor([7.3669e-11], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 005 |--------------------------------------------------\n",
      "\ti = 50\n",
      "\tweights = tensor([69.2649,  2.6558,  1.5509, 76.5134], requires_grad=True)\n",
      "\tdw = tensor([0., 0., 0., 0.])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 010 |--------------------------------------------------\n",
      "\ti = 0\n",
      "\tweights = tensor([69.2648,  2.6558,  1.5509, 76.5135], requires_grad=True)\n",
      "\tdw = tensor([ 4.1563e-06, -1.5778e-06,  1.5377e-05, -8.0247e-07])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([1.7166e-05])\n",
      "\tloss = tensor([7.3669e-11], grad_fn=<PowBackward0>)\n",
      "\n",
      "epoch 010 |--------------------------------------------------\n",
      "\ti = 50\n",
      "\tweights = tensor([69.2649,  2.6558,  1.5509, 76.5134], requires_grad=True)\n",
      "\tdw = tensor([0., 0., 0., 0.])\n",
      "\tbias = tensor([0.5000], requires_grad=True)\n",
      "\tdb = tensor([0.])\n",
      "\tloss = tensor([0.], grad_fn=<PowBackward0>)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([69.2648,  2.6558,  1.5509, 76.5134], requires_grad=True),\n array([69.26485673,  2.65577295,  1.55092277, 76.51344004]))"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "neuron = Neuron(X.size(1))\n",
    "se = SELoss()\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD([neuron.weights, neuron.bias], lr=lr)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for i, (x, y_true) in enumerate(zip(X, y)):\n",
    "        y_pred = neuron.forward(x)\n",
    "        loss = se.forward(y_pred, y_true)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 5 == 0 and i % 50 == 0:\n",
    "            pretty_train_log(\n",
    "                epoch,\n",
    "                i=i,\n",
    "                weights=neuron.weights,\n",
    "                dw=neuron.weights.grad,\n",
    "                bias=neuron.bias,\n",
    "                db=neuron.bias.grad,\n",
    "                loss=loss,\n",
    "            )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "neuron.weights, coef"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Воспользовавшись классами `Linear` и `MSELoss` из задачи 2.1.4 и 2.3.1, `ReLU` из 2.2.1 и автоматическим дифференцированием, которое предоставляет `torch`, решить задачу регрессии. Для оптимизации использовать пакетный градиентный спуск. Вывести график функции потерь в зависимости от номера эпохи. Вывести на одном графике исходные данные и предсказанные значения."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "X = torch.linspace(0, 1, 100).view(-1, 1)\n",
    "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.weights = torch.randn(out_features, in_features, requires_grad=True)\n",
    "        self.biases = torch.randn(out_features, requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(inputs, self.weights.T) + self.biases\n",
    "\n",
    "\n",
    "class MSELoss:\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.mean((y_pred - y_true) ** 2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 |--------------------------------------------------\n",
      "\tweights = tensor([[1.4405]], requires_grad=True)\n",
      "\tdw = tensor([[1.0053]])\n",
      "\tbias = tensor([-0.3791], requires_grad=True)\n",
      "\tdb = tensor([0.8570])\n",
      "\tloss = 1.3648285865783691\n",
      "\n",
      "epoch 100 |--------------------------------------------------\n",
      "\tweights = tensor([[-1.0424]], requires_grad=True)\n",
      "\tdw = tensor([[0.1100]])\n",
      "\tbias = tensor([0.5407], requires_grad=True)\n",
      "\tdb = tensor([-0.0589])\n",
      "\tloss = 0.2608502209186554\n",
      "\n",
      "epoch 200 |--------------------------------------------------\n",
      "\tweights = tensor([[-1.6416]], requires_grad=True)\n",
      "\tdw = tensor([[0.0285]])\n",
      "\tbias = tensor([0.8618], requires_grad=True)\n",
      "\tdb = tensor([-0.0153])\n",
      "\tloss = 0.2067205011844635\n",
      "\n",
      "epoch 300 |--------------------------------------------------\n",
      "\tweights = tensor([[-1.7970]], requires_grad=True)\n",
      "\tdw = tensor([[0.0074]])\n",
      "\tbias = tensor([0.9451], requires_grad=True)\n",
      "\tdb = tensor([-0.0040])\n",
      "\tloss = 0.2030831277370453\n",
      "\n",
      "epoch 400 |--------------------------------------------------\n",
      "\tweights = tensor([[-1.8373]], requires_grad=True)\n",
      "\tdw = tensor([[0.0019]])\n",
      "\tbias = tensor([0.9667], requires_grad=True)\n",
      "\tdb = tensor([-0.0010])\n",
      "\tloss = 0.2028387486934662\n",
      "\n",
      "epoch 500 |--------------------------------------------------\n",
      "\tweights = tensor([[-1.8477]], requires_grad=True)\n",
      "\tdw = tensor([[0.0005]])\n",
      "\tbias = tensor([0.9723], requires_grad=True)\n",
      "\tdb = tensor([-0.0003])\n",
      "\tloss = 0.20282232761383057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "layer = Linear(X.size(1), y.size(1))\n",
    "mse = MSELoss()\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD([layer.weights, layer.biases], lr=lr)\n",
    "epochs = 500\n",
    "\n",
    "losses = torch.empty(epochs + 1)\n",
    "for epoch in range(epochs + 1):\n",
    "    y_pred = layer.forward(X)\n",
    "\n",
    "    loss = mse.forward(y_pred, y)\n",
    "    losses[epoch] = loss\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        pretty_train_log(\n",
    "            epoch,\n",
    "            weights=layer.weights,\n",
    "            dw=layer.weights.grad,\n",
    "            bias=layer.biases,\n",
    "            db=layer.biases.grad,\n",
    "            loss=loss,\n",
    "        )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "predicts = layer.forward(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(losses.size(0)), losses.detach().numpy());"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "sns.plot(predicts, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nifm0FVB2y5N"
   },
   "source": [
    "## 2. Алгоритмы оптимизации в `torch.optim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5PTTYou3xx8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oBFfJpmcwfn"
   },
   "source": [
    "2.1 Решить задачу 1.1, воспользовавшись оптимизатором `optim.SDG` для применения стохастического градиентого спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LFAacdy46bX"
   },
   "source": [
    "2.2 Решить задачу 1.2, воспользовавшись оптимизатором `optim.Adam` для применения пакетного градиентого спуска. Вывести график функции потерь в зависимости от номера эпохи. Вывести на одном графике исходные данные и предсказанные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-qUqdALiN-G"
   },
   "source": [
    "## 3. Построение сетей при помощи `torch.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vxsck-1M6TAV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0ICJtarif3_"
   },
   "source": [
    "3.1 Решить задачу регрессии, соблюдая следующие условия:\n",
    "\n",
    "1. Оформить нейронную сеть в виде класса - наследника `nn.Module`\n",
    "2. При создании сети использовать готовые блоки из `torch.nn`: слои, функции активации, функции потерь и т.д.\n",
    "3. Для оптимизации использовать любой алгоритм оптимизации из `torch.optim` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1bvXHhO7aWs"
   },
   "outputs": [],
   "source": [
    "X = torch.linspace(0, 1, 100).view(-1, 1)\n",
    "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPUW6fm5jbQd"
   },
   "source": [
    "3.2 Решить задачу регрессии, соблюдая следующие условия:\n",
    "\n",
    "1. Оформить нейронную сеть в виде объекта `nn.Sequential`\n",
    "2. При создании сети использовать готовые блоки из `torch.nn`: слои, функции активации, функции потерь и т.д.\n",
    "3. Для оптимизации использовать любой алгоритм оптимизации из `torch.optim` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBwbAEd57a2r"
   },
   "outputs": [],
   "source": [
    "X = torch.linspace(0, 1, 100).view(-1, 1)\n",
    "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Решить задачу классификации. Датасет: Breast Cancer Wisconsin\n",
    "1. Оформить нейронную сеть в виде объекта `nn.Sequential`\n",
    "2. При создании сети использовать готовые блоки из `torch.nn`: слои, функции активации, функции потерь и т.д.\n",
    "3. Для оптимизации использовать любой алгоритм оптимизации из `torch.optim` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQj0oVeLj2A1"
   },
   "source": [
    "## 4. Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c82tAkXMjajm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoFPckkp8yhz"
   },
   "source": [
    "4.1 Создать датасет, поставляющий данные из задачи 1.2. \n",
    "\n",
    "Создать `DataLoader` на основе этого датасета и проверить работоспособность.\n",
    "\n",
    "Воспользовавшись результатами 3.1 (или 3.2) обучите модель, пользуясь мини-пакетным градиентным спуском с размером пакета (`batch_size`) = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tlcwQzCFRvFc"
   },
   "outputs": [],
   "source": [
    "class SinDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxz02a3k_VQL"
   },
   "source": [
    "4.2 Предсказание цен алмазов\n",
    "\n",
    "4.2.1 Создайте датасет на основе файла diamonds.csv. \n",
    "\n",
    "1. Удалите все нечисловые столбцы\n",
    "2. Целевой столбец (`y`) - `price`\n",
    "3. Преобразуйте данные в тензоры корректных размеров\n",
    "\n",
    "4.2.2 Разбейте датасет на обучающий и тестовый датасет при помощи `torch.utils.data.random_split`.\n",
    "\n",
    "4.2.3 Обучите модель для предсказания цен при помощи мини-пакетного градиентного спуска (`batch_size = 256`). \n",
    "\n",
    "4.2.4 Выведите график функции потерь в зависимости от номера эпохи (значение потерь для эпохи рассчитывайте как среднее значение ошибок на каждом батче). Проверьте качество модели на тестовой выборке. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEfTNJQI8emD"
   },
   "outputs": [],
   "source": [
    "class DiamondsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qE81cgQdGM7I"
   },
   "source": [
    "4.3 Модифицируйте метод `__init__` датасета из 4.2 таким образом, чтобы он мог принимать параметр `transform: callable`. Реализуйте класс `DropColsTransform` для удаления нечисловых данных из массива. Реализуйте класс `ToTensorTransorm` для трансформации массива в тензор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J02LNj_F8qxK"
   },
   "outputs": [],
   "source": [
    "class DiamondsDataset(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        # ....\n",
    "        self.transform = transform\n",
    "        # ....\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ...\n",
    "        sample = self.X[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        # ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJii-22pHIlU"
   },
   "outputs": [],
   "source": [
    "class DropColsTransform:\n",
    "    def __init__(self, drop):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        X, y = sample\n",
    "        # <удаление из X столбцов self.drop>\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZZ-OKrVHnY5"
   },
   "outputs": [],
   "source": [
    "class ToTensorTransform:\n",
    "    def __call__(self, sample):\n",
    "        X, y = sample\n",
    "        # <преобразование X и y в тензоры>\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GssBjT9JHt5g"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "drop = DropColsTransform(drop=[1, 2, 3])\n",
    "to_tensor = ToTensorTransform()\n",
    "dataset = DiamondsDataset(data, transforms.compose([drop, to_tensor]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "blank_03_autograd_optim_nn_datasets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
