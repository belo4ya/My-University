{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5669,
     "status": "ok",
     "timestamp": 1619632510103,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "zKMq7dp2W15Y",
    "outputId": "ce2273c5-6a96-4216-9d88-fbee51bf5ff0"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_cuda(device: str) -> bool:\n",
    "    return device == \"cuda\"\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_dataloader: DataLoader,\n",
    "        epochs: int,\n",
    "        test_dataloader: DataLoader = None,\n",
    "        lr_scheduler=None,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.List[float]:\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "        train_loss = train_loop(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "        )\n",
    "        train_losses.append(train_loss.item())\n",
    "        if test_dataloader:\n",
    "            loss, acc = test_loop(test_dataloader, model, loss_fn, device=device)\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step(loss)\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> torch.Tensor:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss\n",
    "        if batch % verbose == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, correct = 0, 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        avg_loss += loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # noqa\n",
    "\n",
    "        del x, y, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:>4f}, Avg loss: {avg_loss:>8f} \\n\")\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_test_split(dataset: t.Union[Dataset, t.Sized], train_part: float) -> t.Tuple[Subset, Subset]:\n",
    "    train_size = round(train_part * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_test_y_pred(\n",
    "        model: nn.Module,\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.hstack(y_test).detach().cpu(), torch.hstack(y_pred).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm-QilGISxkt"
   },
   "source": [
    "## 1. Классификация фамилий (RNN)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/frNchuaBQVLxyA?w=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdPr92i6k-If"
   },
   "source": [
    "1.1 Используя класс `nn.RNNCell` (абстракцию для отдельного временного шага RNN), реализуйте простейшую рекуррентную сеть Элмана в виде класса `RNN`. Используя созданный класс `RNN`, решите задачу классификации фамилий. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ir6UUkl6l4tp"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, hx: torch.Tensor = None):\n",
    "        batch_size, sequence_size, _ = inputs.size()\n",
    "        inputs = inputs.permute(1, 0, 2)  # для nn.RNNCell batch_size должен быть на 2-ом месте\n",
    "\n",
    "        if hx is None:\n",
    "            # инициализация как в nn.RNN\n",
    "            hx = torch.zeros(batch_size, self.hidden_size, dtype=inputs.dtype, device=inputs.device)\n",
    "        else:\n",
    "            # 1-ая размерность равная 1 для совместимости с nn.RNN\n",
    "            hx = hx.squeeze(0)  # избавляемся от 1-ой размерности равной 1\n",
    "\n",
    "        hidden = []\n",
    "        for i in range(sequence_size):\n",
    "            hx = self.rnn_cell(inputs[i], hx)\n",
    "            hidden.append(hx)\n",
    "\n",
    "        hidden = torch.stack(hidden)\n",
    "        hx = hidden[-1].unsqueeze(0)\n",
    "        # выход и скрытое состояние размерностей: (batch_size, ...), (1, batch_size, ...)\n",
    "        return hidden.permute(1, 0, 2), hx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка реализации RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "input_size, hidden_size = 4, 5\n",
    "inputs = torch.randn(2, 3, input_size)\n",
    "hx = torch.randn(1, 2, hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "my_rnn = RNN(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "true_rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<UnsqueezeBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ 100% совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.rnn = RNN(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        # здесь позволим себе потерять скрытое состояние hx\n",
    "        # в будущих моделях будем его сохранять\n",
    "        x, hx = self.rnn(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesVocab:\n",
    "    pad = \"<PAD>\"\n",
    "\n",
    "    def __init__(self, surnames: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for w in map(str.lower, surnames):\n",
    "            uniques.update(w)\n",
    "            max_len = max(len(w), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, *uniques]\n",
    "        self.max_len = max_len\n",
    "        self.ch2i = {ch: i for i, ch in enumerate(self.alphabet)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        indices = [self.ch2i[ch] for ch in word]\n",
    "        indices += [self.ch2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.ch2i[self.pad], as_tuple=True)[0]\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \"\".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class SurnamesDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    surnames: t.List[str]\n",
    "    vocab: SurnamesVocab\n",
    "    labeler: LabelEncoder\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.surnames = self.df[\"surname\"].tolist()\n",
    "        self.vocab = SurnamesVocab(self.surnames)\n",
    "        size = self.vocab.encode(self.surnames[0].lower()).size()\n",
    "        data = torch.vstack([self.vocab.encode(w.lower()) for w in self.surnames])\n",
    "        self.data = data.view(len(self.surnames), *size)\n",
    "\n",
    "        self.labeler = LabelEncoder()\n",
    "        targets = self.labeler.fit_transform(self.df[\"nationality\"])\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(word)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames_dataset = SurnamesDataset(DATA_DIR / \"surnames.csv\")\n",
    "len(surnames_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8784 2196\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_surnames_dataset, test_surnames_dataset = train_test_split(surnames_dataset, train_part=0.8)\n",
    "print(len(train_surnames_dataset), len(test_surnames_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "handmade_rnn_net = SurnamesRNNClassifier(\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(handmade_rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.891901  [    0/ 8784]\n",
      "loss: 1.465396  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.622495, Avg loss: 1.298633 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.154157  [    0/ 8784]\n",
      "loss: 1.179678  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.694444, Avg loss: 1.057449 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.036496  [    0/ 8784]\n",
      "loss: 0.837359  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.718579, Avg loss: 0.964127 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.856482  [    0/ 8784]\n",
      "loss: 0.841396  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734062, Avg loss: 0.924591 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.664573  [    0/ 8784]\n",
      "loss: 0.949235  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744080, Avg loss: 0.865812 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.722839  [    0/ 8784]\n",
      "loss: 0.614783  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747268, Avg loss: 0.872199 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.515337  [    0/ 8784]\n",
      "loss: 0.628560  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.755009, Avg loss: 0.852178 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.597517  [    0/ 8784]\n",
      "loss: 0.682090  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.754098, Avg loss: 0.859217 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.544104  [    0/ 8784]\n",
      "loss: 0.431519  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.757741, Avg loss: 0.838505 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.400761  [    0/ 8784]\n",
      "loss: 0.527620  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.755464, Avg loss: 0.838108 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.549541  [    0/ 8784]\n",
      "loss: 0.504755  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.766849, Avg loss: 0.852068 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.435418  [    0/ 8784]\n",
      "loss: 0.507152  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.764572, Avg loss: 0.868060 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.348249  [    0/ 8784]\n",
      "loss: 0.418751  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.759563, Avg loss: 0.874918 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.377530  [    0/ 8784]\n",
      "loss: 0.452588  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.757741, Avg loss: 0.879005 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.315860  [    0/ 8784]\n",
      "loss: 0.532221  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.765027, Avg loss: 0.919324 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.268380  [    0/ 8784]\n",
      "loss: 0.381107  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.759107, Avg loss: 0.913041 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.437253  [    0/ 8784]\n",
      "loss: 0.447419  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.768215, Avg loss: 0.899608 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.347026  [    0/ 8784]\n",
      "loss: 0.348366  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.767760, Avg loss: 0.929794 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.265240  [    0/ 8784]\n",
      "loss: 0.346834  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.759107, Avg loss: 0.945011 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.339513  [    0/ 8784]\n",
      "loss: 0.187589  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.766849, Avg loss: 0.950094 \n",
      "\n",
      "CPU times: user 17.4 s, sys: 561 ms, total: 18 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=handmade_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.97      1.00      0.98       340\n",
      "     Chinese       0.78      0.76      0.77        38\n",
      "       Czech       0.58      0.33      0.42        96\n",
      "       Dutch       0.59      0.43      0.50        51\n",
      "     English       0.72      0.86      0.79       573\n",
      "      French       0.18      0.05      0.08        39\n",
      "      German       0.56      0.49      0.52       121\n",
      "       Greek       0.70      0.62      0.66        34\n",
      "       Irish       0.60      0.32      0.42        37\n",
      "     Italian       0.71      0.76      0.73       128\n",
      "    Japanese       0.86      0.88      0.87       156\n",
      "      Korean       0.36      0.40      0.38        10\n",
      "      Polish       0.57      0.50      0.53        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.83      0.88      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.46      0.36      0.40        50\n",
      "  Vietnamese       0.25      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.77      2196\n",
      "   macro avg       0.54      0.48      0.50      2196\n",
      "weighted avg       0.74      0.77      0.75      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(handmade_rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2MIErKTo9aO"
   },
   "source": [
    "1.2 Замените модуль `RNN` из 1.1 на модули `nn.RNN`, `nn.LSTM` и `nn.GRU` (не забудьте указать аргумент `batch_first=True`). Сравните результаты работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesAutobotRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.cx = cx.detach()\n",
    "            self.hx = hx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.RNN,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.894483  [    0/ 8784]\n",
      "loss: 1.630486  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.581512, Avg loss: 1.438731 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.345863  [    0/ 8784]\n",
      "loss: 1.308324  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.644809, Avg loss: 1.212533 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.161597  [    0/ 8784]\n",
      "loss: 1.007689  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.674408, Avg loss: 1.111740 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.016940  [    0/ 8784]\n",
      "loss: 0.884982  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.694900, Avg loss: 1.034357 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.955447  [    0/ 8784]\n",
      "loss: 1.070568  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.710838, Avg loss: 1.011102 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.977373  [    0/ 8784]\n",
      "loss: 0.827253  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.720856, Avg loss: 0.972597 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.657779  [    0/ 8784]\n",
      "loss: 0.871493  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.727687, Avg loss: 0.974482 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.783444  [    0/ 8784]\n",
      "loss: 0.967391  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.722222, Avg loss: 0.966097 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.670315  [    0/ 8784]\n",
      "loss: 0.598530  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729964, Avg loss: 0.946612 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.568015  [    0/ 8784]\n",
      "loss: 0.593403  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735428, Avg loss: 0.942739 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.706932  [    0/ 8784]\n",
      "loss: 0.652993  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.955723 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.490176  [    0/ 8784]\n",
      "loss: 0.632686  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.935077 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.520478  [    0/ 8784]\n",
      "loss: 0.588194  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.966555 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.489050  [    0/ 8784]\n",
      "loss: 0.588648  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.956340 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.494865  [    0/ 8784]\n",
      "loss: 0.647517  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734517, Avg loss: 0.963625 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.506586  [    0/ 8784]\n",
      "loss: 0.420964  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743169, Avg loss: 0.972977 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.567723  [    0/ 8784]\n",
      "loss: 0.574521  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740437, Avg loss: 0.988176 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.464846  [    0/ 8784]\n",
      "loss: 0.560161  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.986797 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.325948  [    0/ 8784]\n",
      "loss: 0.443015  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741803, Avg loss: 1.011581 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.423289  [    0/ 8784]\n",
      "loss: 0.349036  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.746357, Avg loss: 0.997399 \n",
      "\n",
      "CPU times: user 14.6 s, sys: 917 ms, total: 15.6 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.97      1.00      0.99       340\n",
      "     Chinese       0.76      0.76      0.76        38\n",
      "       Czech       0.44      0.23      0.30        96\n",
      "       Dutch       0.80      0.39      0.53        51\n",
      "     English       0.68      0.87      0.77       573\n",
      "      French       0.20      0.08      0.11        39\n",
      "      German       0.59      0.48      0.53       121\n",
      "       Greek       0.56      0.44      0.49        34\n",
      "       Irish       0.62      0.22      0.32        37\n",
      "     Italian       0.66      0.64      0.65       128\n",
      "    Japanese       0.83      0.86      0.84       156\n",
      "      Korean       0.27      0.30      0.29        10\n",
      "      Polish       0.50      0.38      0.43        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.83      0.87      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.38      0.32      0.35        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.53      0.44      0.46      2196\n",
      "weighted avg       0.72      0.75      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.LSTM,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.884699  [    0/ 8784]\n",
      "loss: 1.878506  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.540073, Avg loss: 1.575988 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.447626  [    0/ 8784]\n",
      "loss: 1.610469  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.618852, Avg loss: 1.319369 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.309874  [    0/ 8784]\n",
      "loss: 1.262846  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.662568, Avg loss: 1.176828 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.032387  [    0/ 8784]\n",
      "loss: 1.082438  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.682149, Avg loss: 1.096950 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.021482  [    0/ 8784]\n",
      "loss: 0.957862  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.699454, Avg loss: 1.029817 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.058702  [    0/ 8784]\n",
      "loss: 0.979626  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714481, Avg loss: 0.979212 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.868596  [    0/ 8784]\n",
      "loss: 0.786667  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.717213, Avg loss: 0.971432 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.634187  [    0/ 8784]\n",
      "loss: 0.701613  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724044, Avg loss: 0.957337 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.556886  [    0/ 8784]\n",
      "loss: 0.792655  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726321, Avg loss: 0.941104 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.614025  [    0/ 8784]\n",
      "loss: 0.812822  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731785, Avg loss: 0.934080 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.657146  [    0/ 8784]\n",
      "loss: 0.707791  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734517, Avg loss: 0.929226 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.763235  [    0/ 8784]\n",
      "loss: 0.687776  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.912718 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.535523  [    0/ 8784]\n",
      "loss: 0.642031  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745902, Avg loss: 0.924076 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.468682  [    0/ 8784]\n",
      "loss: 0.671491  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.948828 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.604427  [    0/ 8784]\n",
      "loss: 0.694328  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.751366, Avg loss: 0.937007 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.630770  [    0/ 8784]\n",
      "loss: 0.602806  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.926287 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.470244  [    0/ 8784]\n",
      "loss: 0.643437  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 0.937898 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.365152  [    0/ 8784]\n",
      "loss: 0.505254  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.748634, Avg loss: 0.940508 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.440061  [    0/ 8784]\n",
      "loss: 0.413067  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.943778 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.481767  [    0/ 8784]\n",
      "loss: 0.521119  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747268, Avg loss: 0.943986 \n",
      "\n",
      "CPU times: user 15.9 s, sys: 757 ms, total: 16.6 s\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.71      0.76      0.73        38\n",
      "       Czech       0.50      0.20      0.28        96\n",
      "       Dutch       0.73      0.47      0.57        51\n",
      "     English       0.68      0.87      0.76       573\n",
      "      French       0.00      0.00      0.00        39\n",
      "      German       0.56      0.40      0.46       121\n",
      "       Greek       0.68      0.56      0.61        34\n",
      "       Irish       0.65      0.30      0.41        37\n",
      "     Italian       0.62      0.73      0.67       128\n",
      "    Japanese       0.84      0.83      0.84       156\n",
      "      Korean       0.30      0.30      0.30        10\n",
      "      Polish       0.47      0.31      0.37        26\n",
      "  Portuguese       0.25      0.11      0.15         9\n",
      "     Russian       0.81      0.87      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.56      0.40      0.47        50\n",
      "  Vietnamese       1.00      0.15      0.27        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.57      0.46      0.48      2196\n",
      "weighted avg       0.72      0.75      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.GRU,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.875168  [    0/ 8784]\n",
      "loss: 1.732089  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.554645, Avg loss: 1.542402 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.660108  [    0/ 8784]\n",
      "loss: 1.294080  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.628871, Avg loss: 1.269239 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.254287  [    0/ 8784]\n",
      "loss: 1.296043  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.669854, Avg loss: 1.152408 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.151398  [    0/ 8784]\n",
      "loss: 1.006115  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.693534, Avg loss: 1.080060 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.090511  [    0/ 8784]\n",
      "loss: 0.937375  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.705829, Avg loss: 1.025246 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.898771  [    0/ 8784]\n",
      "loss: 0.731767  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724044, Avg loss: 0.977456 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.781482  [    0/ 8784]\n",
      "loss: 0.762931  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.727231, Avg loss: 0.947536 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.703454  [    0/ 8784]\n",
      "loss: 0.858764  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729508, Avg loss: 0.940425 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.588037  [    0/ 8784]\n",
      "loss: 0.631037  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.922806 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.628890  [    0/ 8784]\n",
      "loss: 0.578595  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734517, Avg loss: 0.928720 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.584863  [    0/ 8784]\n",
      "loss: 0.628271  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.931452 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.552817  [    0/ 8784]\n",
      "loss: 0.761206  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.926917 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.509454  [    0/ 8784]\n",
      "loss: 0.577276  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.936473 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.478059  [    0/ 8784]\n",
      "loss: 0.537208  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743625, Avg loss: 0.942314 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.669557  [    0/ 8784]\n",
      "loss: 0.378693  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.748179, Avg loss: 0.947480 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.405621  [    0/ 8784]\n",
      "loss: 0.532567  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.750455, Avg loss: 0.959899 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.394683  [    0/ 8784]\n",
      "loss: 0.571932  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.749089, Avg loss: 0.951770 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.380647  [    0/ 8784]\n",
      "loss: 0.558956  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.749089, Avg loss: 0.997529 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.415653  [    0/ 8784]\n",
      "loss: 0.540969  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.749089, Avg loss: 0.987103 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.536361  [    0/ 8784]\n",
      "loss: 0.367854  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.753643, Avg loss: 1.000163 \n",
      "\n",
      "CPU times: user 14.6 s, sys: 779 ms, total: 15.4 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.95      1.00      0.97       340\n",
      "     Chinese       0.81      0.76      0.78        38\n",
      "       Czech       0.53      0.27      0.36        96\n",
      "       Dutch       0.90      0.37      0.53        51\n",
      "     English       0.69      0.87      0.77       573\n",
      "      French       0.14      0.08      0.10        39\n",
      "      German       0.60      0.40      0.48       121\n",
      "       Greek       0.83      0.44      0.58        34\n",
      "       Irish       0.74      0.38      0.50        37\n",
      "     Italian       0.65      0.73      0.69       128\n",
      "    Japanese       0.83      0.83      0.83       156\n",
      "      Korean       0.33      0.40      0.36        10\n",
      "      Polish       0.58      0.42      0.49        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.80      0.89      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.48      0.28      0.35        50\n",
      "  Vietnamese       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.60      0.46      0.49      2196\n",
      "weighted avg       0.74      0.75      0.73      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6YBam_3t-fO"
   },
   "source": [
    "1.3 Загрузите предобученные эмбеддинги (https://disk.yandex.ru/d/BHuT2tEXr_yBOQ?w=1) в модуль `nn.Embedding` и обучите модели из 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesDecepticonRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(56, 50, padding_idx=0), 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.50d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.ones(len(surnames_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, ch in enumerate(surnames_dataset.vocab.alphabet):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[ch].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.844056  [    0/ 8784]\n",
      "loss: 1.964587  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.468579, Avg loss: 1.820964 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.773107  [    0/ 8784]\n",
      "loss: 1.707007  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.549180, Avg loss: 1.588969 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.587244  [    0/ 8784]\n",
      "loss: 1.545814  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.585155, Avg loss: 1.436049 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.449910  [    0/ 8784]\n",
      "loss: 1.292889  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.625228, Avg loss: 1.315430 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.052271  [    0/ 8784]\n",
      "loss: 1.246510  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.650273, Avg loss: 1.217674 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.177599  [    0/ 8784]\n",
      "loss: 1.405028  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.673042, Avg loss: 1.183046 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.015822  [    0/ 8784]\n",
      "loss: 1.124703  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.685792, Avg loss: 1.121246 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.061003  [    0/ 8784]\n",
      "loss: 1.004349  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.699454, Avg loss: 1.106312 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.775783  [    0/ 8784]\n",
      "loss: 0.997083  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.692168, Avg loss: 1.048207 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.883357  [    0/ 8784]\n",
      "loss: 0.817463  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.700820, Avg loss: 1.048577 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.879294  [    0/ 8784]\n",
      "loss: 0.932797  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.706740, Avg loss: 1.018107 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.807468  [    0/ 8784]\n",
      "loss: 0.849311  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.719490, Avg loss: 0.987668 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.866414  [    0/ 8784]\n",
      "loss: 0.872985  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724044, Avg loss: 0.980700 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.893000  [    0/ 8784]\n",
      "loss: 0.806810  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.715392, Avg loss: 0.986593 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.815314  [    0/ 8784]\n",
      "loss: 0.859754  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.722222, Avg loss: 0.973549 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.713729  [    0/ 8784]\n",
      "loss: 0.819714  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734973, Avg loss: 0.950494 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.668632  [    0/ 8784]\n",
      "loss: 0.610967  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.942311 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.726248  [    0/ 8784]\n",
      "loss: 0.629716  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.942766 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.745061  [    0/ 8784]\n",
      "loss: 0.793065  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.725865, Avg loss: 0.974755 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.698626  [    0/ 8784]\n",
      "loss: 0.702179  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731785, Avg loss: 0.971733 \n",
      "\n",
      "CPU times: user 13.9 s, sys: 468 ms, total: 14.3 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.94      1.00      0.97       340\n",
      "     Chinese       0.70      0.84      0.76        38\n",
      "       Czech       0.42      0.22      0.29        96\n",
      "       Dutch       0.76      0.25      0.38        51\n",
      "     English       0.64      0.90      0.75       573\n",
      "      French       0.50      0.08      0.13        39\n",
      "      German       0.63      0.27      0.38       121\n",
      "       Greek       0.62      0.47      0.53        34\n",
      "       Irish       0.80      0.22      0.34        37\n",
      "     Italian       0.59      0.70      0.64       128\n",
      "    Japanese       0.81      0.85      0.83       156\n",
      "      Korean       0.17      0.10      0.12        10\n",
      "      Polish       0.47      0.27      0.34        26\n",
      "  Portuguese       1.00      0.11      0.20         9\n",
      "     Russian       0.83      0.84      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.44      0.16      0.24        50\n",
      "  Vietnamese       0.33      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.73      2196\n",
      "   macro avg       0.59      0.41      0.44      2196\n",
      "weighted avg       0.72      0.73      0.70      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.900342  [    0/ 8784]\n",
      "loss: 2.213560  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.426685, Avg loss: 1.954773 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.061828  [    0/ 8784]\n",
      "loss: 1.852823  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.525046, Avg loss: 1.633880 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.755817  [    0/ 8784]\n",
      "loss: 1.605192  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.571038, Avg loss: 1.474017 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.500857  [    0/ 8784]\n",
      "loss: 1.445649  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.610656, Avg loss: 1.340348 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.162403  [    0/ 8784]\n",
      "loss: 1.348665  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.642077, Avg loss: 1.252978 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.204712  [    0/ 8784]\n",
      "loss: 1.063030  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.663479, Avg loss: 1.161660 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.942881  [    0/ 8784]\n",
      "loss: 1.049383  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.684882, Avg loss: 1.113877 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.114825  [    0/ 8784]\n",
      "loss: 1.070152  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.696721, Avg loss: 1.044551 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.859738  [    0/ 8784]\n",
      "loss: 0.820544  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.705373, Avg loss: 1.021037 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.682327  [    0/ 8784]\n",
      "loss: 1.067902  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.700820, Avg loss: 0.999282 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.772260  [    0/ 8784]\n",
      "loss: 0.807716  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.716758, Avg loss: 0.971943 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.747040  [    0/ 8784]\n",
      "loss: 0.892590  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.719490, Avg loss: 0.962619 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.740001  [    0/ 8784]\n",
      "loss: 0.544213  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726321, Avg loss: 0.944224 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.660015  [    0/ 8784]\n",
      "loss: 0.867568  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728142, Avg loss: 0.921567 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.690466  [    0/ 8784]\n",
      "loss: 0.650512  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728142, Avg loss: 0.948623 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.544168  [    0/ 8784]\n",
      "loss: 0.593569  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731330, Avg loss: 0.940830 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.662864  [    0/ 8784]\n",
      "loss: 0.526543  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739071, Avg loss: 0.922299 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.522709  [    0/ 8784]\n",
      "loss: 0.639003  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.925198 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.576465  [    0/ 8784]\n",
      "loss: 0.549394  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734973, Avg loss: 0.927748 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.434710  [    0/ 8784]\n",
      "loss: 0.368915  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739071, Avg loss: 0.917749 \n",
      "\n",
      "CPU times: user 14.6 s, sys: 1.24 s, total: 15.8 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.69      0.82      0.75        38\n",
      "       Czech       0.53      0.22      0.31        96\n",
      "       Dutch       0.64      0.27      0.38        51\n",
      "     English       0.66      0.88      0.76       573\n",
      "      French       0.11      0.05      0.07        39\n",
      "      German       0.47      0.37      0.42       121\n",
      "       Greek       0.61      0.50      0.55        34\n",
      "       Irish       0.75      0.24      0.37        37\n",
      "     Italian       0.67      0.75      0.71       128\n",
      "    Japanese       0.83      0.83      0.83       156\n",
      "      Korean       0.33      0.30      0.32        10\n",
      "      Polish       0.57      0.31      0.40        26\n",
      "  Portuguese       1.00      0.11      0.20         9\n",
      "     Russian       0.83      0.83      0.83       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.67      0.36      0.47        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.60      0.44      0.47      2196\n",
      "weighted avg       0.72      0.74      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.875406  [    0/ 8784]\n",
      "loss: 1.868150  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.447177, Avg loss: 1.894987 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.730289  [    0/ 8784]\n",
      "loss: 1.541893  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.535519, Avg loss: 1.590992 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.390318  [    0/ 8784]\n",
      "loss: 1.433776  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.595628, Avg loss: 1.429333 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.192235  [    0/ 8784]\n",
      "loss: 1.437784  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.624317, Avg loss: 1.304180 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.273698  [    0/ 8784]\n",
      "loss: 1.454974  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.644809, Avg loss: 1.221057 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.360022  [    0/ 8784]\n",
      "loss: 1.316154  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.673042, Avg loss: 1.140971 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.996415  [    0/ 8784]\n",
      "loss: 1.000092  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.683060, Avg loss: 1.093105 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.843947  [    0/ 8784]\n",
      "loss: 0.961851  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.699454, Avg loss: 1.052783 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 1.123075  [    0/ 8784]\n",
      "loss: 1.106619  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.701730, Avg loss: 1.015682 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.818433  [    0/ 8784]\n",
      "loss: 0.984435  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.700820, Avg loss: 1.025835 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 1.086803  [    0/ 8784]\n",
      "loss: 0.888522  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.713570, Avg loss: 0.989604 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.672689  [    0/ 8784]\n",
      "loss: 0.793593  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.715847, Avg loss: 0.987255 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.769277  [    0/ 8784]\n",
      "loss: 0.636032  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.711293, Avg loss: 0.982809 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.985721  [    0/ 8784]\n",
      "loss: 0.761178  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734062, Avg loss: 0.959015 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.682634  [    0/ 8784]\n",
      "loss: 0.670928  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724954, Avg loss: 0.958361 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.736224  [    0/ 8784]\n",
      "loss: 0.680919  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.954255 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.761587  [    0/ 8784]\n",
      "loss: 0.680614  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741803, Avg loss: 0.950929 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.760193  [    0/ 8784]\n",
      "loss: 0.766182  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742259, Avg loss: 0.944505 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.619518  [    0/ 8784]\n",
      "loss: 0.709548  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.953206 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.447549  [    0/ 8784]\n",
      "loss: 0.576108  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741803, Avg loss: 0.978827 \n",
      "\n",
      "CPU times: user 14.5 s, sys: 1.21 s, total: 15.8 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.71      0.79      0.75        38\n",
      "       Czech       0.52      0.17      0.25        96\n",
      "       Dutch       0.68      0.29      0.41        51\n",
      "     English       0.64      0.92      0.75       573\n",
      "      French       0.33      0.05      0.09        39\n",
      "      German       0.63      0.36      0.46       121\n",
      "       Greek       0.55      0.47      0.51        34\n",
      "       Irish       0.83      0.27      0.41        37\n",
      "     Italian       0.65      0.76      0.70       128\n",
      "    Japanese       0.79      0.85      0.82       156\n",
      "      Korean       0.27      0.30      0.29        10\n",
      "      Polish       0.50      0.27      0.35        26\n",
      "  Portuguese       0.33      0.11      0.17         9\n",
      "     Russian       0.88      0.82      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.41      0.24      0.30        50\n",
      "  Vietnamese       0.33      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.56      0.43      0.46      2196\n",
      "weighted avg       0.73      0.74      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7kf990U9Do-"
   },
   "source": [
    "## 2. Классификация новостей на основе заголовка\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/FN-EgWGIpyjLxQ?w=1\n",
    "\n",
    "Эмбеддинги: https://nlp.stanford.edu/projects/glove/ (находите ссылку на архив\n",
    "glove.6B.zip, в нем несколько файлов с эмбеддингами слов, выбираете один из файлов в\n",
    "архиве)\n",
    "\n",
    "2.1 Загрузите набор данных train.csv. Выполните предобработку столбца Title\n",
    "\n",
    "2.2 На основе этих данных создайте датасет NewsDataset . Не забудьте добавить\n",
    "специальные токены `<PAD>` для дополнения последовательностей до нужной длины и\n",
    "`<UNK>` для корректной обработке ранее не встречавшихся токенов. В данной задаче\n",
    "рассматривайте отдельные слова как токены. Разбейте датасет на обучающее и\n",
    "валидационное множество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def simple_preprocess_news_title(title: str) -> str:\n",
    "    return title.lower()\n",
    "\n",
    "\n",
    "def complex_preprocess_news_title(\n",
    "        title: str,\n",
    "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
    "        min_word_len: int = 0,\n",
    ") -> str:\n",
    "    title = simple_preprocess_news_title(title)\n",
    "    title = PATTERN.sub(\" \", title)\n",
    "\n",
    "    words = []\n",
    "    for word in nltk.word_tokenize(title):\n",
    "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "            if not lemmatizer_or_stemmer:\n",
    "                words.append(word)\n",
    "                continue\n",
    "            word = lemmatizer_or_stemmer(word)\n",
    "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "                words.append(word)\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def wordnet_lemmatizer(token: str) -> str:\n",
    "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
    "\n",
    "\n",
    "_snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "\n",
    "\n",
    "def snowball_stemmer(token: str) -> str:\n",
    "    return _snowball_stemmer.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVocab:\n",
    "    pad = \"<PAD>\"\n",
    "    unknown = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, news_titles: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for title in news_titles:\n",
    "            words = nltk.word_tokenize(title)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
    "        unknown_idx = w2i[self.unknown]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, review: str) -> torch.Tensor:\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(review)]\n",
    "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \" \".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    titles: t.List[str]\n",
    "    classes: t.List[int]\n",
    "    vocab: NewsVocab\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path, preprocess: t.Callable[[str], str], vocab: NewsVocab = None):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.titles = self.df[\"Title\"].apply(preprocess).tolist()\n",
    "        self.vocab = vocab or NewsVocab(self.titles)\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(w.lower()) for w in self.titles])\n",
    "        self.targets = torch.tensor(self.df[\"Class Index\"].to_numpy(), dtype=torch.long) - 1\n",
    "        self.classes = self.targets.unique().tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, title: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(title)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 7600)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_news_title(title: str) -> str:\n",
    "    return complex_preprocess_news_title(title, lemmatizer_or_stemmer=snowball_stemmer, min_word_len=3)\n",
    "\n",
    "\n",
    "train_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/train.csv\",\n",
    "    preprocess_news_title,\n",
    ")\n",
    "test_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/test.csv\",\n",
    "    preprocess_news_title,\n",
    "    vocab=train_news_dataset.vocab,\n",
    ")\n",
    "len(train_news_dataset), len(test_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_dataloader = DataLoader(train_news_dataset, batch_size=128, shuffle=True)\n",
    "test_news_dataloader = DataLoader(test_news_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Создайте модель для классификации, используя слой nn.Embedding и слой nn.RNN.\n",
    "эмбеддинги инициализируйте случайным образом не забудьте указать аргумент padding_idx для nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.399483  [    0/120000]\n",
      "loss: 0.665744  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.757368, Avg loss: 0.653162 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.686342  [    0/120000]\n",
      "loss: 0.623132  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.816711, Avg loss: 0.520643 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.592750  [    0/120000]\n",
      "loss: 0.603143  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.833947, Avg loss: 0.466934 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.355661  [    0/120000]\n",
      "loss: 0.371405  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.848026, Avg loss: 0.443782 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.248916  [    0/120000]\n",
      "loss: 0.375288  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.852237, Avg loss: 0.445302 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.334263  [    0/120000]\n",
      "loss: 0.254900  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.853158, Avg loss: 0.432706 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.201589  [    0/120000]\n",
      "loss: 0.301010  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.854868, Avg loss: 0.439724 \n",
      "\n",
      "CPU times: user 1min 6s, sys: 14.4 s, total: 1min 20s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Переобучите модель, заменив слой nn.RNN на nn.LSTM и nn.GRU . Сравните качество\n",
    "на тестовой выборке. Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.385408  [    0/120000]\n",
      "loss: 0.506344  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.797763, Avg loss: 0.555189 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.469934  [    0/120000]\n",
      "loss: 0.455326  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.835132, Avg loss: 0.463926 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.469752  [    0/120000]\n",
      "loss: 0.444949  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.847105, Avg loss: 0.436783 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.253789  [    0/120000]\n",
      "loss: 0.449008  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.852237, Avg loss: 0.422752 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.302637  [    0/120000]\n",
      "loss: 0.479967  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.854868, Avg loss: 0.419413 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.237966  [    0/120000]\n",
      "loss: 0.404549  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.857500, Avg loss: 0.426447 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.256313  [    0/120000]\n",
      "loss: 0.324134  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.858421, Avg loss: 0.434198 \n",
      "\n",
      "CPU times: user 1min 4s, sys: 11.3 s, total: 1min 15s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.381036  [    0/120000]\n",
      "loss: 0.679253  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.771447, Avg loss: 0.615910 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.593520  [    0/120000]\n",
      "loss: 0.523701  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.822237, Avg loss: 0.503939 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.616606  [    0/120000]\n",
      "loss: 0.389013  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.835658, Avg loss: 0.468799 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.350165  [    0/120000]\n",
      "loss: 0.470860  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.845263, Avg loss: 0.448543 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.394414  [    0/120000]\n",
      "loss: 0.423523  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.846447, Avg loss: 0.441016 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.378863  [    0/120000]\n",
      "loss: 0.383736  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.854868, Avg loss: 0.438653 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.288676  [    0/120000]\n",
      "loss: 0.322292  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.856053, Avg loss: 0.437164 \n",
      "\n",
      "CPU times: user 1min 4s, sys: 11.8 s, total: 1min 15s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Выполните пункты 2.3 и 2.4, используя предобученные эмбеддинги Glove.\n",
    "Прокомментируйте результат.\n",
    "Эмбеддинги из скачанного файла загрузите в виде двумерного тензора pretrained_embeddings.\n",
    "Обратите внимание, что номер строки в этом тензоре должен соответствовать\n",
    "токену (слову), имеющему такой индекс в вашем словаре.\n",
    "для слов, которых нет в файле с эмбеддингами, инициализуйте эмбеддинг\n",
    "случайным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21963/21963 [01:51<00:00, 197.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Embedding(21963, 50, padding_idx=0), 6143)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.50d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.empty(len(train_news_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, w in tqdm(enumerate(train_news_dataset.vocab.alphabet), total=len(train_news_dataset.vocab.alphabet)):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[w].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.378969  [    0/120000]\n",
      "loss: 0.636690  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.742368, Avg loss: 0.678814 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.667430  [    0/120000]\n",
      "loss: 0.780115  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.761711, Avg loss: 0.638612 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.729674  [    0/120000]\n",
      "loss: 0.589769  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.774737, Avg loss: 0.614285 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.614638  [    0/120000]\n",
      "loss: 0.477693  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.778553, Avg loss: 0.595008 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.602732  [    0/120000]\n",
      "loss: 0.641261  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.792237, Avg loss: 0.584499 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.621062  [    0/120000]\n",
      "loss: 0.531873  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.790000, Avg loss: 0.574094 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.443483  [    0/120000]\n",
      "loss: 0.589313  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.794079, Avg loss: 0.570096 \n",
      "\n",
      "CPU times: user 1min, sys: 7.01 s, total: 1min 7s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_rnn_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.389539  [    0/120000]\n",
      "loss: 0.522932  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.779342, Avg loss: 0.592925 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.518597  [    0/120000]\n",
      "loss: 0.486259  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.806711, Avg loss: 0.538815 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.446654  [    0/120000]\n",
      "loss: 0.566288  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.816842, Avg loss: 0.507826 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.449597  [    0/120000]\n",
      "loss: 0.478184  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.827895, Avg loss: 0.484715 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.294284  [    0/120000]\n",
      "loss: 0.419032  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.829211, Avg loss: 0.484127 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.501319  [    0/120000]\n",
      "loss: 0.342621  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.830789, Avg loss: 0.467524 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.413230  [    0/120000]\n",
      "loss: 0.352283  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.836316, Avg loss: 0.464462 \n",
      "\n",
      "CPU times: user 1min 1s, sys: 7.76 s, total: 1min 9s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_lstm_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.398109  [    0/120000]\n",
      "loss: 0.761654  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.763553, Avg loss: 0.636516 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.707721  [    0/120000]\n",
      "loss: 0.580133  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.783289, Avg loss: 0.584327 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.544067  [    0/120000]\n",
      "loss: 0.548390  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.795921, Avg loss: 0.552553 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.581506  [    0/120000]\n",
      "loss: 0.554088  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.806842, Avg loss: 0.540216 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.563062  [    0/120000]\n",
      "loss: 0.537943  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.805526, Avg loss: 0.533407 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.401021  [    0/120000]\n",
      "loss: 0.409920  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.808421, Avg loss: 0.528913 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.549597  [    0/120000]\n",
      "loss: 0.326002  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.815132, Avg loss: 0.508747 \n",
      "\n",
      "CPU times: user 1min, sys: 7.3 s, total: 1min 8s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_gru_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_table(\n",
    "        models: t.List[t.Tuple[str, NewsClassifier]],\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> pd.DataFrame:\n",
    "    general_report = {}\n",
    "    for name, model in models:\n",
    "        report = {}\n",
    "        y_test, y_pred = get_y_test_y_pred(model, test_dataloader, device)\n",
    "        ms = metrics.classification_report(y_test, y_pred, zero_division=True, output_dict=True)\n",
    "        report[\"accuracy\"] = ms[\"accuracy\"]\n",
    "        report[\"precision (w avg)\"] = ms[\"weighted avg\"][\"precision\"]\n",
    "        report[\"recall (w avg)\"] = ms[\"weighted avg\"][\"recall\"]\n",
    "        report[\"f1-score (w avg)\"] = ms[\"weighted avg\"][\"f1-score\"]\n",
    "        general_report[name] = report\n",
    "    return pd.DataFrame(general_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "      <th>RNN (pretrained)</th>\n",
       "      <th>LSTM (pretrained)</th>\n",
       "      <th>GRU (pretrained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.854868</td>\n",
       "      <td>0.858421</td>\n",
       "      <td>0.855921</td>\n",
       "      <td>0.794079</td>\n",
       "      <td>0.836316</td>\n",
       "      <td>0.815132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision (w avg)</th>\n",
       "      <td>0.855221</td>\n",
       "      <td>0.858569</td>\n",
       "      <td>0.856023</td>\n",
       "      <td>0.793776</td>\n",
       "      <td>0.838553</td>\n",
       "      <td>0.815611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall (w avg)</th>\n",
       "      <td>0.854868</td>\n",
       "      <td>0.858421</td>\n",
       "      <td>0.855921</td>\n",
       "      <td>0.794079</td>\n",
       "      <td>0.836316</td>\n",
       "      <td>0.815132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score (w avg)</th>\n",
       "      <td>0.854592</td>\n",
       "      <td>0.857924</td>\n",
       "      <td>0.855503</td>\n",
       "      <td>0.793563</td>\n",
       "      <td>0.836451</td>\n",
       "      <td>0.815042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RNN      LSTM       GRU  RNN (pretrained)  \\\n",
       "accuracy           0.854868  0.858421  0.855921          0.794079   \n",
       "precision (w avg)  0.855221  0.858569  0.856023          0.793776   \n",
       "recall (w avg)     0.854868  0.858421  0.855921          0.794079   \n",
       "f1-score (w avg)   0.854592  0.857924  0.855503          0.793563   \n",
       "\n",
       "                   LSTM (pretrained)  GRU (pretrained)  \n",
       "accuracy                    0.836316          0.815132  \n",
       "precision (w avg)           0.838553          0.815611  \n",
       "recall (w avg)              0.836316          0.815132  \n",
       "f1-score (w avg)            0.836451          0.815042  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = make_pivot_table(\n",
    "    [\n",
    "        (\"RNN\", news_rnn_net),\n",
    "        (\"LSTM\", news_lstm_net),\n",
    "        (\"GRU\", news_gru_net),\n",
    "        (\"RNN (pretrained)\", news_rnn_pretrained_net),\n",
    "        (\"LSTM (pretrained)\", news_lstm_pretrained_net),\n",
    "        (\"GRU (pretrained)\", news_gru_pretrained_net),\n",
    "    ],\n",
    "    test_news_dataloader,\n",
    "    DEVICE,\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = report.plot.bar(rot=15)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1));"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPopRjm9A6la5QJRG/PWjfN",
   "collapsed_sections": [],
   "name": "blank__07_rnn_1_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
