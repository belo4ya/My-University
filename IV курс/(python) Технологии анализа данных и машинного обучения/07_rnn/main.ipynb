{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5669,
     "status": "ok",
     "timestamp": 1619632510103,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "zKMq7dp2W15Y",
    "outputId": "ce2273c5-6a96-4216-9d88-fbee51bf5ff0"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_cuda(device: str) -> bool:\n",
    "    return device == \"cuda\"\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_dataloader: DataLoader,\n",
    "        epochs: int,\n",
    "        test_dataloader: DataLoader = None,\n",
    "        lr_scheduler=None,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.List[float]:\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "        train_loss = train_loop(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "        )\n",
    "        train_losses.append(train_loss.item())\n",
    "        if test_dataloader:\n",
    "            loss, acc = test_loop(test_dataloader, model, loss_fn, device=device)\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step(loss)\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> torch.Tensor:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss\n",
    "        if batch % verbose == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, correct = 0, 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        avg_loss += loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # noqa\n",
    "\n",
    "        del x, y, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:>4f}, Avg loss: {avg_loss:>8f} \\n\")\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_test_split(dataset: t.Union[Dataset, t.Sized], train_part: float) -> t.Tuple[Subset, Subset]:\n",
    "    train_size = round(train_part * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_test_y_pred(\n",
    "        model: nn.Module,\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.hstack(y_test).detach().cpu(), torch.hstack(y_pred).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm-QilGISxkt"
   },
   "source": [
    "## 1. Классификация фамилий (RNN)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/frNchuaBQVLxyA?w=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdPr92i6k-If"
   },
   "source": [
    "1.1 Используя класс `nn.RNNCell` (абстракцию для отдельного временного шага RNN), реализуйте простейшую рекуррентную сеть Элмана в виде класса `RNN`. Используя созданный класс `RNN`, решите задачу классификации фамилий. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ir6UUkl6l4tp"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, hx: torch.Tensor = None):\n",
    "        batch_size, sequence_size, _ = inputs.size()\n",
    "        inputs = inputs.permute(1, 0, 2)  # для nn.RNNCell batch_size должен быть на 2-ом месте\n",
    "\n",
    "        if hx is None:\n",
    "            # инициализация как в nn.RNN\n",
    "            hx = torch.zeros(batch_size, self.hidden_size, dtype=inputs.dtype, device=inputs.device)\n",
    "        else:\n",
    "            # 1-ая размерность равная 1 для совместимости с nn.RNN\n",
    "            hx = hx.squeeze(0)  # избавляемся от 1-ой размерности равной 1\n",
    "\n",
    "        hidden = []\n",
    "        for i in range(sequence_size):\n",
    "            hx = self.rnn_cell(inputs[i], hx)\n",
    "            hidden.append(hx)\n",
    "\n",
    "        hidden = torch.stack(hidden)\n",
    "        hx = hidden[-1].unsqueeze(0)\n",
    "        # выход и скрытое состояние размерностей: (batch_size, ...), (1, batch_size, ...)\n",
    "        return hidden.permute(1, 0, 2), hx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка реализации RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "input_size, hidden_size = 4, 5\n",
    "inputs = torch.randn(2, 3, input_size)\n",
    "hx = torch.randn(1, 2, hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "my_rnn = RNN(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "true_rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<UnsqueezeBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ 100% совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.rnn = RNN(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        # здесь позволим себе потерять скрытое состояние hx\n",
    "        # в будущих моделях будем его сохранять\n",
    "        x, hx = self.rnn(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesVocab:\n",
    "    pad = \"<PAD>\"\n",
    "\n",
    "    def __init__(self, surnames: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for w in map(str.lower, surnames):\n",
    "            uniques.update(w)\n",
    "            max_len = max(len(w), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, *uniques]\n",
    "        self.max_len = max_len\n",
    "        self.ch2i = {ch: i for i, ch in enumerate(self.alphabet)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        indices = [self.ch2i[ch] for ch in word]\n",
    "        indices += [self.ch2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.ch2i[self.pad], as_tuple=True)[0]\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \"\".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class SurnamesDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    surnames: t.List[str]\n",
    "    vocab: SurnamesVocab\n",
    "    labeler: LabelEncoder\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.surnames = self.df[\"surname\"].tolist()\n",
    "        self.vocab = SurnamesVocab(self.surnames)\n",
    "        size = self.vocab.encode(self.surnames[0].lower()).size()\n",
    "        data = torch.vstack([self.vocab.encode(w.lower()) for w in self.surnames])\n",
    "        self.data = data.view(len(self.surnames), *size)\n",
    "\n",
    "        self.labeler = LabelEncoder()\n",
    "        targets = self.labeler.fit_transform(self.df[\"nationality\"])\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(word)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames_dataset = SurnamesDataset(DATA_DIR / \"surnames.csv\")\n",
    "len(surnames_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8784 2196\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_surnames_dataset, test_surnames_dataset = train_test_split(surnames_dataset, train_part=0.8)\n",
    "print(len(train_surnames_dataset), len(test_surnames_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "handmade_rnn_net = SurnamesRNNClassifier(\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(handmade_rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.874556  [    0/ 8784]\n",
      "loss: 1.421411  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.641166, Avg loss: 1.217882 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.065406  [    0/ 8784]\n",
      "loss: 1.125816  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.706284, Avg loss: 1.034739 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.922047  [    0/ 8784]\n",
      "loss: 0.849748  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.723133, Avg loss: 0.945770 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.826200  [    0/ 8784]\n",
      "loss: 0.791709  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735428, Avg loss: 0.909884 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.740576  [    0/ 8784]\n",
      "loss: 0.911624  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.874033 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.717624  [    0/ 8784]\n",
      "loss: 0.632623  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.749089, Avg loss: 0.864982 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.517666  [    0/ 8784]\n",
      "loss: 0.676171  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.749545, Avg loss: 0.858542 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.633696  [    0/ 8784]\n",
      "loss: 0.738699  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.752277, Avg loss: 0.877561 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.601152  [    0/ 8784]\n",
      "loss: 0.488232  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.761384, Avg loss: 0.839012 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.392385  [    0/ 8784]\n",
      "loss: 0.535486  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.759563, Avg loss: 0.848911 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.511275  [    0/ 8784]\n",
      "loss: 0.523403  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.760018, Avg loss: 0.853630 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.388022  [    0/ 8784]\n",
      "loss: 0.566504  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.757741, Avg loss: 0.864279 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.386875  [    0/ 8784]\n",
      "loss: 0.418838  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.758652, Avg loss: 0.885487 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.474010  [    0/ 8784]\n",
      "loss: 0.426867  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.760018, Avg loss: 0.887180 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.337869  [    0/ 8784]\n",
      "loss: 0.620182  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.774590, Avg loss: 0.869153 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.308572  [    0/ 8784]\n",
      "loss: 0.393883  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.761384, Avg loss: 0.895038 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.472230  [    0/ 8784]\n",
      "loss: 0.420854  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.760474, Avg loss: 0.895717 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.338669  [    0/ 8784]\n",
      "loss: 0.383420  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.772769, Avg loss: 0.909704 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.307094  [    0/ 8784]\n",
      "loss: 0.266759  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.765027, Avg loss: 0.929497 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.208056  [    0/ 8784]\n",
      "loss: 0.307956  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.769581, Avg loss: 0.935548 \n",
      "\n",
      "CPU times: user 17 s, sys: 588 ms, total: 17.6 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=handmade_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.72      0.74      0.73        38\n",
      "       Czech       0.60      0.35      0.44        96\n",
      "       Dutch       0.76      0.43      0.55        51\n",
      "     English       0.71      0.88      0.79       573\n",
      "      French       0.13      0.05      0.07        39\n",
      "      German       0.56      0.51      0.53       121\n",
      "       Greek       0.70      0.56      0.62        34\n",
      "       Irish       0.70      0.43      0.53        37\n",
      "     Italian       0.72      0.78      0.75       128\n",
      "    Japanese       0.87      0.88      0.88       156\n",
      "      Korean       0.25      0.20      0.22        10\n",
      "      Polish       0.61      0.42      0.50        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.87      0.84      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.43      0.48      0.45        50\n",
      "  Vietnamese       0.38      0.23      0.29        13\n",
      "\n",
      "    accuracy                           0.77      2196\n",
      "   macro avg       0.55      0.49      0.51      2196\n",
      "weighted avg       0.75      0.77      0.75      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(handmade_rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2MIErKTo9aO"
   },
   "source": [
    "1.2 Замените модуль `RNN` из 1.1 на модули `nn.RNN`, `nn.LSTM` и `nn.GRU` (не забудьте указать аргумент `batch_first=True`). Сравните результаты работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesAutobotRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.hx, self.cx = None, None  # начальное скрытое состояние RNN\n",
    "        self.rnn = rnn_cls(input_size=embedding_dim, hidden_size=rnn_hidden_size)  # подставляем любую реализацию RNN\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:  # LSTM возвращает кортеж из 2-х тензоров в качестве скрытого состояния\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.cx = cx.detach()\n",
    "            self.hx = hx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.RNN,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.883942  [    0/ 8784]\n",
      "loss: 1.602068  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.576503, Avg loss: 1.437185 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.333282  [    0/ 8784]\n",
      "loss: 1.292796  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.661202, Avg loss: 1.199116 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.070057  [    0/ 8784]\n",
      "loss: 0.994886  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.674863, Avg loss: 1.107447 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.030502  [    0/ 8784]\n",
      "loss: 0.881999  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.693078, Avg loss: 1.027522 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.000975  [    0/ 8784]\n",
      "loss: 0.978069  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.710383, Avg loss: 1.005455 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.907455  [    0/ 8784]\n",
      "loss: 0.865072  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.715847, Avg loss: 0.966902 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.604049  [    0/ 8784]\n",
      "loss: 0.780595  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.723133, Avg loss: 0.960819 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.814529  [    0/ 8784]\n",
      "loss: 0.879969  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724044, Avg loss: 0.956446 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.698954  [    0/ 8784]\n",
      "loss: 0.616971  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.941409 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.550896  [    0/ 8784]\n",
      "loss: 0.666326  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729508, Avg loss: 0.918867 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.580977  [    0/ 8784]\n",
      "loss: 0.648883  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.961549 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.456417  [    0/ 8784]\n",
      "loss: 0.590602  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731785, Avg loss: 0.923812 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.461487  [    0/ 8784]\n",
      "loss: 0.661550  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.935437 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.498756  [    0/ 8784]\n",
      "loss: 0.520681  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.936521 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.417843  [    0/ 8784]\n",
      "loss: 0.729319  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.928594 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.506724  [    0/ 8784]\n",
      "loss: 0.552499  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.946771 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.609065  [    0/ 8784]\n",
      "loss: 0.532458  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743169, Avg loss: 0.946399 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.427562  [    0/ 8784]\n",
      "loss: 0.490954  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.958115 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.304979  [    0/ 8784]\n",
      "loss: 0.482456  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.737705, Avg loss: 0.955388 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.442738  [    0/ 8784]\n",
      "loss: 0.432429  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743625, Avg loss: 0.944747 \n",
      "\n",
      "CPU times: user 16.2 s, sys: 956 ms, total: 17.2 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.97      1.00      0.98       340\n",
      "     Chinese       0.74      0.66      0.69        38\n",
      "       Czech       0.49      0.27      0.35        96\n",
      "       Dutch       0.67      0.47      0.55        51\n",
      "     English       0.70      0.83      0.76       573\n",
      "      French       0.13      0.05      0.07        39\n",
      "      German       0.58      0.52      0.55       121\n",
      "       Greek       0.61      0.50      0.55        34\n",
      "       Irish       0.46      0.16      0.24        37\n",
      "     Italian       0.60      0.66      0.63       128\n",
      "    Japanese       0.83      0.85      0.84       156\n",
      "      Korean       0.33      0.40      0.36        10\n",
      "      Polish       0.62      0.38      0.48        26\n",
      "  Portuguese       0.33      0.11      0.17         9\n",
      "     Russian       0.80      0.88      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.50      0.36      0.42        50\n",
      "  Vietnamese       0.33      0.15      0.21        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.54      0.46      0.48      2196\n",
      "weighted avg       0.72      0.74      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.LSTM,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.884565  [    0/ 8784]\n",
      "loss: 1.831156  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.546903, Avg loss: 1.560420 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.449702  [    0/ 8784]\n",
      "loss: 1.589251  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.628415, Avg loss: 1.303952 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.277747  [    0/ 8784]\n",
      "loss: 1.260169  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.669854, Avg loss: 1.165356 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.056461  [    0/ 8784]\n",
      "loss: 1.085960  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.676230, Avg loss: 1.091754 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.029248  [    0/ 8784]\n",
      "loss: 0.955076  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.692623, Avg loss: 1.033219 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.032812  [    0/ 8784]\n",
      "loss: 0.846041  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.709927, Avg loss: 0.988087 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.890109  [    0/ 8784]\n",
      "loss: 0.765982  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.725410, Avg loss: 0.965844 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.623343  [    0/ 8784]\n",
      "loss: 0.671911  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.723133, Avg loss: 0.960452 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.506297  [    0/ 8784]\n",
      "loss: 0.840388  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.931186 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.539131  [    0/ 8784]\n",
      "loss: 0.771520  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731785, Avg loss: 0.919249 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.620746  [    0/ 8784]\n",
      "loss: 0.757640  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.918505 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.729721  [    0/ 8784]\n",
      "loss: 0.728999  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.922937 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.677733  [    0/ 8784]\n",
      "loss: 0.673619  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.922484 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.468532  [    0/ 8784]\n",
      "loss: 0.798513  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.949048 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.532281  [    0/ 8784]\n",
      "loss: 0.674203  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.941773 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.598234  [    0/ 8784]\n",
      "loss: 0.577957  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.746357, Avg loss: 0.929128 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.494786  [    0/ 8784]\n",
      "loss: 0.624430  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741803, Avg loss: 0.938696 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.400648  [    0/ 8784]\n",
      "loss: 0.419914  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747268, Avg loss: 0.945738 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.441720  [    0/ 8784]\n",
      "loss: 0.440553  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.748179, Avg loss: 0.943594 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.496306  [    0/ 8784]\n",
      "loss: 0.547819  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747268, Avg loss: 0.959969 \n",
      "\n",
      "CPU times: user 18 s, sys: 824 ms, total: 18.8 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.94      1.00      0.97       340\n",
      "     Chinese       0.77      0.79      0.78        38\n",
      "       Czech       0.63      0.28      0.39        96\n",
      "       Dutch       0.78      0.41      0.54        51\n",
      "     English       0.68      0.87      0.76       573\n",
      "      French       0.00      0.00      0.00        39\n",
      "      German       0.58      0.44      0.50       121\n",
      "       Greek       0.62      0.53      0.57        34\n",
      "       Irish       0.83      0.27      0.41        37\n",
      "     Italian       0.58      0.72      0.64       128\n",
      "    Japanese       0.86      0.84      0.85       156\n",
      "      Korean       0.33      0.30      0.32        10\n",
      "      Polish       0.62      0.38      0.48        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.84      0.85      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.38      0.36      0.37        50\n",
      "  Vietnamese       0.67      0.15      0.25        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.56      0.46      0.48      2196\n",
      "weighted avg       0.73      0.75      0.73      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.GRU,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.879841  [    0/ 8784]\n",
      "loss: 1.722876  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.557832, Avg loss: 1.545358 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.655988  [    0/ 8784]\n",
      "loss: 1.203939  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.632969, Avg loss: 1.254734 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.243177  [    0/ 8784]\n",
      "loss: 1.277447  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.664390, Avg loss: 1.149105 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.078428  [    0/ 8784]\n",
      "loss: 1.050015  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.692623, Avg loss: 1.062530 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.105967  [    0/ 8784]\n",
      "loss: 0.912017  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704463, Avg loss: 0.999653 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.869840  [    0/ 8784]\n",
      "loss: 0.698957  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714481, Avg loss: 0.964454 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.777239  [    0/ 8784]\n",
      "loss: 0.767638  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.725410, Avg loss: 0.934358 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.637324  [    0/ 8784]\n",
      "loss: 0.759100  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726321, Avg loss: 0.935210 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.634553  [    0/ 8784]\n",
      "loss: 0.692831  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.918075 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.645766  [    0/ 8784]\n",
      "loss: 0.563110  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.921922 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.646565  [    0/ 8784]\n",
      "loss: 0.679496  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736794, Avg loss: 0.926201 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.576990  [    0/ 8784]\n",
      "loss: 0.714817  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.916441 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.532451  [    0/ 8784]\n",
      "loss: 0.579642  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.948613 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.372089  [    0/ 8784]\n",
      "loss: 0.500557  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735428, Avg loss: 0.936376 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.720009  [    0/ 8784]\n",
      "loss: 0.369867  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 0.942884 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.602505  [    0/ 8784]\n",
      "loss: 0.462491  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747723, Avg loss: 0.938726 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.442358  [    0/ 8784]\n",
      "loss: 0.688259  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.969425 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.377818  [    0/ 8784]\n",
      "loss: 0.462115  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 1.000794 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.501734  [    0/ 8784]\n",
      "loss: 0.435592  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.982158 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.584079  [    0/ 8784]\n",
      "loss: 0.352422  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.750000, Avg loss: 0.980404 \n",
      "\n",
      "CPU times: user 16.6 s, sys: 729 ms, total: 17.3 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.72      0.76      0.74        38\n",
      "       Czech       0.57      0.24      0.34        96\n",
      "       Dutch       0.71      0.43      0.54        51\n",
      "     English       0.69      0.88      0.78       573\n",
      "      French       0.14      0.08      0.10        39\n",
      "      German       0.57      0.40      0.47       121\n",
      "       Greek       0.71      0.44      0.55        34\n",
      "       Irish       0.75      0.24      0.37        37\n",
      "     Italian       0.65      0.73      0.69       128\n",
      "    Japanese       0.81      0.86      0.83       156\n",
      "      Korean       0.00      0.00      0.00        10\n",
      "      Polish       0.50      0.35      0.41        26\n",
      "  Portuguese       0.25      0.11      0.15         9\n",
      "     Russian       0.82      0.87      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.53      0.36      0.43        50\n",
      "  Vietnamese       0.25      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.54      0.43      0.46      2196\n",
      "weighted avg       0.73      0.75      0.73      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что пользовательская реализация RNN, которая при проверки отработала число в число с nn.RNN, дала лучшую точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6YBam_3t-fO"
   },
   "source": [
    "1.3 Загрузите предобученные эмбеддинги (https://disk.yandex.ru/d/BHuT2tEXr_yBOQ?w=1) в модуль `nn.Embedding` и обучите модели из 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesDecepticonRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(56, 50, padding_idx=0), 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.50d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "# инициализация как в nn.Embedding\n",
    "weights = torch.ones(len(surnames_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0  # счетчик отсутствующих токенов\n",
    "for i, ch in enumerate(surnames_dataset.vocab.alphabet):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[ch].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.844056  [    0/ 8784]\n",
      "loss: 1.963993  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.468579, Avg loss: 1.820995 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.773461  [    0/ 8784]\n",
      "loss: 1.701152  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.551002, Avg loss: 1.583422 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.596159  [    0/ 8784]\n",
      "loss: 1.530861  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.593352, Avg loss: 1.425762 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.425993  [    0/ 8784]\n",
      "loss: 1.283223  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.618852, Avg loss: 1.308009 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.013008  [    0/ 8784]\n",
      "loss: 1.279283  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.647996, Avg loss: 1.210004 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.181927  [    0/ 8784]\n",
      "loss: 1.356983  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.673042, Avg loss: 1.168989 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.977154  [    0/ 8784]\n",
      "loss: 1.158678  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.683971, Avg loss: 1.113868 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.075573  [    0/ 8784]\n",
      "loss: 0.966971  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.693534, Avg loss: 1.086907 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.770116  [    0/ 8784]\n",
      "loss: 1.006936  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.691257, Avg loss: 1.053428 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.846536  [    0/ 8784]\n",
      "loss: 0.811924  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.698998, Avg loss: 1.029488 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.851722  [    0/ 8784]\n",
      "loss: 0.911454  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.709927, Avg loss: 0.998172 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.769855  [    0/ 8784]\n",
      "loss: 0.858469  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.717668, Avg loss: 0.987739 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.829248  [    0/ 8784]\n",
      "loss: 0.909832  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.717668, Avg loss: 0.982215 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.831440  [    0/ 8784]\n",
      "loss: 0.739993  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726776, Avg loss: 0.967127 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.793800  [    0/ 8784]\n",
      "loss: 0.773227  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.719490, Avg loss: 0.977175 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.778300  [    0/ 8784]\n",
      "loss: 0.749666  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.957240 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.721109  [    0/ 8784]\n",
      "loss: 0.571693  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.954781 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.811938  [    0/ 8784]\n",
      "loss: 0.681719  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.934672 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.758749  [    0/ 8784]\n",
      "loss: 0.659884  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.948390 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.645239  [    0/ 8784]\n",
      "loss: 0.662477  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.967313 \n",
      "\n",
      "CPU times: user 13 s, sys: 471 ms, total: 13.5 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.94      1.00      0.97       340\n",
      "     Chinese       0.71      0.95      0.81        38\n",
      "       Czech       0.47      0.20      0.28        96\n",
      "       Dutch       0.63      0.24      0.34        51\n",
      "     English       0.64      0.90      0.75       573\n",
      "      French       0.38      0.08      0.13        39\n",
      "      German       0.56      0.31      0.40       121\n",
      "       Greek       0.61      0.41      0.49        34\n",
      "       Irish       0.78      0.19      0.30        37\n",
      "     Italian       0.65      0.69      0.67       128\n",
      "    Japanese       0.75      0.86      0.80       156\n",
      "      Korean       0.33      0.10      0.15        10\n",
      "      Polish       0.47      0.35      0.40        26\n",
      "  Portuguese       0.50      0.11      0.18         9\n",
      "     Russian       0.85      0.84      0.84       458\n",
      "    Scottish       1.00      0.00      0.00        17\n",
      "     Spanish       0.50      0.18      0.26        50\n",
      "  Vietnamese       1.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.73      2196\n",
      "   macro avg       0.65      0.41      0.43      2196\n",
      "weighted avg       0.72      0.73      0.70      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.900342  [    0/ 8784]\n",
      "loss: 2.213983  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.428051, Avg loss: 1.954197 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.061850  [    0/ 8784]\n",
      "loss: 1.854247  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.524135, Avg loss: 1.634682 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.749582  [    0/ 8784]\n",
      "loss: 1.607282  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.575137, Avg loss: 1.472476 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.504245  [    0/ 8784]\n",
      "loss: 1.441958  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.618397, Avg loss: 1.332797 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.156432  [    0/ 8784]\n",
      "loss: 1.344259  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.649362, Avg loss: 1.239605 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.185885  [    0/ 8784]\n",
      "loss: 1.021422  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.667577, Avg loss: 1.154989 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.948046  [    0/ 8784]\n",
      "loss: 1.043611  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.685337, Avg loss: 1.102512 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.065908  [    0/ 8784]\n",
      "loss: 1.068078  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.692623, Avg loss: 1.041122 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.865754  [    0/ 8784]\n",
      "loss: 0.777616  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704463, Avg loss: 1.024664 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.689042  [    0/ 8784]\n",
      "loss: 1.076438  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.708561, Avg loss: 0.999518 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.756285  [    0/ 8784]\n",
      "loss: 0.809872  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.716302, Avg loss: 0.977204 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.708952  [    0/ 8784]\n",
      "loss: 0.917464  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.718124, Avg loss: 0.968807 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.775866  [    0/ 8784]\n",
      "loss: 0.513942  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.730874, Avg loss: 0.942597 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.691796  [    0/ 8784]\n",
      "loss: 0.915396  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724954, Avg loss: 0.922211 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.694179  [    0/ 8784]\n",
      "loss: 0.614471  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724044, Avg loss: 0.944169 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.534124  [    0/ 8784]\n",
      "loss: 0.672754  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.737250, Avg loss: 0.924802 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.674164  [    0/ 8784]\n",
      "loss: 0.542443  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.918931 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.567259  [    0/ 8784]\n",
      "loss: 0.630169  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.748179, Avg loss: 0.922518 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.652757  [    0/ 8784]\n",
      "loss: 0.529133  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739071, Avg loss: 0.944950 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.406437  [    0/ 8784]\n",
      "loss: 0.416101  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.937352 \n",
      "\n",
      "CPU times: user 13.3 s, sys: 1.15 s, total: 14.4 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.95      1.00      0.97       340\n",
      "     Chinese       0.71      0.79      0.75        38\n",
      "       Czech       0.42      0.18      0.25        96\n",
      "       Dutch       0.72      0.35      0.47        51\n",
      "     English       0.65      0.90      0.75       573\n",
      "      French       0.27      0.08      0.12        39\n",
      "      German       0.55      0.39      0.46       121\n",
      "       Greek       0.65      0.44      0.53        34\n",
      "       Irish       0.73      0.22      0.33        37\n",
      "     Italian       0.63      0.69      0.66       128\n",
      "    Japanese       0.89      0.80      0.84       156\n",
      "      Korean       0.38      0.30      0.33        10\n",
      "      Polish       0.50      0.27      0.35        26\n",
      "  Portuguese       0.50      0.11      0.18         9\n",
      "     Russian       0.82      0.84      0.83       458\n",
      "    Scottish       1.00      0.00      0.00        17\n",
      "     Spanish       0.54      0.38      0.45        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.63      0.43      0.47      2196\n",
      "weighted avg       0.73      0.74      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.875406  [    0/ 8784]\n",
      "loss: 1.869347  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.446266, Avg loss: 1.894478 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.730143  [    0/ 8784]\n",
      "loss: 1.539891  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.537341, Avg loss: 1.592430 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.392235  [    0/ 8784]\n",
      "loss: 1.422222  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.592896, Avg loss: 1.425689 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.209486  [    0/ 8784]\n",
      "loss: 1.416513  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.626594, Avg loss: 1.304587 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.268894  [    0/ 8784]\n",
      "loss: 1.414186  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.642077, Avg loss: 1.214843 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.376970  [    0/ 8784]\n",
      "loss: 1.308743  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.668488, Avg loss: 1.142515 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.002071  [    0/ 8784]\n",
      "loss: 1.020531  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.686248, Avg loss: 1.086798 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.860629  [    0/ 8784]\n",
      "loss: 0.943406  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.698998, Avg loss: 1.052603 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 1.087773  [    0/ 8784]\n",
      "loss: 1.087293  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.703097, Avg loss: 1.023140 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.858067  [    0/ 8784]\n",
      "loss: 1.022344  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.710838, Avg loss: 1.024801 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 1.041272  [    0/ 8784]\n",
      "loss: 0.845682  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.719035, Avg loss: 0.987574 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.705879  [    0/ 8784]\n",
      "loss: 0.759907  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726776, Avg loss: 0.970456 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.669911  [    0/ 8784]\n",
      "loss: 0.585181  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.719490, Avg loss: 0.979149 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 1.009854  [    0/ 8784]\n",
      "loss: 0.794174  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.727687, Avg loss: 0.968391 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.718607  [    0/ 8784]\n",
      "loss: 0.691776  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731330, Avg loss: 0.968102 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.683218  [    0/ 8784]\n",
      "loss: 0.663493  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.737250, Avg loss: 0.948013 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.818264  [    0/ 8784]\n",
      "loss: 0.597551  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.960134 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.727238  [    0/ 8784]\n",
      "loss: 0.775666  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731785, Avg loss: 0.982683 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.657666  [    0/ 8784]\n",
      "loss: 0.799044  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.952761 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.459648  [    0/ 8784]\n",
      "loss: 0.582021  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735428, Avg loss: 0.979473 \n",
      "\n",
      "CPU times: user 13.2 s, sys: 1.08 s, total: 14.3 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.92      1.00      0.96       340\n",
      "     Chinese       0.77      0.79      0.78        38\n",
      "       Czech       0.60      0.19      0.29        96\n",
      "       Dutch       0.48      0.29      0.37        51\n",
      "     English       0.64      0.93      0.76       573\n",
      "      French       0.25      0.05      0.09        39\n",
      "      German       0.62      0.40      0.49       121\n",
      "       Greek       0.62      0.47      0.53        34\n",
      "       Irish       0.70      0.19      0.30        37\n",
      "     Italian       0.68      0.64      0.66       128\n",
      "    Japanese       0.75      0.86      0.80       156\n",
      "      Korean       0.40      0.40      0.40        10\n",
      "      Polish       0.50      0.27      0.35        26\n",
      "  Portuguese       0.50      0.11      0.18         9\n",
      "     Russian       0.88      0.78      0.83       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.47      0.36      0.41        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.57      0.43      0.46      2196\n",
      "weighted avg       0.72      0.74      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С предобученными Embedding лучше не стало. Возможно из-за того, что Embedding готовились для слов? (нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7kf990U9Do-"
   },
   "source": [
    "## 2. Классификация новостей на основе заголовка\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/FN-EgWGIpyjLxQ?w=1\n",
    "\n",
    "Эмбеддинги: https://nlp.stanford.edu/projects/glove/ (находите ссылку на архив\n",
    "glove.6B.zip, в нем несколько файлов с эмбеддингами слов, выбираете один из файлов в\n",
    "архиве)\n",
    "\n",
    "2.1 Загрузите набор данных train.csv. Выполните предобработку столбца Title\n",
    "\n",
    "2.2 На основе этих данных создайте датасет NewsDataset . Не забудьте добавить\n",
    "специальные токены `<PAD>` для дополнения последовательностей до нужной длины и\n",
    "`<UNK>` для корректной обработке ранее не встречавшихся токенов. В данной задаче\n",
    "рассматривайте отдельные слова как токены. Разбейте датасет на обучающее и\n",
    "валидационное множество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько вариантов предобработки для экспериментов.\n",
    "\n",
    "_Влияние разных методов предобработки не сильно заметно - 1-2%._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def simple_preprocess_news_title(title: str) -> str:\n",
    "    return title.lower()\n",
    "\n",
    "\n",
    "def complex_preprocess_news_title(\n",
    "        title: str,\n",
    "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
    "        min_word_len: int = 0,\n",
    ") -> str:\n",
    "    title = simple_preprocess_news_title(title)\n",
    "    title = PATTERN.sub(\" \", title)\n",
    "\n",
    "    words = []\n",
    "    for word in nltk.word_tokenize(title):\n",
    "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "            if not lemmatizer_or_stemmer:\n",
    "                words.append(word)\n",
    "                continue\n",
    "            word = lemmatizer_or_stemmer(word)\n",
    "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "                words.append(word)\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def wordnet_lemmatizer(token: str) -> str:\n",
    "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
    "\n",
    "\n",
    "_snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "\n",
    "\n",
    "def snowball_stemmer(token: str) -> str:\n",
    "    return _snowball_stemmer.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVocab:\n",
    "    pad = \"<PAD>\"\n",
    "    unknown = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, news_titles: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for title in news_titles:\n",
    "            words = nltk.word_tokenize(title)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
    "        unknown_idx = w2i[self.unknown]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, review: str) -> torch.Tensor:\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(review)]\n",
    "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \" \".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    titles: t.List[str]\n",
    "    classes: t.List[int]\n",
    "    vocab: NewsVocab\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path, preprocess: t.Callable[[str], str], vocab: NewsVocab = None):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.titles = self.df[\"Title\"].apply(preprocess).tolist()\n",
    "        self.vocab = vocab or NewsVocab(self.titles)\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(w.lower()) for w in self.titles])\n",
    "        self.targets = torch.tensor(self.df[\"Class Index\"].to_numpy(), dtype=torch.long) - 1\n",
    "        self.classes = self.targets.unique().tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, title: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(title)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 7600)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_news_title(title: str) -> str:\n",
    "    return complex_preprocess_news_title(title, lemmatizer_or_stemmer=snowball_stemmer, min_word_len=3)\n",
    "\n",
    "\n",
    "train_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/train.csv\",\n",
    "    preprocess_news_title,\n",
    ")\n",
    "test_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/test.csv\",\n",
    "    preprocess_news_title,\n",
    "    vocab=train_news_dataset.vocab,\n",
    ")\n",
    "# очень много данных\n",
    "len(train_news_dataset), len(test_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_dataloader = DataLoader(train_news_dataset, batch_size=128, shuffle=True)\n",
    "test_news_dataloader = DataLoader(test_news_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Создайте модель для классификации, используя слой nn.Embedding и слой nn.RNN.\n",
    "эмбеддинги инициализируйте случайным образом не забудьте указать аргумент padding_idx для nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.401149  [    0/120000]\n",
      "loss: 0.630077  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.748026, Avg loss: 0.665682 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.600516  [    0/120000]\n",
      "loss: 0.723923  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.808289, Avg loss: 0.524179 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.532383  [    0/120000]\n",
      "loss: 0.531087  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.834474, Avg loss: 0.469292 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.269752  [    0/120000]\n",
      "loss: 0.317807  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.842105, Avg loss: 0.444049 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.295347  [    0/120000]\n",
      "loss: 0.313171  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.849737, Avg loss: 0.438343 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.305548  [    0/120000]\n",
      "loss: 0.216066  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.851842, Avg loss: 0.429903 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.216184  [    0/120000]\n",
      "loss: 0.305774  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.857368, Avg loss: 0.433593 \n",
      "\n",
      "CPU times: user 1min 1s, sys: 13.4 s, total: 1min 15s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Переобучите модель, заменив слой nn.RNN на nn.LSTM и nn.GRU . Сравните качество\n",
    "на тестовой выборке. Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.385897  [    0/120000]\n",
      "loss: 0.565436  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.800000, Avg loss: 0.558378 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.486548  [    0/120000]\n",
      "loss: 0.524426  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.833684, Avg loss: 0.471666 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.490820  [    0/120000]\n",
      "loss: 0.464460  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.843421, Avg loss: 0.444492 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.281298  [    0/120000]\n",
      "loss: 0.377138  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.854342, Avg loss: 0.427924 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.325552  [    0/120000]\n",
      "loss: 0.453431  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.850789, Avg loss: 0.429338 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.178394  [    0/120000]\n",
      "loss: 0.364339  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.856711, Avg loss: 0.431530 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.263824  [    0/120000]\n",
      "loss: 0.330436  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.857237, Avg loss: 0.441051 \n",
      "\n",
      "CPU times: user 1min, sys: 10.8 s, total: 1min 11s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.390591  [    0/120000]\n",
      "loss: 0.660719  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.771974, Avg loss: 0.629217 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.683724  [    0/120000]\n",
      "loss: 0.511498  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.816316, Avg loss: 0.518918 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.575345  [    0/120000]\n",
      "loss: 0.371687  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.830263, Avg loss: 0.479486 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.351367  [    0/120000]\n",
      "loss: 0.595831  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.839342, Avg loss: 0.454323 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.361750  [    0/120000]\n",
      "loss: 0.421611  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.847763, Avg loss: 0.440059 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.333088  [    0/120000]\n",
      "loss: 0.366769  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.853026, Avg loss: 0.435525 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.283764  [    0/120000]\n",
      "loss: 0.332910  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.853684, Avg loss: 0.438774 \n",
      "\n",
      "CPU times: user 1min 10s, sys: 11.8 s, total: 1min 22s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Выполните пункты 2.3 и 2.4, используя предобученные эмбеддинги Glove.\n",
    "Прокомментируйте результат.\n",
    "Эмбеддинги из скачанного файла загрузите в виде двумерного тензора pretrained_embeddings.\n",
    "Обратите внимание, что номер строки в этом тензоре должен соответствовать\n",
    "токену (слову), имеющему такой индекс в вашем словаре.\n",
    "для слов, которых нет в файле с эмбеддингами, инициализуйте эмбеддинг\n",
    "случайным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21963/21963 [02:00<00:00, 182.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Embedding(21963, 50, padding_idx=0), 6143)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    # пробовал 100d и 200d: 100d не отличается от 50d, 200d немного снижает точность\n",
    "    DATA_DIR / \"glove.6B/glove.6B.50d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.empty(len(train_news_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, w in tqdm(enumerate(train_news_dataset.vocab.alphabet), total=len(train_news_dataset.vocab.alphabet)):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[w].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за стемминга очень много непопаданий в предобученные Embedding'и, но на точности моделей это не скажется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.382876  [    0/120000]\n",
      "loss: 0.644763  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.750000, Avg loss: 0.669954 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.621895  [    0/120000]\n",
      "loss: 0.776580  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.763947, Avg loss: 0.638002 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.637593  [    0/120000]\n",
      "loss: 0.591928  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.774737, Avg loss: 0.607652 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.626807  [    0/120000]\n",
      "loss: 0.505839  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.783289, Avg loss: 0.592206 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.568150  [    0/120000]\n",
      "loss: 0.576426  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.787368, Avg loss: 0.580810 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.559564  [    0/120000]\n",
      "loss: 0.593256  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.795132, Avg loss: 0.565733 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.507115  [    0/120000]\n",
      "loss: 0.554179  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.796447, Avg loss: 0.558928 \n",
      "\n",
      "CPU times: user 56.6 s, sys: 7.17 s, total: 1min 3s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_rnn_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.389729  [    0/120000]\n",
      "loss: 0.549070  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.788158, Avg loss: 0.579177 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.465080  [    0/120000]\n",
      "loss: 0.538472  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.812763, Avg loss: 0.524194 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.421716  [    0/120000]\n",
      "loss: 0.514988  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.825263, Avg loss: 0.492162 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.473409  [    0/120000]\n",
      "loss: 0.487043  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.833026, Avg loss: 0.474369 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.328568  [    0/120000]\n",
      "loss: 0.426346  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.832632, Avg loss: 0.466693 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.441821  [    0/120000]\n",
      "loss: 0.338025  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.833158, Avg loss: 0.469010 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.422293  [    0/120000]\n",
      "loss: 0.329360  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.837895, Avg loss: 0.468911 \n",
      "\n",
      "CPU times: user 57.9 s, sys: 7.85 s, total: 1min 5s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_lstm_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.394067  [    0/120000]\n",
      "loss: 0.803267  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.768816, Avg loss: 0.631746 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.707675  [    0/120000]\n",
      "loss: 0.572706  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.791184, Avg loss: 0.574005 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.551059  [    0/120000]\n",
      "loss: 0.538492  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.804211, Avg loss: 0.545979 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.546677  [    0/120000]\n",
      "loss: 0.538868  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.810921, Avg loss: 0.531987 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.484073  [    0/120000]\n",
      "loss: 0.583805  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.810132, Avg loss: 0.522295 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.368425  [    0/120000]\n",
      "loss: 0.443336  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.816316, Avg loss: 0.512507 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.548119  [    0/120000]\n",
      "loss: 0.391079  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.818026, Avg loss: 0.502742 \n",
      "\n",
      "CPU times: user 57.8 s, sys: 7.2 s, total: 1min 4s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=7,\n",
    "    model=news_gru_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=800,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_table(\n",
    "        models: t.List[t.Tuple[str, NewsClassifier]],\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> pd.DataFrame:\n",
    "    general_report = {}\n",
    "    for name, model in models:\n",
    "        report = {}\n",
    "        y_test, y_pred = get_y_test_y_pred(model, test_dataloader, device)\n",
    "        ms = metrics.classification_report(y_test, y_pred, zero_division=True, output_dict=True)\n",
    "        report[\"accuracy\"] = ms[\"accuracy\"]\n",
    "        report[\"precision (w avg)\"] = ms[\"weighted avg\"][\"precision\"]\n",
    "        report[\"recall (w avg)\"] = ms[\"weighted avg\"][\"recall\"]\n",
    "        report[\"f1-score (w avg)\"] = ms[\"weighted avg\"][\"f1-score\"]\n",
    "        general_report[name] = report\n",
    "    return pd.DataFrame(general_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "      <th>RNN (pretrained)</th>\n",
       "      <th>LSTM (pretrained)</th>\n",
       "      <th>GRU (pretrained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.857368</td>\n",
       "      <td>0.857237</td>\n",
       "      <td>0.853684</td>\n",
       "      <td>0.796447</td>\n",
       "      <td>0.837895</td>\n",
       "      <td>0.818026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision (w avg)</th>\n",
       "      <td>0.857438</td>\n",
       "      <td>0.857508</td>\n",
       "      <td>0.853727</td>\n",
       "      <td>0.796169</td>\n",
       "      <td>0.838341</td>\n",
       "      <td>0.819434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall (w avg)</th>\n",
       "      <td>0.857368</td>\n",
       "      <td>0.857237</td>\n",
       "      <td>0.853684</td>\n",
       "      <td>0.796447</td>\n",
       "      <td>0.837895</td>\n",
       "      <td>0.818026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score (w avg)</th>\n",
       "      <td>0.857109</td>\n",
       "      <td>0.857159</td>\n",
       "      <td>0.853461</td>\n",
       "      <td>0.796238</td>\n",
       "      <td>0.837556</td>\n",
       "      <td>0.818062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RNN      LSTM       GRU  RNN (pretrained)  \\\n",
       "accuracy           0.857368  0.857237  0.853684          0.796447   \n",
       "precision (w avg)  0.857438  0.857508  0.853727          0.796169   \n",
       "recall (w avg)     0.857368  0.857237  0.853684          0.796447   \n",
       "f1-score (w avg)   0.857109  0.857159  0.853461          0.796238   \n",
       "\n",
       "                   LSTM (pretrained)  GRU (pretrained)  \n",
       "accuracy                    0.837895          0.818026  \n",
       "precision (w avg)           0.838341          0.819434  \n",
       "recall (w avg)              0.837895          0.818026  \n",
       "f1-score (w avg)            0.837556          0.818062  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = make_pivot_table(\n",
    "    [\n",
    "        (\"RNN\", news_rnn_net),\n",
    "        (\"LSTM\", news_lstm_net),\n",
    "        (\"GRU\", news_gru_net),\n",
    "        (\"RNN (pretrained)\", news_rnn_pretrained_net),\n",
    "        (\"LSTM (pretrained)\", news_lstm_pretrained_net),\n",
    "        (\"GRU (pretrained)\", news_gru_pretrained_net),\n",
    "    ],\n",
    "    test_news_dataloader,\n",
    "    DEVICE,\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAEOCAYAAAB7KjXIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8rklEQVR4nO3deXgUVdo28PvJTkhEEgIIGMKSpLOxSAggDoIIogMI4gKoqKPggqKCiO+IuIyO8MrwOlFQmPlUxH1AHWBUGAEHxRkQdGRNICgGMCFhJ2Sjk+f741SFptMxQZolxf27Li7SVaeqTlc6/dTZRVVBREREzhBwtjNARERE/sPATkRE5CAM7ERERA7CwE5EROQgDOxEREQOwsBORETkIEFn68JNmjTRuLi4s3V5IqJ6ad26dXtVNeZs54POXWctsMfFxWHt2rVn6/JERPWSiPx0tvNA5zZWxRMRETkIAzsREZGDMLATERE5yFlrYyciIv9Yt25d06CgoL8CSAULbE5XCWCj2+2+q0uXLgW+EjCwExHVc0FBQX9t3rx5UkxMzIGAgACu7OVglZWVUlhYmJyfn/9XAIN9peGTHRFR/ZcaExNzmEHd+QICAjQmJuYQTO2M7zRnMD9ERHR6BDConz+s33WN8ZuBnYiITllgYGAXl8uVHB8fn3LFFVe037t3byAAZGdnh4hIl+eee66pnXbUqFGxmZmZ0QAwbNiwuKZNm3YoKSkRAMjLywtq2bJl2tl5F87gqDb2uMf+UeO+HWEjaz7wqUOnITf1H++n//Be+hfv5y+Le+wfXfx5vh1Tf7uutjShoaGVWVlZmwHguuuui3vhhRdipk2blg8AUVFR7tmzZzedMGFCYVhYWLWahcDAQM3MzGwyadKkQn/m+3zlqMD+a6XNrfnhcMNtG85gTpyB99N/eC/9i/fzzOjevfvR9evXN7BfR0VFubt27Vo0c+bM6AkTJuz1Tn/33XcXvPLKK83Gjx/PwO4HrIonIiK/cbvdWLFiReSQIUMOem6fPHly3ksvvdTc7XZXO6Z169blXbt2LZo1a1b0mcqnkzGwExHRKSsrKwtwuVzJMTExHQsLC4OHDBly2HN/cnJyeefOnYtmz54d5ev4KVOm5GVmZjavrKw8Mxl2MAZ2IiI6ZXYbe25u7gZVxdSpU5t6p5kyZUr+iy++eJFq9Q78aWlpZcnJycVz585tfEYy7GBsYz8FM+9ZXuO+sa9ecQZz4gy8n/7De+lfvJ91FxkZWZmZmZl7ww03tJ80adIJM6N17ty5ND4+vuTzzz9v1LVr16Pexz755JN51157bfyZy60zscRORER+1bNnzxKXy1UyZ86catXuTzzxRN6ePXtCfB2Xnp5empKSUnz6c+hsLLETETlMXYan+VtxcfF3nq+XL1+eY/+8bdu2TfbPPXr0KKmsrKzK34IFC3Z4Hrd06dLtpzGb5wWW2ImIiByEJfbT5E83Daxx34T3F5/BnDgD76f/8F76F+8nnWvqVGIXkQEiki0iOSLymI/9sSKyQkS+E5H1InKN/7NKREREtak1sItIIICZAK4GkAxghIgkeyWbDOADVe0MYDiAWf7OKBEREdWuLiX2DAA5qvqDqpYDeA/AtV5pFMAF1s+NAPzsvywSERFRXdWljb0lgJ0er3cB6OaV5ikAS0XkAQANAVzpl9wRERHRSfFXr/gRAN5Q1VYArgEwT0SqnVtExojIWhFZW1jIuf6JiJwiPDy8s/e277//PjQjIyPR5XIlt23bNmXEiBGtFyxYcIHL5Up2uVzJ4eHhnePi4lJdLlfy0KFD4xYvXhwpIl1mzJjRxD7H119/3UBEukyZMqXZmX1H9VddSuy7AVzs8bqVtc3TnQAGAICq/ltEwgA0AXDCrEOqOgfAHABIT0+vPqfgOWiLK6nmnb1nnrmMOATvp//wXvqXo+7nU438umwrnjr0q8bFjx07NnbcuHF7brnlloMAsGbNmgYZGRklw4YN2wwAGRkZidOnT9/Zq1evYgBYvHhxZHx8fMmCBQsajx8/fi8AzJs3LyoxMbHET+/kvFCXEvs3AOJFpI2IhMB0jlvolSYXQF8AEJEkAGEAWCQnIjqPFRQUBLdu3brcfp2RkVFrgG7ZsmV5WVlZwM6dO4MqKyuxfPnyRn379j10enPqLLUGdlV1A7gfwBIAW2B6v28SkWdEZLCVbAKA0SLyPYB3Adyuvmb5JyKi88bYsWP3XHPNNQm9evWKf/rpp5vu3bs3sC7HDRky5MC8efMaf/755w3T0tKKQ0NDGU9OQp3a2FX1E1VNUNV2qvqctW2Kqi60ft6sqj1VtaOqdlLVpacz00REdO578MEH923YsGHTddddt3/lypWRXbt2dZWUlEhtx40aNWr/Rx99FPXWW29Fjxw5cv+ZyKuTcEpZIiI6beLi4o499NBD+5YtW7Y9KCgIa9eubVDbMbGxse7g4GBduXLlBYMHDz5cW3o6EaeUJSKi02L+/PkXDBo06EhoaKjm5uYGHTx4MNCzzf2XPP3007vz8/ODg4IYpk4W7xgREZ2y0tLSgGbNmnWwX9977717du3aFfzII4/EhoaGVgLA008/vSs2NtZdl/P169ev2nrtVDcM7ERETvMrh6edCs+lWL3squmYNWvWZHu+Hjhw4JGBAwce8U43Y8YMzmZ6EtjGTkRE5CAM7ERERA7CwE5EROQgDOxEREQOwsBORETkIAzsREREDsLATkREp2znzp1BgwYNatOqVau0lJSUpE6dOrnefPPNCxcvXhwZGRnZyeVyJbdp0yZlzJgxrexjxo8f38J7OdaWLVum5eXlcSj2KeDNIyJymLS5aX5dtnXDbRt+cVx8ZWUlBg0a1H7kyJH7Fi1a9CMAbN26NeRvf/vbhVFRUSXp6elFK1asyCkqKpK0tLTkpUuXHujfvz8noDlNWGInIqJTsmjRosjg4GB99NFHq5brTkhIKH/88ccLPNNFRERoSkpKSW5ubsiZz+X5g4GdiIhOyYYNGxp06NChuLZ0hYWFgT/++GNo//79q80uR/7DwE5ERH516623xiYmJianpqYmAcDatWsjEhMTk2NjYzv06dPnsD1fvIj4XGe9pu1UNwzsRER0StLS0krWr18fbr+eN29e7hdffLH1wIEDQQCQnp5elJ2dvfm7777b9O677zb5+uuvGwBAdHS0205jO3r0aGCTJk0qzuw7cBYGdiIiOiWDBg06UlZWJtOmTYuxtxUVFVWLLy6Xq3zcuHF5zz//fHMA6Nu3b9GSJUsaHThwIAAA5s6de6HL5SrmUq2nhnePiIhOSUBAABYtWrR97NixF2dmZjaPiopyh4eHVzz11FPVVnabMGFCYdu2bZtnZ2eHdOvWrWT06NEF3bt3d4kIoqOjj7322ms7zsJbcBQGdiIih6lteNrp0Lp162OLFy/+wdc+z6VYIyIitKCgYL39euLEiXsnTpy490zk8XzBqngiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIjplgYGBXVwuV3J8fHzKFVdc0X7v3r2BAJCdnR0iIl2ee+65pnbaUaNGxWZmZkYDwLBhw+KaNm3aoaSkRAAgLy8vqGXLlmm+rlFUVCRdu3ZNdLvdfsnzY4891vzXHHfTTTe1XrduXZg/8mAvU1taWirp6emJx44dO+Vzchw7EZHDbHEl+XXZ1qSsLbWOiw8NDa3MysraDADXXXdd3AsvvBAzbdq0fACIiopyz549u+mECRMKw8LCqs0DHxgYqJmZmU0mTZpU6L3P00svvdRk8ODBB05mZjq3242a0mdmZl40derUfO/tlZWVUFUEBgb6PO7999//qc4ZqKOwsDC9/PLLD//1r3+Nuvfee/efyrlYYiciIr/q3r370d27d1ctzRoVFeW+7LLLjsycOTPaV/q777674JVXXmlWW2n1gw8+iL7xxhsPAsDixYsj09PTE3v37t0+Li4udeTIkbEVFWaK+fDw8M6jR49ulZiYmLxs2bKIWbNmRaWlpSW5XK7kkSNHtna73bjvvvtalpWVBbhcruTBgwe3yc7ODomLi0sdOnRoXEJCQsr27dtDbr755tjU1NSk9u3bpzz88MMt7HxkZGQkrly5Mty+1gMPPNAyMTExuWPHjq6dO3cGAcDPP/8cdNVVV7VLTU1NSk1NTVq6dGlDAMjPzw/s2bNnfPv27VNuuumm1qrHn3Ouv/76g++9917Ur7vrxzGwExGR37jdbqxYsSJyyJAhBz23T548Oe+ll15q7qsavXXr1uVdu3YtmjVrls/ADwClpaWyc+fO0MTExHJ724YNGxrOmjUrNycnZ+OOHTtC33zzzcYAUFJSEtCtW7ej2dnZm2NiYtzz58+PWrt2bVZWVtbmgIAAffXVV6NnzZq1265lWLhw4Y8AkJubG3r//fcX5uTkbEpISCifMWPG7o0bN27JysratGrVqsjVq1c38M5XSUlJQI8ePYqys7M39+jRo+ill16KAYC777774vHjx+/ZuHHjlo8++mj7PffcEwcAjz32WIsePXoU5eTkbBo6dOjBvLy8qgegrl27lqxfv77hSd7yalgVT0REp8wu/e7Zsye4Xbt2pUOGDDnsuT85Obm8c+fORbNnz/ZZIp0yZUrekCFD2l9//fWHfO3Pz88PioyMPOGpIC0t7WhycnI5ANx44437v/zyy4g77rjjQGBgIG6//fYDAPDZZ59Fbty4Mbxjx45JAFBaWhrQtGlTn430F110UXnfvn2P2q/nzp0b9cYbbzRxu91SWFgY/P3334d169atxPOY4OBgHT58+CEA6NKly9HPP//8AgBYtWrVBdu2bat6ECgqKgo8dOhQwH/+85/IDz/8MAcAhg8ffujuu++uWskuKCgIwcHBeuDAgYDGjRtX+spjXTCwExHRKbNLv0eOHAno3bt3/NSpU5tOnjy5wDPNlClT8m+88cZ23bt3P+J9fFpaWllycnLx3LlzG/s6f8OGDSvLy8tPqGUWEfh6HRISUmm3q6uq3HDDDftmzpy5u7b3EB4eXhVMs7KyQl5++eVm69at2xITE1MxbNiwuNLS0mq13EFBQRoQEGD/DLfbLdZ18e23324JDw8/qbXljx07Jid7jDdWxRMRkd9ERkZWZmZm5s6aNatam3nnzp1L4+PjSz7//PNGvo598skn82bOnOmzp3pMTExFRUWFFBcXV0XzDRs2NMzKygqpqKjA/Pnzo37zm99Ue2AYMGDA4cWLFzfevXt3EADs2bMncOvWrSGACcplZWXifQwAHDhwILBBgwaVUVFRFTt37gz64osvfOa5Jpdddtnh559/vmokgL0Gfffu3Y+88cYb0QDwwQcfXHD48OGqHnr5+fmBF154oTs0NJSBnYiIzh09e/YscblcJXPmzKlW7f7EE0/k7dmzJ8TXcenp6aUpKSnFNZ23V69eh5YuXRphv05NTT16zz33xLZr1y41Nja27NZbbz3ofUyXLl1KJ0+evLtv374JCQkJyVdccUXCzp07gwHg5ptvLkxKSkoePHhwG+/jevToUZKamlrcrl271BtvvLFtly5diur49gEAc+bM2fntt982TEhISG7Xrl3Kyy+/HAMAU6dO/XnVqlUR7du3T/nwww8bX3TRRVV9Bj799NMLrrzySp9NESeDVfFERA5Tl+Fp/lZcXPyd5+vly5fn2D9v27Ztk/1zjx49SiorK6vyt2DBgh2exy1dunR7TdcYN25c4fTp05sNGTLkCABERkZWrFixIsc7nXdeRo8efWD06NEHvNO98soruwFUVdF75tNX3mxr1qzJ9nWtO+6448Add9xxAAAuuugi9z/+8Y9qy9g2b968YtWqVdt8nffdd9+Nmj59erU17E8WAzsREdULl112WfHatWsP+2uCmnNJaWmpDB48+GCHDh3KTvVcDOxERFRvPPTQQ/sAYODAgUcGDhxYrU29vgoLC9P7779/nz/OxTZ2IiIiB2FgJyIichAGdiIiIgdhYCciInKQOgV2ERkgItkikiMij9WQ5kYR2Swim0TkHf9mk4iIzmXh4eGdvbd9//33oRkZGYkulyu5bdu2KSNGjGi9YMGCC1wuV7LL5UoODw/vHBcXl+pyuZKHDh0at3jx4kgR6TJjxowm9jm+/vrrBiLSZcqUKc18XfeZZ55p+vLLL9c4x/zJWLx4ceQ///nPk56rfeXKleG33377xf7IQ2ZmZvSoUaNiAeCPf/xjzIsvvnjS763WXvEiEghgJoB+AHYB+EZEFqrqZo808QD+B0BPVT0gIk19n42IiE63mfcs9+uyrWNfveJXjYsfO3Zs7Lhx4/bccsstBwFgzZo1DTIyMkqGDRu2GTCrpE2fPn1nr169igETWOPj40sWLFjQePz48XsBYN68eVGJiYklvs5/7NgxvPXWW002bdq02df+mo4JDg72uW/58uWRERERFf369Tvqve+XjuvVq1ex/R786YEHHtiXkZHhskcC1FVdSuwZAHJU9QdVLQfwHoBrvdKMBjBTVQ8AgKoWgIiIzmsFBQXBrVu3rppZLSMjw2eA9tSyZcvysrKygJ07dwZVVlZi+fLljfr27etzNrZFixZdkJaWVmwH3IyMjMQ77rjjYpfLlRwfH5+yYsWKcAAYP358iyFDhrS55JJLXNddd10bX0uqZmdnh7z55psxr776ajOXy5X82WefRQwbNixu5MiRsR06dHDde++9rVasWBHeqVMnV1JSUnLnzp1d33//fShgHkj69OnT3r7WDTfcEJeRkZHYqlWrtGeffbaqoOtr+VgA+POf/xwdFxeXmpaWlvT1119XzawXGRlZ2apVqzL7fdRVXcaxtwSw0+P1LgDdvNIkAICIrAIQCOApVf3M+0QiMgbAGACIjY09mXwSEVE9M3bs2D3XXHNNQufOnY/27dv30NixY/c1adKkorbjhgwZcmDevHmN09PTi9PS0oprmjv9yy+/jLjkkktOKCmXlJQEZGVlbf70008jxowZ08aeTW7btm1hq1evzoqIiNBBgwa1GT9+/J6rrrqqaNu2bSFXXXVV/A8//LBp1KhRhRERERXPPPPMHgD4y1/+0iQvLy/k22+/zQoKCsL+/fsDvvnmm6zg4GB8/PHHkY8++mirJUuWVJspLycnJ+zrr7/OPnjwYGBSUlLqxIkTCzdt2hRqLx8bGhqqt9xyS+yrr74aPWjQoMNTp05tsW7dui1RUVEVl156aWJqamrVe7rkkkuOfvHFF5F9+vSpc42AvyaoCQIQD6A3gFYAVopImqoe9EykqnMAzAGA9PT0U5rknoiIzm0PPvjgvmuvvfbwxx9/fMGiRYsufOONN2I2b968uUGDBr/4/T9q1Kj9w4YNa5eVldVg5MiR+7/66qsIX+ny8/ODk5KSTqgFGDly5H4AuPrqq4uKiooC9u7dGwgAAwYMOBgREaFAzUuq+rrGddddd8BeKW7//v2BN910U5sdO3aEiYgeO3bM5wIy/fv3P9igQQNt0KCBOyoq6tiuXbuCalo+duXKlQ27d+9+pEWLFm7revu3bt0aZp+radOm7qysrDBf16lJXaridwPw7BTQCh5z61p2AVioqsdU9UcAW2ECPRERncfi4uKOPfTQQ/uWLVu2PSgoCGvXrm1Q2zGxsbHu4OBgXbly5QWDBw8+XFO6sLCwSu+lVGtayrVhw4ZVS7LaS6pmZWVtzsrK2lxQULC+UaNGPtc/j4iIqNo+adKklpdffvmRbdu2bVq0aFGO9zKyNs8ahsDAQLjdbrGXj7WvuWPHjo0zZsz4+ZfvhHkAaNCgwUmtzV6XwP4NgHgRaSMiIQCGA1joleZjmNI6RKQJTNV8tcnviYjo/DF//vwL7GVRc3Nzgw4ePBjo2eb+S55++undf/jDH3bZpWVfkpKSSnNyckI9t7377ruNAWDJkiURkZGRFdHR0dWq/mtaUjUyMrLiyJEjgd7pbYcPHw5s1apVOQDMnj27SU3pfKlp+dhevXodXb16dWR+fn5gWVmZfPTRRyesR79169bQ1NTUWvsmeKq1Kl5V3SJyP4AlMO3nr6nqJhF5BsBaVV1o7esvIpsBVACYqKp+mfOWiIjOfaWlpQHNmjXrYL++99579+zatSv4kUceiQ0NDa0EgKeffnpXbGxsnVZw8dUz3duQIUMOjRw58oQlV8PCwjQpKSnZ7XbLnDlzfvR13Jw5c3beddddsQkJCckVFRXSrVu3I5deemnusGHDDl5//fXtPv300wtffPHFXO/jJk2alH/XXXe1mTZtWot+/fodrMv7sHkuH1tZWYng4GDNzMzM7du379FJkyb93L1796TIyMgKz/Z1APjmm28ipk2bVmvJ3lOd2thV9RMAn3htm+LxswIYb/0jIqKz6NcOTzsVnkuxeqlxGVLP5U+Bmhd2qanKOiEhobxx48buDRs2hKalpZUBwO23377vtdde2/lLx9e0pGqHDh3Ktm7dWjV0bsCAASeswX7llVce3bFjx0b7dWZm5s/e+fa+ludSsDUtH/vggw/ue/DBB6sVhletWtUgISGhtHnz5rV2OPTEmeeIiKjemj59+q5du3b5HmBezxUUFARPmzbNu09brbhsKxER1VsdO3Ys69ixYxlQvQagvhs6dGiNHQd/CUvsREREDsLATkRE5CAM7ERERA7CwE5EROQgDOxERHTKdu7cGTRo0KA2rVq1SktJSUnq1KmT680337wQMIukREZGdnK5XMlt2rRJGTNmTCv7uPHjx7fwXpK1ZcuWaXl5edU6d1dWVqJ79+4J+/fv90vseuaZZ5oeOXLkpM/10EMPtfj4448j/ZGHjIyMxJUrV4YDwKWXXppQWFhY4wQ5dcVe8UREDvOnmwb6ddnWCe8v/sVx8ZWVlRg0aFD7kSNH7lu0aNGPALB169aQv/3tbxfaadLT04tWrFiRU1RUJGlpaclLly490L9//1onofH0wQcfNEpJSSmJioqq8xSrbrcbNc1eN3v27GajR4/eHxkZWe18v3Tciy++eFITxtTViBEj9k2fPj1m2rRp+adyHpbYiYjolCxatCgyODhYH3300UJ7W0JCQvnjjz9ebQnviIgITUlJKcnNzQ052eu8/fbbUUOHDj0IANnZ2SFt2rRJGTx4cJu2bdumDBgwoK1d+m7ZsmXavffe2zI5OTnptddea/zhhx9e0KlTJ1dycnLS1Vdf3fbQoUMBzz77bNOCgoLgyy+/PKFbt24JABAeHt559OjRrRITE5OXLVsW8cgjj1yUmpqaFB8fnzJixIjWlZUm/g8bNizu9ddfb2xf6+GHH26RnJyclJCQkPzdd9+FAcDhw4cDbrjhhri0tLSkpKSk5LfeeutCACgqKpKBAwe2bdu2bUq/fv3alZaWVk1uP3z48IMffvhh9MneF28M7EREdEo2bNjQoEOHDnVaVrSwsDDwxx9/DO3fv3+1GeZqs27duoiePXtWlfJ37NgRdv/99xf88MMPmyIjIytfeOGFGHtfdHS0e/PmzVsGDRp05I9//ONFK1eu3Lp58+Ytl1xySfEf/vCHZpMnTy5o2rTpsX/9619bV69evRUwS75269btaHZ29uarrrqqaOLEiQUbN27csm3btk0lJSUB7733XiNf+WrSpIl78+bNW373u98VTp06tRkA/P73v7+oT58+hzds2LDlyy+/zJ48eXKrw4cPB0yfPr1pgwYNKn/44YdNzz777M+bN29uaJ8nJiamory8XPLz80+pOp5V8URE5Fe33npr7Jo1ayKCg4N148aNWwBg7dq1EYmJicm5ubmhd955Z4E9Z7yI+FzC1df2Q4cOBTVu3Liq2rx58+bldnX+rbfeui8zM7MpgD0AMGrUqAMA8MUXXzTcvn17WEZGhgsAjh07Jl26dCnyPjdgVmK7/fbbq6Z8/fTTTyNnzJjRvLS0NODgwYNBycnJJQAOeR83cuTIAwCQkZFRvHDhwsbWdS9YsmTJhZmZmc0BoKysTHJyckK++uqriHHjxhUAQLdu3UoSEhJOeCCKjo525+bmhjRv3vykFn7xxMBORESnJC0treTvf/971apk8+bNy83LywtKT09PsrfZbexZWVkhPXv2TBo5cuT+Sy+9tCQ6Otqdl5d3QrX80aNHA5s0aVJtfvTAwECtqKhAYKAp0Na0RCsA2O3mqorLLrvssN32/0tCQkIq7Xb14uJimTBhQuvVq1dvbt++/bHx48e38F4i1hYWFqYAEBQUpG63W+zrzp8/P8eeFa+uysrKJDw8/KSWafXGqngiIjolgwYNOlJWVibTpk2rqgovKiryGV9cLlf5uHHj8p5//vnmANC3b9+iJUuWNDpw4EAAAMydO/dCl8tV7KvjWps2bUq3bNlStUxrXl5eyOeff94QMO3vl156abWSeO/evY+uXbs2YuPGjaGAaftev359KAA0bNiw4tChQz7zWVxcHAAAzZs3dx86dChg0aJFjX2lq0mfPn0O/+lPf2pmt8uvWrWqAQBcdtllRW+//XYUAHzzzTdhW7duDbePqaysRGFhYXBiYuJJPQx4Y4mdiIhOSUBAABYtWrR97NixF2dmZjaPiopyh4eHVzz11FM+V3abMGFCYdu2bZtnZ2eHdOvWrWT06NEF3bt3d4kIoqOjj7322ms7fB3Xv3//Q0uXLo1MTU0tA4C4uLjSl156qemYMWPC4+PjSx955JFC72NatGjhnj179o7hw4e3LS8vFwB48sknd3fo0KHstttu2ztgwICEZs2aldvt7LYmTZpU3HzzzYVJSUkpMTEx7o4dO55UD/6pU6f+PGbMmFiXy5VcWVkpF198cdmKFStyHnnkkYLhw4e3adu2bUr79u1Lk5OTq8771VdfhXfu3PlocPCprWnDwE5E5DC1DU87HVq3bn1s8eLF1ZZCBaovxxoREaEFBQXr7dcTJ07cO3HixL21XeP+++/fO2LEiLjx48fvBYCgoCD8/e9/r1bFvnv37g2erwcPHnxk8ODBW7zTPf744wWePfeLi4u/89yfmZn5s700q6cFCxbs8HWtXr16FdsL0UREROg777zzk/exERERWtN9ev3116Pvu+++aiMJThar4omIqF5o3br1sd/97nd7/TVBzbkmNTW15Nprrz3p0QLeWGInIqJ646677joAAFFRUeXbtm3bdLbz408TJkyotdaiLhz51ENERHS+YmAnIqr/KisrK6X2ZOQE1u+6xiFxDOxERPXfxsLCwkYM7s5XWVkphYWFjQBsrCkN29iJiOo5t9t9V35+/l/z8/NTwQKb01UC2Oh2u++qKQEDOxFRPdelS5cCAIPPdj7o3MAnOyIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB6lTYBeRASKSLSI5IvLYL6QbJiIqIun+yyIRERHVVa2BXUQCAcwEcDWAZAAjRCTZR7pIAA8CWO3vTBIREVHd1KXEngEgR1V/UNVyAO8BuNZHuj8AmAag1I/5IyIiopNQl8DeEsBOj9e7rG1VROQSABer6j9+6UQiMkZE1orI2sLCwpPOLBEREf2yU+48JyIBAGYAmFBbWlWdo6rpqpoeExNzqpcmIiIiL3UJ7LsBXOzxupW1zRYJIBXAFyKyA0B3AAvZgY6IiOjMq0tg/wZAvIi0EZEQAMMBLLR3quohVW2iqnGqGgfgPwAGq+ra05JjIiIiqlGtgV1V3QDuB7AEwBYAH6jqJhF5RkQGn+4MEhERUd0F1SWRqn4C4BOvbVNqSNv71LNFREREvwZnniMiInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJykDoFdhEZICLZIpIjIo/52D9eRDaLyHoRWSYirf2fVSIiIqpNrYFdRAIBzARwNYBkACNEJNkr2XcA0lW1A4D5AP7X3xklIiKi2tWlxJ4BIEdVf1DVcgDvAbjWM4GqrlDVYuvlfwC08m82iYiIqC7qEthbAtjp8XqXta0mdwL49FQyRURERL9OkD9PJiK3AEgHcHkN+8cAGAMAsbGx/rw0ERERoW4l9t0ALvZ43cradgIRuRLA4wAGq2qZrxOp6hxVTVfV9JiYmF+TXyIiIvoFdQns3wCIF5E2IhICYDiAhZ4JRKQzgNkwQb3A/9kkIiKiuqg1sKuqG8D9AJYA2ALgA1XdJCLPiMhgK9kLACIA/E1E/isiC2s4HREREZ1GdWpjV9VPAHzitW2Kx89X+jlfRERE9Ctw5jkiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgdhYCciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIicpA6BXYRGSAi2SKSIyKP+dgfKiLvW/tXi0ic33NKREREtao1sItIIICZAK4GkAxghIgkeyW7E8ABVW0P4P8ATPN3RomIiKh2dSmxZwDIUdUfVLUcwHsArvVKcy2AudbP8wH0FRHxXzaJiIioLkRVfzmByPUABqjqXdbrWwF0U9X7PdJstNLssl5vt9Ls9TrXGABjrJeJALL99UZOoyYA9taaiuqK99N/eC/9q77cz9aqGnO2M0HnrqAzeTFVnQNgzpm85qkSkbWqmn628+EUvJ/+w3vpX7yf5BR1qYrfDeBij9etrG0+04hIEIBGAPb5I4NERERUd3UJ7N8AiBeRNiISAmA4gIVeaRYCuM36+XoAy7W2On4iIiLyu1qr4lXVLSL3A1gCIBDAa6q6SUSeAbBWVRcC+H8A5olIDoD9MMHfKepV00E9wPvpP7yX/sX7SY5Qa+c5IiIiqj848xwREZGDMLDTeU9EokTkgrOdj/qCc1ScPva9tToh817Tr8LATuclEQmw/m8AYDyAe85ujs59IhIiIr9nx9jTQ0REVVVEbgQwAwB4r+nXYGCn84YYAQCgqpXW/yUA3geQKiK/OZv5O9fY98uaVhrWzJMJInKXiDQ5y9lzBBEJ9PhM2kH8XwAOisi4s5czqs8Y2E8zj6q1xiLyVxG59Gzn6XylRqWIBIlIWxF52Nq+AcDfAdzJKvnj7PulqhV28AHwNIB2AG4Gjtd8UN153jNVrbAfMkUkUUQiVXUPzEij60XEdbbySfUX/yj9zFrprqOIuERkMoBR1q5kAG4A285e7s5fVukzSETeArABpvr9KRHpYCX5AkAkgCvOUhbPOSKSLCJ3iMj/AXgTAFT1RwDLAIy2krGquBZ2jYfNDuTWvl4i8qGIvArgW1hDhVX1JwC5AEZY6djWTnXGwO4nItJERGYB2AJgLIBKmCA+yvqjPAygu6oW8o/Uf6yqzGr303ObiHwBoC+AXgBKVTUJwKswky9dCQCqug/mi7XPGcj2WWM94Pj8/IlIsIj0FpFIEUmCaaJIAFAGYJjVHwGq+jmAC0SkJduAT2Td3qrqdcCUyr3SXC8i46wOckMBbATwOIClAK7xSPohrM8nAH5nUJ0xsP8KIhIvIveLyIMiEmZt7g4gRlXbquoYVd0K4G8AlsN0hAkG8L2IhPPL0H+sqkwVkQgRaQgAIvIGgIesn8NgHrYOwSw8FGUdugWmurOvlS7Q2tbwTOb/TLGDuVW9rvY2EblMREKtZKEA3gAQBuBGAG+o6v+o6mMA8gF4NiP9COshiA+qx1m3t8KrVH61iEz0uM+xALoAuBDmM/my9WA5GUAnj9P9E6bZ44RSPlFtGNjrQETCReQ6ERkmIr1hvvyaw1RDzrKS9YLp9FJVirT+GKfCzKM/B8AaVS0+w9l3LCuY3ysi/4apSn/ACuTvAugiIl1g1i1oDLOewToA7YGqUlQFgFgRCbZeNwKwSczUyfWWr3Zvj2DeQ0QmiEgTa9tzAG4XkQhVLQKwA8AxAC0BHPQ4xXIAAz1eLwXQ9fS8g3NfTX0LROQiEXlMRD4VkZdFJBrmnqYCuNNKtgfmQakIJsiXi0iQqm4C0FhEOlnpigB8KyKpp/GtkAMxsHvwqr5tZ/0/FcDLMFVmRwBsAtAbwCKYP9bfikhLmC/DShFp4FGKDLECxkswVWmJ1jlPaHOj42qoVg+0/o/xfA1TsiwAMATAbwGkAbhPVZfAlHaesDoidQNwWFXXAIgUkatEpDGAJOs8doBKAnBMVcvrWynUqtYF4Lt0JyIXi8hCAJNgHnSesqrbbwHwGwD9RKQ9TK3FUQDfA7jco5RZCKta2LrWTgA/WNc7L2qg7M+EiATUcI8DAKTD1M79HqYvwtuqugXA8wDuE5EIK81/VbUUprnud9bU3RcBKAbQ0zplBwD/xYkPWES1YmC3iEgyrHYsERkAINOq2i2G+cJ/UFWXqmohzB/tH2FKMV8CuAHAewAuBzDSKuGPAJBhnf4rmGr5n4DqbW7nOxG5VETGAicGCRFpJCKXW72yrwYwz9plD1XbC1Ny/B+YtQzaAegqItGqOhdAcxG5F6YtvbV17H0wwWwNTIl9A6xSPEyJfq93Ps4lVvW5vZJi1cOHqro90vQTkY7Wz/bf+GEAt8L0Zt8OE6SHqepOmJqmITAPnvGqegzAYgDlAF4UkWkAmgK40CpZugH0g6klcRwx4/V7WjU+9rYA62G9gTWy4kIRWeZ5nBXsl8K0jd8G8z3RSUQ6q2oWzMPSEJiOtBHWYX+CqTXaAlP7txam4AAADQA0UtVdp+u9kjOdd4Hd46m7lYjcLWYyCAD4DCZAA0AegJ8BuAD8B+bLv7F13CUwf5i3qOp7MF+Y/a0hU7MADACwGqbt9oB1vmiYL8Klp/fd1S8egSkCpo8CRKSdiNgdhh4D8LGIhMOUzr+2akE8g+5wmNEGnWEmmQnF8ZL4H2ACeTscf6j6FMDdqhoP83sqB7DYqgX4GmbY27nsNgCDPQKN/XmeJCK/t9IMAfA762e7bf0QzOd2Ocy9mgtgmJXmfZiq4RtgBRyrV/aDMCXzbJgS5084fm//CVOD5UQXwIya2AaYh34rmF8M4KiI9FHVgzAPOm29jg0GcC/MstU9Yf7m7SaMP8Hcv8thPrNQ1a8ATAEwQFWHAvgHTCkdAL6DaVYiOinnTWC32mMvtL4MbwYwH+YPr8RK8i6A/tbPBTCBvTtMUG8I06YOa3sDmJL5U9bx8SISqqr/AjBaVdNU9S6rzQwwT+55qL6O/XlBPCY58eQRoKNhvsQAU7J+TEQuhCmZbwHQAyYY7bW2eVbHdwHQ1DpXBkzp255oZilMJ7oHrfZjuwR7jYh8D2ACgH+q6n6r+WSnmglrzioRaSgiGdY9sLfZ7zcNQKAVaO4GMM3a3gHAdSKSDhN07RK8fb+CAIwEMFNVxwH4N4BoEWmqqocBvABTUlwtxzuElsLUkihMB9Dl1gMsALynqj/4+a2fMdZnsqbvv30ALoJZzRIAPhCRHgBCYGrfBojIFTBB2K49sdP2ANAKwPNqJvRpDuAqAFDVbwG8A2ABzO/IFgrzmV8H86D6hpW+zAr8RCfF8YFdTKe3r2CqXq8UM2SnF4BpqjpKVRdZST+G1UMapk3rIIAkVc2DCd5tRCRQVfNhSpLpMKWb/1XVeFUts/YftK4baLd7qupDqnqLqu4/A2/5nKPWJCfe2z1K7F1glf5UdTlMe24/ALtgSoshML+z1lZbZCCOj5+eCVNy2g5gMIBnAHxqneuYqi7z/HK0qkuXAeikqgNU9W2/v+FfQcwERndYHaU6AHgAJojbU43a9+9HmPsBmIehXiISBfPQ8zqAuwC0ALDd+jyqdbwbZpx+nIiMhAk2gbB6ulvNGimq+qDV9ms3GfWE6aPwMszkNLD2lZ+ue3E6ePeZsD6TNfU0T4WpqbObbz6EeejpAvNA9C1MbcYRmBo7wHqAArAe5vP7oYj8E6apLluOzy63SVVv9qpePwTTlNdXVfuo6nlZACD/qXU99vrE6gw0FEATmKfen2AmiJkE4D9WW21LmCrJ/7E7BllPxv+22s1aqOrPVpu7yyo17YCpig8FUKyqm2FNHOFxbc8v3/OuHV28pmr12N4QwGUwVchlAP6kqhut3QEw7dyFAC7xOOwdAINg7vsGmGCWAGC/dQ3P+7xBRO4BEGxVH/vMm2e+VPWAr3RnkhVoAkx2tBIm6HaGqcp9D+aetPI6JgimdmM3zIFrROS/MJPqpMGUqjvAtKVP97hPAvMg9ATMHAtjAEwH8H+qWmB9dlVVj1q/R7VrU6zmpvdOz104/ezfvVffjSCY2rneMLUQn1nbA617Fgrz8GR3HHwHZvhfKoA2MGPOn4D5XbwCHK99UtU9IjIJplljnaqu9ZUnK63dV6Qc1ogaIn9wTIldTC/26TC907+AKcnFAWinqqusoB5oPQ2HwpTYyqyStl0CmgVgtoh8CxNw5sO07U5T1ZfUa6iaeEyO4tXu63hiZtibZXfksktAIhImIi2sNC6YEQHjYap0CwH8wUe1/DIAl1i1KQDwOUwwvxNArpqOR7sAHPKoJq6iqj/bQd2qYq1WOvPT2/YbK5B6jnfOhxlxEW9VjR+A6VQV5FXqFpghUY2t496HaX5oAdPBbQFMcP8NUBWs7ACyU1UfU9XeqrpYVQvsvHjkq7K+fpa9m3w8H+hEJEHM3BP2sLMRMJ+xLiIyxT7E+v9HAOGwmt+sz99XME1zkTDfDR9br+1SfRU1TTuz7aDu/ZmspbaA6JQ5JrCr6naY9qm1MF9qXWD+eP8lIm2sNHYJZi6A0SJyj4g8BuCPVjCaDPNwcJeq3qOqf1bVfDW9hH1ds6K+fgmeLPtL0+NBpgzAM2p6VUNEYkVkLkxw+rOIjLa+EMsBHFTTaS0TppYozTpHhfX/WpjSeB8rkJUAeA1AjEcWboT5vZT+Uj7PtcDk/ZDhsT1NTIe310WkrVVqy4Vp946CaYKIwfFSux2wvocJ4vbEJStg2oQTYGqVvgbwIoAsa7+vJhCffR7qG+92cvVo8hGRhtaDZkcR+QymlB0C0zFumPX6GEzNUFfreLtD2z6YjnMdxBpiqaaJKBzm8xsKMy9FPwA5NeRNPP5WzqnPJDmfYwK7ZRiAiQBWwkwZWgrTieh3ACAiqSJymarOtPb3ANAMwHyr1Fepqv9S08nF/uN02j2qE6vkfaeI9AGOf2lapUd7Za80MXOvA6atNkBV28G0c08SkViYvg35YiaB2QXTX6GdfV897u88mCr7S6zr7QHQQlXnWyWvHed684b1efGeF9yeGCZWTH+PSKuZZwJM08QXAB4WM9piM0ywSYFpgggDYPe6tgPDv2E6d17rcZn3YT7PW1S1SFUfV9VXa8qn1tDnob7xLvmKSLSIzBYzYdFfrPucBTPD225VnQHzYJQG01k2HibAD/Y4h/0g9jHMg9UAj0uOBnC7qpaqaq6qrrAecH3lrao5g+hMc0zQsr5QuwBYpqZD3HaYQL8OZjzzBpgpRHsCgBXAb1PVh1X1P17n8px+87ypMrNK5HZgqgSwAsAqa19Lq3S5DqaTFmBKip2sn3vAGtespuf0Wpgq4Z0wASrBSpcNU0Kyp2612ybfgaluv93Oj6oWWVXQ5+zvwDOQ29XrXvujRORNmHHhA2CmtP0Rpq17Hcx48gEwHad+ggnal8BM/lICq6rXo3YjH+b+9xOROGvbYVW9z6498c5XfebrYclje18ReU5EJlibB8HcsxthPoszYErX6wHssB4iQ2A+08+r6iRVXQZTS9LG8/xqJpVZAuBaEYm0t6lHx7aaamOIzjbHBHaYALEZwBUi8hzMF+Z2mMlJxgO4RlW7qeo0z4PEa8EG4PxpL/fRFl2hx/silMO0OT5r7f4tgK0Afquqg6xtWwAUiRnLewRAiP0laL3uDBO8gOOT9fwbplTqq2/CGzBDi6qq4M/134VnIBeRTiLyolVqvMzafA2ABqraQc0aAj9ZTQ0DATwKEzyewfFJSbbD9Aspg5lSNFmsOfCtawRYwf1tAN3l+Gx83tXS9b5EDpz4sGQ1X9h9LO6G6RRbBNP8AAB3AFirpi/BHJg+HVfBdEzrDCBUTcfJ5TC1JBNE5B2YyaNi7et5XP4TmCahzvbfiuffzLn+2aTzl2N6xVululdEpBlM55bfW0/dtiPACT1f7eMc8QX4a3h/MYnIGJhST5yIXAXTpphuBY84mNLjbVZVZ76qbrVqQq6CGRL0KIC9YqYurYRpby+DGZZld9T6BOYL01d+ilGPZjMTkdYwvasbw1SH3weT/0MAxouIG2bOA7tjX4geHyY2DmZ8/VoReRRAazH9PHbAjJNuDtMRTmFmPwRwQkfAWTBVzCVe2+sNMdOrXglgr9YwXltEgmHWW7gCpiBym4hsg3nQnGaVuG3/hqm1s5uHtsBMCPMmTNCPgenHMBumM9xdMGPRP7eafk5g/X18YtUaqcc2onOaYwK7TVWf8nzt+Udp7T+vArn3g4zH9tYwpZhlqnpERLrCdDp8CWaxmoMicgym6vwKmDHMN8NUoT8EoImYiX4+ATBGVV8RkdetfY/DjN/9h1XyfNXr2vV+JIGYaYffgQmwX8DcywiYfh03wTRRtLC2HRKRRmpmf7Ntg1l85Q6Y6uJsmAenrwF8Z6XNr+n61u90n3/f1eknIr8B0BGmaeJlmM/WayKySX0PQ+wOU7szwA6+ItIBJkAfsF6HWp+zxQBeF5FHYDobxgN4U1V3iEgFTMc5+96th3m4qlV9/pzS+clxgR2oal+sPB87sFjvvapvgEc1ZgRMO3cuTO//bjDBJNlqA+4Lc888p709BNO80VtV34eploSY3u9/hSnRr4fpwxCqqktEZJ2ayU688xXgkScn/E42w7z/uaq6TUQehplr/SqYYZJjrQcmF8xUokdEZAmA62EeBO6CKeE3BfC6mlEdtqrJX7wfTOszEbkG5sHvPZiahgdgxob3gHmoOWA99AnM7HrHYGrfEgHMFJGlMNXrq600GQC+VTNkNVxVvxKR9wAshKla/w5WU5CqXuUjPwLgnO7DQfRrODKwn2+lck8+Om/9FqY9NwomGGUBKFHVHiJyHcx0twrTC7uDdUyw9aV6zNrez3pgGAHTIbEtzJfrT2qGn3W2jgu0g7rnw5WVL0d9eapqroishgk622CG6/0LwCxVzQEAMYuI/BdmMpPbYXr+fwIgT83QqkzPc4pUXzXMKUHd0gmmSSYbZhrgDWImieoH85n6r/V+FWalxCCYwDwJZqx+U5ihfBMBfATgcTHj+RNh4vRkVX1CRNIA7FBVu/lNVKvmAvCsvbOvReQojgzs5yurer03zOx7n6vqyzDBeQSAUaq6UEQGwqxbfiVMVe9smPbxxjCdhNqp6narl/BhmBJ+GEwbezbM+N2v7C9Nj2ufjzPvrYRpY19s/WsK4GUR+RnmYScLwJ2q+q2IfF9Dk4hn7ZKjHn48iZkEqjfM1MA/w3zuADNC4BA8JnoRkW4wwbwTgKGq+j2Ajda+NJjOiB+IyEGYh9bVAD5UM+ubqDWfvXeTj8MekohqJPysO4PV2e09AH+G6b0+BKa0M9163d8K2INgSo93e5SuL1DVwyLyNEzJqB1MoB9nVa97tw87op38VIlIP5gpcjt4bOsLU/r8p6ru8EpvTyN7Xk5YYpWu1wDoqKrFHiXp+2Cqzl9W1V1ixp9HwFSzu61A/xhMyXwjzMRIG2u6DtH5joHdIcRMBrMN5kszS0QyADwJMxvf32Dacd8XkUYwQ6XWAVgEU7qPBDBVzRz5KTDtm+truI5j2nxPlYhEA/g/APeptXqcjzS8Xx7EzAK3QFX/YnfsFLN2/DCYvgk/eN9LMes1tAGw3kdTk8BMjHQ+1BAR1YmTxrGf11Q1F2bMvj3RRi5Me2Y8zFrzV1rpDsGM6y+Baa8MBvC2qv5s7d9kB3XxMeseg9RxqrpPzQqB3oEogDUaNVqK42P2bdfADEf7D0zHN+/x4gdV9TvrIcB7vL4yqBOdiCV2BxGRF2CWNr1RRFrBVMs/ABPs31Qz3audtsaSJEuZJ8dXpzfyTcwKjP+E+ZxWWDVNf4GpPfqHqv54VjNI5ADsPOcsKwDMF5EnYUpBG62S+M8i0sszod1LGCcuHVq170xmur5jUK87Vd0iIl/BLK28x6ppqjYUjYh+PZbYHUTM4iwLYaZm/UrNuvEsUdI57XzvVEjkb2xjdxCrl/shAKWqutlui2RQp3ONr3ZyBnUi/2Bgd54PcHzFNAZ0Oifxs0l0+rAqnoiIyEFYYiciInIQBnYiIiIHYWAnIiJyEAZ2IiIiB2FgJyIichAGdiIiIgf5/+/RH0BvAGI/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = report.plot.bar(rot=15)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ни странно, предобученные Embedding'и только ухудшили точности модели.\n",
    "\n",
    "LSTM выглядит небольшим фаворитом. Но, учитывая непонятное поведение (не готовность реагировать на изменение параметров) всего, я отказываюсь от сравнения моделей и выводов."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPopRjm9A6la5QJRG/PWjfN",
   "collapsed_sections": [],
   "name": "blank__07_rnn_1_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
