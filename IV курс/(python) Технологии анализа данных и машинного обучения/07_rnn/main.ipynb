{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5669,
     "status": "ok",
     "timestamp": 1619632510103,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "zKMq7dp2W15Y",
    "outputId": "ce2273c5-6a96-4216-9d88-fbee51bf5ff0"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_cuda(device: str) -> bool:\n",
    "    return device == \"cuda\"\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_dataloader: DataLoader,\n",
    "        epochs: int,\n",
    "        test_dataloader: DataLoader = None,\n",
    "        lr_scheduler=None,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.List[float]:\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "        train_loss = train_loop(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "        )\n",
    "        train_losses.append(train_loss.item())\n",
    "        if test_dataloader:\n",
    "            loss, acc = test_loop(test_dataloader, model, loss_fn, device=device)\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step(loss)\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> torch.Tensor:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss\n",
    "        if batch % verbose == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, correct = 0, 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        avg_loss += loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # noqa\n",
    "\n",
    "        del x, y, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:>4f}, Avg loss: {avg_loss:>8f} \\n\")\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_test_split(dataset: t.Union[Dataset, t.Sized], train_part: float) -> t.Tuple[Subset, Subset]:\n",
    "    train_size = round(train_part * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_test_y_pred(\n",
    "        model: nn.Module,\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.hstack(y_test).detach().cpu(), torch.hstack(y_pred).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm-QilGISxkt"
   },
   "source": [
    "## 1. Классификация фамилий (RNN)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/frNchuaBQVLxyA?w=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdPr92i6k-If"
   },
   "source": [
    "1.1 Используя класс `nn.RNNCell` (абстракцию для отдельного временного шага RNN), реализуйте простейшую рекуррентную сеть Элмана в виде класса `RNN`. Используя созданный класс `RNN`, решите задачу классификации фамилий. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ir6UUkl6l4tp"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, hx: torch.Tensor = None):\n",
    "        batch_size, sequence_size, _ = inputs.size()\n",
    "        inputs = inputs.permute(1, 0, 2)  # для nn.RNNCell batch_size должен быть на 2-ой месте\n",
    "\n",
    "        if hx is None:\n",
    "            # так же скрытое состояние инициализируется в nn.RNN\n",
    "            hx = torch.zeros(batch_size, self.hidden_size, dtype=inputs.dtype, device=inputs.device)\n",
    "        else:\n",
    "            # 1-ая размерность равная 1 для совместимости с nn.RNN\n",
    "            hx = hx.squeeze(0)  # избавляемся от 1-ой размерности равной 1\n",
    "\n",
    "        hidden = []\n",
    "        for i in range(sequence_size):\n",
    "            hx = self.rnn_cell(inputs[i], hx)\n",
    "            hidden.append(hx)\n",
    "\n",
    "        hidden = torch.stack(hidden)\n",
    "        hx = hidden[-1].unsqueeze(0)\n",
    "        return hidden.permute(1, 0, 2), hx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка реализации RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "input_size, hidden_size = 4, 5\n",
    "inputs = torch.randn(2, 3, input_size)\n",
    "hx = torch.randn(1, 2, hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "my_rnn = RNN(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "true_rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<UnsqueezeBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.rnn = RNN(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x, hx = self.rnn(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesVocab:\n",
    "    pad = \"<PAD>\"\n",
    "\n",
    "    def __init__(self, surnames: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for w in map(str.lower, surnames):\n",
    "            uniques.update(w)\n",
    "            max_len = max(len(w), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, *uniques]\n",
    "        self.max_len = max_len\n",
    "        self.ch2i = {ch: i for i, ch in enumerate(self.alphabet)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        indices = [self.ch2i[ch] for ch in word]\n",
    "        indices += [self.ch2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.ch2i[self.pad], as_tuple=True)[0]\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \"\".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class SurnamesDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    surnames: t.List[str]\n",
    "    vocab: SurnamesVocab\n",
    "    labeler: LabelEncoder\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.surnames = self.df[\"surname\"].tolist()\n",
    "        self.vocab = SurnamesVocab(self.surnames)\n",
    "        size = self.vocab.encode(self.surnames[0].lower()).size()\n",
    "        data = torch.vstack([self.vocab.encode(w.lower()) for w in self.surnames])\n",
    "        self.data = data.view(len(self.surnames), *size)\n",
    "\n",
    "        self.labeler = LabelEncoder()\n",
    "        targets = self.labeler.fit_transform(self.df[\"nationality\"])\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(word)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames_dataset = SurnamesDataset(DATA_DIR / \"surnames.csv\")\n",
    "len(surnames_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8784 2196\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_surnames_dataset, test_surnames_dataset = train_test_split(surnames_dataset, train_part=0.8)\n",
    "print(len(train_surnames_dataset), len(test_surnames_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "handmade_rnn_net = SurnamesRNNClassifier(\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(handmade_rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.887971  [    0/ 8784]\n",
      "loss: 1.460474  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.624317, Avg loss: 1.268815 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.189004  [    0/ 8784]\n",
      "loss: 1.210896  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.702186, Avg loss: 1.038538 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.907800  [    0/ 8784]\n",
      "loss: 0.862654  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729964, Avg loss: 0.954668 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.843660  [    0/ 8784]\n",
      "loss: 0.842537  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.897260 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.711590  [    0/ 8784]\n",
      "loss: 0.976198  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.872289 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.699940  [    0/ 8784]\n",
      "loss: 0.559541  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.746357, Avg loss: 0.865911 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.530410  [    0/ 8784]\n",
      "loss: 0.686770  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747268, Avg loss: 0.857673 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.676878  [    0/ 8784]\n",
      "loss: 0.703729  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.752732, Avg loss: 0.868074 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.587215  [    0/ 8784]\n",
      "loss: 0.484920  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.757741, Avg loss: 0.838710 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.394199  [    0/ 8784]\n",
      "loss: 0.543729  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.752732, Avg loss: 0.843751 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.600710  [    0/ 8784]\n",
      "loss: 0.515518  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.760929, Avg loss: 0.868567 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.430907  [    0/ 8784]\n",
      "loss: 0.596493  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.758197, Avg loss: 0.872534 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.347768  [    0/ 8784]\n",
      "loss: 0.522870  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.765483, Avg loss: 0.859392 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.349622  [    0/ 8784]\n",
      "loss: 0.454128  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.758197, Avg loss: 0.880675 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.410500  [    0/ 8784]\n",
      "loss: 0.564952  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.763206, Avg loss: 0.877613 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.350918  [    0/ 8784]\n",
      "loss: 0.392632  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.763206, Avg loss: 0.890955 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.489407  [    0/ 8784]\n",
      "loss: 0.399498  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.761840, Avg loss: 0.896422 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.310426  [    0/ 8784]\n",
      "loss: 0.409594  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.763661, Avg loss: 0.916582 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.257698  [    0/ 8784]\n",
      "loss: 0.311904  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.764117, Avg loss: 0.905775 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.236101  [    0/ 8784]\n",
      "loss: 0.217790  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.757741, Avg loss: 0.947473 \n",
      "\n",
      "CPU times: user 17.1 s, sys: 595 ms, total: 17.7 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=handmade_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.68      0.74      0.71        38\n",
      "       Czech       0.61      0.34      0.44        96\n",
      "       Dutch       0.73      0.43      0.54        51\n",
      "     English       0.69      0.87      0.77       573\n",
      "      French       0.14      0.05      0.08        39\n",
      "      German       0.53      0.52      0.52       121\n",
      "       Greek       0.79      0.56      0.66        34\n",
      "       Irish       0.86      0.32      0.47        37\n",
      "     Italian       0.70      0.68      0.69       128\n",
      "    Japanese       0.88      0.85      0.86       156\n",
      "      Korean       0.20      0.20      0.20        10\n",
      "      Polish       0.56      0.38      0.45        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.85      0.86      0.86       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.44      0.40      0.42        50\n",
      "  Vietnamese       0.50      0.15      0.24        13\n",
      "\n",
      "    accuracy                           0.76      2196\n",
      "   macro avg       0.56      0.46      0.49      2196\n",
      "weighted avg       0.74      0.76      0.74      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(handmade_rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2MIErKTo9aO"
   },
   "source": [
    "1.2 Замените модуль `RNN` из 1.1 на модули `nn.RNN`, `nn.LSTM` и `nn.GRU` (не забудьте указать аргумент `batch_first=True`). Сравните результаты работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesAutobotRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.cx = cx.detach()\n",
    "            self.hx = hx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.RNN,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.874605  [    0/ 8784]\n",
      "loss: 1.633806  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.579690, Avg loss: 1.431513 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.352032  [    0/ 8784]\n",
      "loss: 1.319001  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.653916, Avg loss: 1.206944 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.082676  [    0/ 8784]\n",
      "loss: 1.019523  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.676685, Avg loss: 1.106101 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.002640  [    0/ 8784]\n",
      "loss: 0.959590  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.703097, Avg loss: 1.016859 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.918670  [    0/ 8784]\n",
      "loss: 1.060783  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.712204, Avg loss: 0.989125 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.896251  [    0/ 8784]\n",
      "loss: 0.856330  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.722222, Avg loss: 0.961450 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.572283  [    0/ 8784]\n",
      "loss: 0.813868  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724954, Avg loss: 0.954690 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.812896  [    0/ 8784]\n",
      "loss: 0.924895  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.723133, Avg loss: 0.956091 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.801140  [    0/ 8784]\n",
      "loss: 0.548746  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.730874, Avg loss: 0.931775 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.608254  [    0/ 8784]\n",
      "loss: 0.648958  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.721767, Avg loss: 0.940834 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.694125  [    0/ 8784]\n",
      "loss: 0.748649  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.945228 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.502941  [    0/ 8784]\n",
      "loss: 0.649656  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.933438 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.469188  [    0/ 8784]\n",
      "loss: 0.647543  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.950914 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.522489  [    0/ 8784]\n",
      "loss: 0.501931  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732696, Avg loss: 0.941898 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.483842  [    0/ 8784]\n",
      "loss: 0.574295  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.946023 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.506085  [    0/ 8784]\n",
      "loss: 0.525778  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742259, Avg loss: 0.957742 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.643111  [    0/ 8784]\n",
      "loss: 0.592711  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741803, Avg loss: 0.954696 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.374892  [    0/ 8784]\n",
      "loss: 0.516851  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 0.951833 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.335706  [    0/ 8784]\n",
      "loss: 0.513879  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744991, Avg loss: 0.988823 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.459731  [    0/ 8784]\n",
      "loss: 0.335652  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.750911, Avg loss: 0.988070 \n",
      "\n",
      "CPU times: user 14 s, sys: 970 ms, total: 15 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.97      1.00      0.98       340\n",
      "     Chinese       0.74      0.84      0.79        38\n",
      "       Czech       0.49      0.26      0.34        96\n",
      "       Dutch       0.76      0.37      0.50        51\n",
      "     English       0.68      0.87      0.76       573\n",
      "      French       0.07      0.03      0.04        39\n",
      "      German       0.58      0.46      0.52       121\n",
      "       Greek       0.70      0.41      0.52        34\n",
      "       Irish       0.67      0.27      0.38        37\n",
      "     Italian       0.63      0.76      0.69       128\n",
      "    Japanese       0.86      0.82      0.84       156\n",
      "      Korean       0.29      0.20      0.24        10\n",
      "      Polish       0.60      0.46      0.52        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.84      0.87      0.86       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.44      0.34      0.38        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.55      0.45      0.47      2196\n",
      "weighted avg       0.73      0.75      0.73      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.LSTM,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.880923  [    0/ 8784]\n",
      "loss: 1.884630  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.547814, Avg loss: 1.564271 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.436014  [    0/ 8784]\n",
      "loss: 1.586476  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.620674, Avg loss: 1.314317 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.358808  [    0/ 8784]\n",
      "loss: 1.247718  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.664390, Avg loss: 1.162704 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.049469  [    0/ 8784]\n",
      "loss: 1.096033  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.678051, Avg loss: 1.092257 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.062434  [    0/ 8784]\n",
      "loss: 0.901455  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.691712, Avg loss: 1.025694 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.024183  [    0/ 8784]\n",
      "loss: 0.912489  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.709016, Avg loss: 0.982719 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.820191  [    0/ 8784]\n",
      "loss: 0.722359  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724499, Avg loss: 0.948643 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.671626  [    0/ 8784]\n",
      "loss: 0.684971  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729964, Avg loss: 0.943292 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.503377  [    0/ 8784]\n",
      "loss: 0.835569  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728597, Avg loss: 0.930491 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.601515  [    0/ 8784]\n",
      "loss: 0.705402  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.727231, Avg loss: 0.926734 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.673676  [    0/ 8784]\n",
      "loss: 0.717960  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.916584 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.755859  [    0/ 8784]\n",
      "loss: 0.679594  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.737705, Avg loss: 0.923599 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.609650  [    0/ 8784]\n",
      "loss: 0.696580  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 0.921945 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.428546  [    0/ 8784]\n",
      "loss: 0.791993  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.946417 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.491627  [    0/ 8784]\n",
      "loss: 0.620301  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742259, Avg loss: 0.922855 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.668554  [    0/ 8784]\n",
      "loss: 0.571164  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744080, Avg loss: 0.918339 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.495359  [    0/ 8784]\n",
      "loss: 0.550954  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745902, Avg loss: 0.921619 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.405947  [    0/ 8784]\n",
      "loss: 0.474199  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.944482 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.450086  [    0/ 8784]\n",
      "loss: 0.414020  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.949907 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.440906  [    0/ 8784]\n",
      "loss: 0.531209  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.959866 \n",
      "\n",
      "CPU times: user 15.3 s, sys: 713 ms, total: 16 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.98      1.00      0.99       340\n",
      "     Chinese       0.73      0.71      0.72        38\n",
      "       Czech       0.57      0.24      0.34        96\n",
      "       Dutch       0.68      0.33      0.45        51\n",
      "     English       0.67      0.88      0.76       573\n",
      "      French       0.10      0.03      0.04        39\n",
      "      German       0.53      0.42      0.47       121\n",
      "       Greek       0.68      0.50      0.58        34\n",
      "       Irish       0.67      0.22      0.33        37\n",
      "     Italian       0.64      0.72      0.68       128\n",
      "    Japanese       0.85      0.85      0.85       156\n",
      "      Korean       0.18      0.20      0.19        10\n",
      "      Polish       0.45      0.38      0.42        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.84      0.86      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.44      0.40      0.42        50\n",
      "  Vietnamese       0.25      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.51      0.43      0.45      2196\n",
      "weighted avg       0.72      0.75      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.GRU,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.884707  [    0/ 8784]\n",
      "loss: 1.712844  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.561931, Avg loss: 1.529570 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.658825  [    0/ 8784]\n",
      "loss: 1.210827  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.627505, Avg loss: 1.270196 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.240748  [    0/ 8784]\n",
      "loss: 1.252751  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.666211, Avg loss: 1.150547 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.150284  [    0/ 8784]\n",
      "loss: 0.970849  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.683971, Avg loss: 1.071097 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.060233  [    0/ 8784]\n",
      "loss: 0.920568  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.696266, Avg loss: 1.013802 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.853729  [    0/ 8784]\n",
      "loss: 0.756440  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.721767, Avg loss: 0.962099 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.766743  [    0/ 8784]\n",
      "loss: 0.763532  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.720856, Avg loss: 0.936980 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.591888  [    0/ 8784]\n",
      "loss: 0.832352  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734517, Avg loss: 0.930019 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.568406  [    0/ 8784]\n",
      "loss: 0.681186  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731330, Avg loss: 0.903739 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.699919  [    0/ 8784]\n",
      "loss: 0.573102  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.913835 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.611698  [    0/ 8784]\n",
      "loss: 0.587865  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.905206 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.525096  [    0/ 8784]\n",
      "loss: 0.750961  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.911986 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.508931  [    0/ 8784]\n",
      "loss: 0.548839  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743169, Avg loss: 0.924677 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.480412  [    0/ 8784]\n",
      "loss: 0.470199  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 0.909476 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.680229  [    0/ 8784]\n",
      "loss: 0.410300  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742259, Avg loss: 0.909834 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.445556  [    0/ 8784]\n",
      "loss: 0.444212  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.918124 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.484598  [    0/ 8784]\n",
      "loss: 0.577711  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740437, Avg loss: 0.947533 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.438853  [    0/ 8784]\n",
      "loss: 0.488828  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.969246 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.505858  [    0/ 8784]\n",
      "loss: 0.489760  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.968024 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.471634  [    0/ 8784]\n",
      "loss: 0.377935  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743169, Avg loss: 0.999265 \n",
      "\n",
      "CPU times: user 14 s, sys: 748 ms, total: 14.7 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.95      1.00      0.97       340\n",
      "     Chinese       0.77      0.61      0.68        38\n",
      "       Czech       0.53      0.25      0.34        96\n",
      "       Dutch       0.75      0.29      0.42        51\n",
      "     English       0.67      0.87      0.75       573\n",
      "      French       0.13      0.08      0.10        39\n",
      "      German       0.64      0.34      0.44       121\n",
      "       Greek       0.65      0.44      0.53        34\n",
      "       Irish       0.58      0.19      0.29        37\n",
      "     Italian       0.63      0.75      0.68       128\n",
      "    Japanese       0.86      0.87      0.86       156\n",
      "      Korean       0.21      0.30      0.25        10\n",
      "      Polish       0.50      0.35      0.41        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.83      0.88      0.86       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.46      0.32      0.38        50\n",
      "  Vietnamese       0.33      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.53      0.42      0.45      2196\n",
      "weighted avg       0.72      0.74      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6YBam_3t-fO"
   },
   "source": [
    "1.3 Загрузите предобученные эмбеддинги (https://disk.yandex.ru/d/BHuT2tEXr_yBOQ?w=1) в модуль `nn.Embedding` и обучите модели из 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesDecepticonRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(56, 50, padding_idx=0), 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.50d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.ones(len(surnames_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, ch in enumerate(surnames_dataset.vocab.alphabet):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[ch].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.844056  [    0/ 8784]\n",
      "loss: 1.961480  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.469035, Avg loss: 1.821727 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.777585  [    0/ 8784]\n",
      "loss: 1.709133  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.547359, Avg loss: 1.581834 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.588760  [    0/ 8784]\n",
      "loss: 1.549079  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.586066, Avg loss: 1.437853 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.450417  [    0/ 8784]\n",
      "loss: 1.257675  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.623406, Avg loss: 1.310767 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.038258  [    0/ 8784]\n",
      "loss: 1.278656  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.653005, Avg loss: 1.219411 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.158547  [    0/ 8784]\n",
      "loss: 1.452169  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.666211, Avg loss: 1.178816 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.991674  [    0/ 8784]\n",
      "loss: 1.162129  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.680783, Avg loss: 1.134419 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.069854  [    0/ 8784]\n",
      "loss: 1.038241  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.696266, Avg loss: 1.094816 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.782191  [    0/ 8784]\n",
      "loss: 0.970086  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.697632, Avg loss: 1.041973 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.874401  [    0/ 8784]\n",
      "loss: 0.814367  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.696266, Avg loss: 1.037598 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.852884  [    0/ 8784]\n",
      "loss: 0.951101  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704007, Avg loss: 1.020246 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.838062  [    0/ 8784]\n",
      "loss: 0.885446  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714936, Avg loss: 0.992707 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.810464  [    0/ 8784]\n",
      "loss: 0.874319  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.721311, Avg loss: 0.988271 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.898576  [    0/ 8784]\n",
      "loss: 0.766908  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.721311, Avg loss: 0.995846 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.846136  [    0/ 8784]\n",
      "loss: 0.827253  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.725865, Avg loss: 0.994483 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.703739  [    0/ 8784]\n",
      "loss: 0.789881  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732696, Avg loss: 0.960898 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.697940  [    0/ 8784]\n",
      "loss: 0.515171  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735428, Avg loss: 0.953442 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.802416  [    0/ 8784]\n",
      "loss: 0.607302  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.951946 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.734617  [    0/ 8784]\n",
      "loss: 0.712938  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.967523 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.675169  [    0/ 8784]\n",
      "loss: 0.605173  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733607, Avg loss: 0.978835 \n",
      "\n",
      "CPU times: user 13.3 s, sys: 461 ms, total: 13.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.93      1.00      0.96       340\n",
      "     Chinese       0.66      0.87      0.75        38\n",
      "       Czech       0.67      0.21      0.32        96\n",
      "       Dutch       0.67      0.24      0.35        51\n",
      "     English       0.63      0.91      0.74       573\n",
      "      French       0.12      0.05      0.07        39\n",
      "      German       0.65      0.26      0.38       121\n",
      "       Greek       0.62      0.47      0.53        34\n",
      "       Irish       0.75      0.24      0.37        37\n",
      "     Italian       0.62      0.72      0.67       128\n",
      "    Japanese       0.79      0.85      0.82       156\n",
      "      Korean       0.17      0.10      0.12        10\n",
      "      Polish       0.62      0.38      0.48        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.87      0.82      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.50      0.22      0.31        50\n",
      "  Vietnamese       1.00      0.15      0.27        13\n",
      "\n",
      "    accuracy                           0.73      2196\n",
      "   macro avg       0.57      0.42      0.44      2196\n",
      "weighted avg       0.72      0.73      0.70      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.900342  [    0/ 8784]\n",
      "loss: 2.214212  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.426230, Avg loss: 1.955202 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.063104  [    0/ 8784]\n",
      "loss: 1.851924  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.525046, Avg loss: 1.633425 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.751783  [    0/ 8784]\n",
      "loss: 1.601672  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.573770, Avg loss: 1.469063 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.500901  [    0/ 8784]\n",
      "loss: 1.434251  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.619308, Avg loss: 1.329760 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.145660  [    0/ 8784]\n",
      "loss: 1.335644  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.651639, Avg loss: 1.240957 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.202477  [    0/ 8784]\n",
      "loss: 1.068419  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.664390, Avg loss: 1.145671 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.915265  [    0/ 8784]\n",
      "loss: 1.057720  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.681694, Avg loss: 1.101404 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.074586  [    0/ 8784]\n",
      "loss: 1.104022  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.691712, Avg loss: 1.036159 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.848900  [    0/ 8784]\n",
      "loss: 0.786144  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704007, Avg loss: 1.018657 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.682439  [    0/ 8784]\n",
      "loss: 1.055549  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704918, Avg loss: 0.994242 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.690191  [    0/ 8784]\n",
      "loss: 0.762269  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.713570, Avg loss: 0.977482 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.724985  [    0/ 8784]\n",
      "loss: 0.924445  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714026, Avg loss: 0.962368 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.794807  [    0/ 8784]\n",
      "loss: 0.588149  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.727231, Avg loss: 0.937032 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.707345  [    0/ 8784]\n",
      "loss: 0.789382  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729964, Avg loss: 0.912925 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.690092  [    0/ 8784]\n",
      "loss: 0.596250  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734062, Avg loss: 0.924788 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.497774  [    0/ 8784]\n",
      "loss: 0.643013  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.911830 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.676020  [    0/ 8784]\n",
      "loss: 0.562028  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734517, Avg loss: 0.910355 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.566877  [    0/ 8784]\n",
      "loss: 0.564874  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.746357, Avg loss: 0.926538 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.582295  [    0/ 8784]\n",
      "loss: 0.556686  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.924578 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.457589  [    0/ 8784]\n",
      "loss: 0.442531  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743625, Avg loss: 0.928419 \n",
      "\n",
      "CPU times: user 14.1 s, sys: 1.18 s, total: 15.3 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.67      0.82      0.74        38\n",
      "       Czech       0.43      0.22      0.29        96\n",
      "       Dutch       0.78      0.35      0.49        51\n",
      "     English       0.65      0.90      0.76       573\n",
      "      French       0.17      0.05      0.08        39\n",
      "      German       0.55      0.40      0.46       121\n",
      "       Greek       0.64      0.41      0.50        34\n",
      "       Irish       0.75      0.24      0.37        37\n",
      "     Italian       0.70      0.67      0.69       128\n",
      "    Japanese       0.86      0.83      0.84       156\n",
      "      Korean       0.38      0.30      0.33        10\n",
      "      Polish       0.53      0.35      0.42        26\n",
      "  Portuguese       1.00      0.00      0.00         9\n",
      "     Russian       0.84      0.84      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.57      0.34      0.42        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.61      0.43      0.46      2196\n",
      "weighted avg       0.73      0.74      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.875406  [    0/ 8784]\n",
      "loss: 1.869805  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.448543, Avg loss: 1.893556 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.731786  [    0/ 8784]\n",
      "loss: 1.537178  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.535974, Avg loss: 1.590274 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.372517  [    0/ 8784]\n",
      "loss: 1.425336  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.592896, Avg loss: 1.427738 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.198495  [    0/ 8784]\n",
      "loss: 1.435925  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.628415, Avg loss: 1.295024 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.276708  [    0/ 8784]\n",
      "loss: 1.447090  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.647996, Avg loss: 1.209272 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.390478  [    0/ 8784]\n",
      "loss: 1.374148  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.670310, Avg loss: 1.142552 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.004989  [    0/ 8784]\n",
      "loss: 0.993891  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.683515, Avg loss: 1.084446 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.860507  [    0/ 8784]\n",
      "loss: 0.978571  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704918, Avg loss: 1.050045 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 1.053811  [    0/ 8784]\n",
      "loss: 1.104792  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704918, Avg loss: 1.018170 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.823182  [    0/ 8784]\n",
      "loss: 1.018349  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.708561, Avg loss: 1.021340 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 1.031335  [    0/ 8784]\n",
      "loss: 0.857455  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.719490, Avg loss: 0.986318 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.661543  [    0/ 8784]\n",
      "loss: 0.787023  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714481, Avg loss: 0.989629 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.776277  [    0/ 8784]\n",
      "loss: 0.621907  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.715847, Avg loss: 1.000995 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.945315  [    0/ 8784]\n",
      "loss: 0.784821  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732696, Avg loss: 0.960323 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.722879  [    0/ 8784]\n",
      "loss: 0.732096  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731330, Avg loss: 0.961841 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.737204  [    0/ 8784]\n",
      "loss: 0.659876  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.962856 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.805515  [    0/ 8784]\n",
      "loss: 0.615498  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.949026 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.753027  [    0/ 8784]\n",
      "loss: 0.763119  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.947762 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.704089  [    0/ 8784]\n",
      "loss: 0.762939  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740437, Avg loss: 0.942890 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.467413  [    0/ 8784]\n",
      "loss: 0.642812  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.966080 \n",
      "\n",
      "CPU times: user 14 s, sys: 1.15 s, total: 15.2 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.94      1.00      0.97       340\n",
      "     Chinese       0.72      0.74      0.73        38\n",
      "       Czech       0.53      0.18      0.27        96\n",
      "       Dutch       0.62      0.39      0.48        51\n",
      "     English       0.65      0.91      0.76       573\n",
      "      French       0.14      0.03      0.04        39\n",
      "      German       0.65      0.32      0.43       121\n",
      "       Greek       0.55      0.47      0.51        34\n",
      "       Irish       0.83      0.27      0.41        37\n",
      "     Italian       0.62      0.77      0.69       128\n",
      "    Japanese       0.78      0.87      0.82       156\n",
      "      Korean       0.25      0.30      0.27        10\n",
      "      Polish       0.45      0.35      0.39        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.89      0.81      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.39      0.24      0.30        50\n",
      "  Vietnamese       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.56      0.43      0.45      2196\n",
      "weighted avg       0.72      0.74      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7kf990U9Do-"
   },
   "source": [
    "## 2. Классификация новостей на основе заголовка\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/FN-EgWGIpyjLxQ?w=1\n",
    "\n",
    "Эмбеддинги: https://nlp.stanford.edu/projects/glove/ (находите ссылку на архив\n",
    "glove.6B.zip, в нем несколько файлов с эмбеддингами слов, выбираете один из файлов в\n",
    "архиве)\n",
    "\n",
    "2.1 Загрузите набор данных train.csv. Выполните предобработку столбца Title\n",
    "\n",
    "2.2 На основе этих данных создайте датасет NewsDataset . Не забудьте добавить\n",
    "специальные токены `<PAD>` для дополнения последовательностей до нужной длины и\n",
    "`<UNK>` для корректной обработке ранее не встречавшихся токенов. В данной задаче\n",
    "рассматривайте отдельные слова как токены. Разбейте датасет на обучающее и\n",
    "валидационное множество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def simple_preprocess_news_title(title: str) -> str:\n",
    "    return title.lower()\n",
    "\n",
    "\n",
    "def complex_preprocess_news_title(\n",
    "        title: str,\n",
    "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
    "        min_word_len: int = 0,\n",
    ") -> str:\n",
    "    title = simple_preprocess_news_title(title)\n",
    "    title = PATTERN.sub(\" \", title)\n",
    "\n",
    "    words = []\n",
    "    for word in nltk.word_tokenize(title):\n",
    "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "            if not lemmatizer_or_stemmer:\n",
    "                words.append(word)\n",
    "                continue\n",
    "            word = lemmatizer_or_stemmer(word)\n",
    "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "                words.append(word)\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def wordnet_lemmatizer(token: str) -> str:\n",
    "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
    "\n",
    "\n",
    "_snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "\n",
    "\n",
    "def snowball_stemmer(token: str) -> str:\n",
    "    return _snowball_stemmer.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVocab:\n",
    "    pad = \"<PAD>\"\n",
    "    unknown = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, news_titles: t.List[str], max_len: int = 0):\n",
    "        uniques = set()\n",
    "        for title in news_titles:\n",
    "            words = nltk.word_tokenize(title)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
    "        unknown_idx = w2i[self.unknown]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, review: str) -> torch.Tensor:\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(review)]\n",
    "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \" \".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    titles: t.List[str]\n",
    "    classes: t.List[int]\n",
    "    vocab: NewsVocab\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path, preprocess: t.Callable[[str], str], title_max_len: int = 0):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.titles = self.df[\"Title\"].apply(preprocess).tolist()\n",
    "        self.vocab = NewsVocab(self.titles, max_len=title_max_len)\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(w.lower()) for w in self.titles])\n",
    "        self.targets = torch.tensor(self.df[\"Class Index\"].to_numpy(), dtype=torch.long) - 1\n",
    "        self.classes = self.targets.unique().tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, title: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(title)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 7600)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_news_title(title: str) -> str:\n",
    "    return complex_preprocess_news_title(title, lemmatizer_or_stemmer=snowball_stemmer, min_word_len=3)\n",
    "\n",
    "\n",
    "train_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/train.csv\",\n",
    "    preprocess_news_title,\n",
    ")\n",
    "test_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/test.csv\",\n",
    "    preprocess_news_title,\n",
    "    title_max_len=train_news_dataset.vocab.max_len,\n",
    ")\n",
    "len(train_news_dataset), len(test_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_dataloader = DataLoader(train_news_dataset, batch_size=256, shuffle=True)\n",
    "test_news_dataloader = DataLoader(test_news_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Создайте модель для классификации, используя слой nn.Embedding и слой nn.RNN.\n",
    "эмбеддинги инициализируйте случайным образом не забудьте указать аргумент padding_idx для nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.398488  [    0/120000]\n",
      "loss: 0.775554  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.245658, Avg loss: 1.825695 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.829722  [    0/120000]\n",
      "loss: 0.577932  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.243289, Avg loss: 2.134828 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.540253  [    0/120000]\n",
      "loss: 0.577653  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.242368, Avg loss: 2.230031 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.459172  [    0/120000]\n",
      "loss: 0.345430  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.242632, Avg loss: 2.448734 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.330366  [    0/120000]\n",
      "loss: 0.426021  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.241974, Avg loss: 2.801781 \n",
      "\n",
      "CPU times: user 38.8 s, sys: 6.67 s, total: 45.5 s\n",
      "Wall time: 46.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=400,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Переобучите модель, заменив слой nn.RNN на nn.LSTM и nn.GRU . Сравните качество\n",
    "на тестовой выборке. Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.386017  [    0/120000]\n",
      "loss: 0.583580  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.248553, Avg loss: 1.786926 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.569937  [    0/120000]\n",
      "loss: 0.514011  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.245000, Avg loss: 1.993639 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.450888  [    0/120000]\n",
      "loss: 0.527745  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.247763, Avg loss: 2.198192 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.308758  [    0/120000]\n",
      "loss: 0.371936  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.242105, Avg loss: 2.420766 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.325474  [    0/120000]\n",
      "loss: 0.498787  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.238553, Avg loss: 2.607911 \n",
      "\n",
      "CPU times: user 39.2 s, sys: 6.05 s, total: 45.2 s\n",
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=400,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.382523  [    0/120000]\n",
      "loss: 0.691126  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.246447, Avg loss: 1.848297 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.695150  [    0/120000]\n",
      "loss: 0.461607  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.250132, Avg loss: 2.005425 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.548943  [    0/120000]\n",
      "loss: 0.419353  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.249474, Avg loss: 2.167577 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.424499  [    0/120000]\n",
      "loss: 0.439187  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.246184, Avg loss: 2.288211 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.406067  [    0/120000]\n",
      "loss: 0.470791  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.240921, Avg loss: 2.458678 \n",
      "\n",
      "CPU times: user 38.5 s, sys: 6.56 s, total: 45.1 s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=400,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Выполните пункты 2.3 и 2.4, используя предобученные эмбеддинги Glove.\n",
    "Прокомментируйте результат.\n",
    "Эмбеддинги из скачанного файла загрузите в виде двумерного тензора pretrained_embeddings.\n",
    "Обратите внимание, что номер строки в этом тензоре должен соответствовать\n",
    "токену (слову), имеющему такой индекс в вашем словаре.\n",
    "для слов, которых нет в файле с эмбеддингами, инициализуйте эмбеддинг\n",
    "случайным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21963/21963 [01:49<00:00, 200.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Embedding(21963, 100, padding_idx=0), 6143)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.100d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.empty(len(train_news_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, w in tqdm(enumerate(train_news_dataset.vocab.alphabet), total=len(train_news_dataset.vocab.alphabet)):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[w].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.384300  [    0/120000]\n",
      "loss: 0.682494  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.265263, Avg loss: 1.929394 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.649540  [    0/120000]\n",
      "loss: 0.538743  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.274737, Avg loss: 1.981722 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.636043  [    0/120000]\n",
      "loss: 0.535246  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.261974, Avg loss: 2.009139 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.609225  [    0/120000]\n",
      "loss: 0.540131  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.266316, Avg loss: 2.066741 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.573378  [    0/120000]\n",
      "loss: 0.522352  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.268421, Avg loss: 2.089403 \n",
      "\n",
      "CPU times: user 35.8 s, sys: 3.11 s, total: 38.9 s\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_rnn_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=400,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.386772  [    0/120000]\n",
      "loss: 0.495739  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.262895, Avg loss: 1.893308 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.572895  [    0/120000]\n",
      "loss: 0.439423  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.265526, Avg loss: 2.153729 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.331599  [    0/120000]\n",
      "loss: 0.529190  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.261316, Avg loss: 2.320305 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.453869  [    0/120000]\n",
      "loss: 0.418262  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.263289, Avg loss: 2.351837 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.422201  [    0/120000]\n",
      "loss: 0.370544  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.258158, Avg loss: 2.510423 \n",
      "\n",
      "CPU times: user 38.2 s, sys: 3.63 s, total: 41.8 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_lstm_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=400,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.387033  [    0/120000]\n",
      "loss: 0.659489  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.256842, Avg loss: 1.852312 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.541958  [    0/120000]\n",
      "loss: 0.521535  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.260132, Avg loss: 2.023633 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.472931  [    0/120000]\n",
      "loss: 0.498077  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.259211, Avg loss: 2.071061 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.567600  [    0/120000]\n",
      "loss: 0.423918  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.259079, Avg loss: 2.148984 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.528394  [    0/120000]\n",
      "loss: 0.492820  [102400/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.268816, Avg loss: 2.194674 \n",
      "\n",
      "CPU times: user 36 s, sys: 3.79 s, total: 39.8 s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_gru_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=400,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_table(\n",
    "        models: t.List[t.Tuple[str, NewsClassifier]],\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> pd.DataFrame:\n",
    "    general_report = {}\n",
    "    for name, model in models:\n",
    "        report = {}\n",
    "        y_test, y_pred = get_y_test_y_pred(model, test_dataloader, device)\n",
    "        ms = metrics.classification_report(y_test, y_pred, zero_division=True, output_dict=True)\n",
    "        report[\"accuracy\"] = ms[\"accuracy\"]\n",
    "        report[\"precision (w avg)\"] = ms[\"weighted avg\"][\"precision\"]\n",
    "        report[\"recall (w avg)\"] = ms[\"weighted avg\"][\"recall\"]\n",
    "        report[\"f1-score (w avg)\"] = ms[\"weighted avg\"][\"f1-score\"]\n",
    "        general_report[name] = report\n",
    "    return pd.DataFrame(general_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "      <th>RNN (pretrained)</th>\n",
       "      <th>LSTM (pretrained)</th>\n",
       "      <th>GRU (pretrained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.241974</td>\n",
       "      <td>0.238553</td>\n",
       "      <td>0.240921</td>\n",
       "      <td>0.268421</td>\n",
       "      <td>0.258158</td>\n",
       "      <td>0.268816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision (w avg)</th>\n",
       "      <td>0.241831</td>\n",
       "      <td>0.240686</td>\n",
       "      <td>0.242836</td>\n",
       "      <td>0.271295</td>\n",
       "      <td>0.265203</td>\n",
       "      <td>0.273612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall (w avg)</th>\n",
       "      <td>0.241974</td>\n",
       "      <td>0.238553</td>\n",
       "      <td>0.240921</td>\n",
       "      <td>0.268421</td>\n",
       "      <td>0.258158</td>\n",
       "      <td>0.268816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score (w avg)</th>\n",
       "      <td>0.236382</td>\n",
       "      <td>0.230627</td>\n",
       "      <td>0.236126</td>\n",
       "      <td>0.264540</td>\n",
       "      <td>0.252909</td>\n",
       "      <td>0.260767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RNN      LSTM       GRU  RNN (pretrained)  \\\n",
       "accuracy           0.241974  0.238553  0.240921          0.268421   \n",
       "precision (w avg)  0.241831  0.240686  0.242836          0.271295   \n",
       "recall (w avg)     0.241974  0.238553  0.240921          0.268421   \n",
       "f1-score (w avg)   0.236382  0.230627  0.236126          0.264540   \n",
       "\n",
       "                   LSTM (pretrained)  GRU (pretrained)  \n",
       "accuracy                    0.258158          0.268816  \n",
       "precision (w avg)           0.265203          0.273612  \n",
       "recall (w avg)              0.258158          0.268816  \n",
       "f1-score (w avg)            0.252909          0.260767  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = make_pivot_table(\n",
    "    [\n",
    "        (\"RNN\", news_rnn_net),\n",
    "        (\"LSTM\", news_lstm_net),\n",
    "        (\"GRU\", news_gru_net),\n",
    "        (\"RNN (pretrained)\", news_rnn_pretrained_net),\n",
    "        (\"LSTM (pretrained)\", news_lstm_pretrained_net),\n",
    "        (\"GRU (pretrained)\", news_gru_pretrained_net),\n",
    "    ],\n",
    "    test_news_dataloader,\n",
    "    DEVICE,\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = report.plot.bar(rot=15)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1));"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPopRjm9A6la5QJRG/PWjfN",
   "collapsed_sections": [],
   "name": "blank__07_rnn_1_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
