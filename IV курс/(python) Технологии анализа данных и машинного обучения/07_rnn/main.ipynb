{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5669,
     "status": "ok",
     "timestamp": 1619632510103,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "zKMq7dp2W15Y",
    "outputId": "ce2273c5-6a96-4216-9d88-fbee51bf5ff0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE.upper()} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_cuda(device: str) -> bool:\n",
    "    return device == \"cuda\"\n",
    "\n",
    "\n",
    "def common_train(\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_dataloader: DataLoader,\n",
    "        epochs: int,\n",
    "        test_dataloader: DataLoader = None,\n",
    "        lr_scheduler=None,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.List[float]:\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
    "        train_loss = train_loop(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "        )\n",
    "        train_losses.append(train_loss.item())\n",
    "        if test_dataloader:\n",
    "            loss, acc = test_loop(test_dataloader, model, loss_fn, device=device)\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step(loss)\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        verbose: int = 100,\n",
    "        device: str = \"cpu\",\n",
    ") -> torch.Tensor:\n",
    "    model.train()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss\n",
    "        if batch % verbose == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "        del x, y, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss / num_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)  # noqa\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, correct = 0, 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        avg_loss += loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # noqa\n",
    "\n",
    "        del x, y, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:>4f}, Avg loss: {avg_loss:>8f} \\n\")\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_test_split(dataset: t.Union[Dataset, t.Sized], train_part: float) -> t.Tuple[Subset, Subset]:\n",
    "    train_size = round(train_part * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_y_test_y_pred(\n",
    "        model: nn.Module,\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        y_test.append(y)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.hstack(y_test).detach().cpu(), torch.hstack(y_pred).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm-QilGISxkt"
   },
   "source": [
    "## 1. Классификация фамилий (RNN)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/frNchuaBQVLxyA?w=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdPr92i6k-If"
   },
   "source": [
    "1.1 Используя класс `nn.RNNCell` (абстракцию для отдельного временного шага RNN), реализуйте простейшую рекуррентную сеть Элмана в виде класса `RNN`. Используя созданный класс `RNN`, решите задачу классификации фамилий. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ir6UUkl6l4tp"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, hx: torch.Tensor = None):\n",
    "        batch_size, sequence_size, _ = inputs.size()\n",
    "        inputs = inputs.permute(1, 0, 2)  # для nn.RNNCell batch_size должен быть на 2-ой месте\n",
    "\n",
    "        if hx is None:\n",
    "            # так же скрытое состояние инициализируется в nn.RNN\n",
    "            hx = torch.zeros(batch_size, self.hidden_size, dtype=inputs.dtype, device=inputs.device)\n",
    "        else:\n",
    "            # 1-ая размерность равная 1 для совместимости с nn.RNN\n",
    "            hx = hx.squeeze(0)  # избавляемся от 1-ой размерности равной 1\n",
    "\n",
    "        hidden = []\n",
    "        for i in range(sequence_size):\n",
    "            hx = self.rnn_cell(inputs[i], hx)\n",
    "            hidden.append(hx)\n",
    "\n",
    "        hidden = torch.stack(hidden)\n",
    "        hx = hidden[-1].unsqueeze(0)\n",
    "        return hidden.permute(1, 0, 2), hx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка реализации RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "input_size, hidden_size = 4, 5\n",
    "inputs = torch.randn(2, 3, input_size)\n",
    "hx = torch.randn(1, 2, hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "my_rnn = RNN(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "true_rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<UnsqueezeBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6515,  0.5430,  0.4023,  0.6325, -0.6068],\n",
       "          [ 0.9149, -0.1088,  0.6385, -0.7387,  0.7532],\n",
       "          [-0.6936,  0.5123, -0.2784, -0.5693, -0.0055]],\n",
       " \n",
       "         [[ 0.1954,  0.6152,  0.2958, -0.8005,  0.8074],\n",
       "          [-0.4577,  0.7566,  0.2972, -0.8834,  0.1265],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.6936,  0.5123, -0.2784, -0.5693, -0.0055],\n",
       "          [ 0.7166,  0.1516,  0.8047, -0.2007,  0.8192]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rnn(inputs, hx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.rnn = RNN(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x, hx = self.rnn(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesVocab:\n",
    "    pad = \"<PAD>\"\n",
    "\n",
    "    def __init__(self, surnames: t.List[str]):\n",
    "        uniques = set()\n",
    "        max_len = 0\n",
    "        for w in map(str.lower, surnames):\n",
    "            uniques.update(w)\n",
    "            max_len = max(len(w), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, *uniques]\n",
    "        self.max_len = max_len\n",
    "        self.ch2i = {ch: i for i, ch in enumerate(self.alphabet)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        indices = [self.ch2i[ch] for ch in word]\n",
    "        indices += [self.ch2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.ch2i[self.pad], as_tuple=True)[0]\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \"\".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class SurnamesDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    surnames: t.List[str]\n",
    "    vocab: SurnamesVocab\n",
    "    labeler: LabelEncoder\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.surnames = self.df[\"surname\"].tolist()\n",
    "        self.vocab = SurnamesVocab(self.surnames)\n",
    "        size = self.vocab.encode(self.surnames[0].lower()).size()\n",
    "        data = torch.vstack([self.vocab.encode(w.lower()) for w in self.surnames])\n",
    "        self.data = data.view(len(self.surnames), *size)\n",
    "\n",
    "        self.labeler = LabelEncoder()\n",
    "        targets = self.labeler.fit_transform(self.df[\"nationality\"])\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, word: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(word)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames_dataset = SurnamesDataset(DATA_DIR / \"surnames.csv\")\n",
    "len(surnames_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8784 2196\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_surnames_dataset, test_surnames_dataset = train_test_split(surnames_dataset, train_part=0.8)\n",
    "print(len(train_surnames_dataset), len(test_surnames_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "handmade_rnn_net = SurnamesRNNClassifier(\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(handmade_rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.871371  [    0/ 8784]\n",
      "loss: 1.428667  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.635701, Avg loss: 1.257843 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.134080  [    0/ 8784]\n",
      "loss: 1.171728  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.691257, Avg loss: 1.047224 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.981887  [    0/ 8784]\n",
      "loss: 0.838968  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.718124, Avg loss: 0.958215 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.826575  [    0/ 8784]\n",
      "loss: 0.806086  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.901430 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.690964  [    0/ 8784]\n",
      "loss: 0.937260  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.871603 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.737858  [    0/ 8784]\n",
      "loss: 0.567542  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.753188, Avg loss: 0.869683 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.566065  [    0/ 8784]\n",
      "loss: 0.659171  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.752732, Avg loss: 0.864761 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.682094  [    0/ 8784]\n",
      "loss: 0.648732  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.745446, Avg loss: 0.873809 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.610356  [    0/ 8784]\n",
      "loss: 0.488593  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.758652, Avg loss: 0.817213 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.389507  [    0/ 8784]\n",
      "loss: 0.574232  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.761384, Avg loss: 0.823749 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.533677  [    0/ 8784]\n",
      "loss: 0.463529  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.757741, Avg loss: 0.855524 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.438514  [    0/ 8784]\n",
      "loss: 0.529348  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.768215, Avg loss: 0.858234 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.366016  [    0/ 8784]\n",
      "loss: 0.496154  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.766849, Avg loss: 0.860953 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.412161  [    0/ 8784]\n",
      "loss: 0.465148  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.756375, Avg loss: 0.887782 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.292166  [    0/ 8784]\n",
      "loss: 0.507486  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.766849, Avg loss: 0.862257 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.299910  [    0/ 8784]\n",
      "loss: 0.338752  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.765938, Avg loss: 0.900125 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.510561  [    0/ 8784]\n",
      "loss: 0.408101  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.768215, Avg loss: 0.864865 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.301343  [    0/ 8784]\n",
      "loss: 0.369471  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.759107, Avg loss: 0.914645 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.198048  [    0/ 8784]\n",
      "loss: 0.354010  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.768670, Avg loss: 0.914926 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.265750  [    0/ 8784]\n",
      "loss: 0.317317  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.765938, Avg loss: 0.914157 \n",
      "\n",
      "CPU times: user 19 s, sys: 670 ms, total: 19.7 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=handmade_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.97      1.00      0.99       340\n",
      "     Chinese       0.70      0.74      0.72        38\n",
      "       Czech       0.58      0.31      0.41        96\n",
      "       Dutch       0.72      0.41      0.53        51\n",
      "     English       0.71      0.85      0.77       573\n",
      "      French       0.20      0.10      0.14        39\n",
      "      German       0.57      0.51      0.54       121\n",
      "       Greek       0.75      0.62      0.68        34\n",
      "       Irish       0.58      0.30      0.39        37\n",
      "     Italian       0.72      0.77      0.75       128\n",
      "    Japanese       0.80      0.90      0.85       156\n",
      "      Korean       0.22      0.20      0.21        10\n",
      "      Polish       0.60      0.46      0.52        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.86      0.88      0.87       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.43      0.38      0.40        50\n",
      "  Vietnamese       0.50      0.15      0.24        13\n",
      "\n",
      "    accuracy                           0.77      2196\n",
      "   macro avg       0.55      0.48      0.50      2196\n",
      "weighted avg       0.75      0.77      0.75      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(handmade_rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2MIErKTo9aO"
   },
   "source": [
    "1.2 Замените модуль `RNN` из 1.1 на модули `nn.RNN`, `nn.LSTM` и `nn.GRU` (не забудьте указать аргумент `batch_first=True`). Сравните результаты работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesAutobotRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            num_embeddings: int,\n",
    "            embedding_dim: int,\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.cx = cx.detach()\n",
    "            self.hx = hx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.RNN,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.867698  [    0/ 8784]\n",
      "loss: 1.622730  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.576503, Avg loss: 1.452961 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.343994  [    0/ 8784]\n",
      "loss: 1.309450  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.643898, Avg loss: 1.214564 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.136298  [    0/ 8784]\n",
      "loss: 0.985533  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.668033, Avg loss: 1.117155 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.034030  [    0/ 8784]\n",
      "loss: 0.907188  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.685337, Avg loss: 1.039520 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.867153  [    0/ 8784]\n",
      "loss: 1.092656  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.712204, Avg loss: 1.004628 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.896041  [    0/ 8784]\n",
      "loss: 0.793838  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.717668, Avg loss: 0.964900 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.617007  [    0/ 8784]\n",
      "loss: 0.816494  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.723588, Avg loss: 0.964670 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.714479  [    0/ 8784]\n",
      "loss: 0.857214  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728597, Avg loss: 0.952684 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.697628  [    0/ 8784]\n",
      "loss: 0.592615  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.926547 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.551538  [    0/ 8784]\n",
      "loss: 0.633459  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728142, Avg loss: 0.937231 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.715209  [    0/ 8784]\n",
      "loss: 0.639617  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.959645 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.469723  [    0/ 8784]\n",
      "loss: 0.624045  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733607, Avg loss: 0.926298 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.516783  [    0/ 8784]\n",
      "loss: 0.640670  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.944383 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.582168  [    0/ 8784]\n",
      "loss: 0.529668  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.735883, Avg loss: 0.956000 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.441305  [    0/ 8784]\n",
      "loss: 0.693570  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733607, Avg loss: 0.945853 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.454312  [    0/ 8784]\n",
      "loss: 0.566176  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744080, Avg loss: 0.957040 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.599831  [    0/ 8784]\n",
      "loss: 0.592176  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.971436 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.357661  [    0/ 8784]\n",
      "loss: 0.531775  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744080, Avg loss: 0.963544 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.359129  [    0/ 8784]\n",
      "loss: 0.519572  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740437, Avg loss: 1.001554 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.416318  [    0/ 8784]\n",
      "loss: 0.340305  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.737705, Avg loss: 0.988230 \n",
      "\n",
      "CPU times: user 14.4 s, sys: 987 ms, total: 15.4 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.69      0.66      0.68        38\n",
      "       Czech       0.36      0.22      0.27        96\n",
      "       Dutch       0.76      0.43      0.55        51\n",
      "     English       0.67      0.85      0.75       573\n",
      "      French       0.21      0.08      0.11        39\n",
      "      German       0.55      0.47      0.51       121\n",
      "       Greek       0.60      0.53      0.56        34\n",
      "       Irish       0.56      0.27      0.36        37\n",
      "     Italian       0.64      0.69      0.66       128\n",
      "    Japanese       0.84      0.86      0.85       156\n",
      "      Korean       0.13      0.20      0.16        10\n",
      "      Polish       0.55      0.46      0.50        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.85      0.84      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.44      0.32      0.37        50\n",
      "  Vietnamese       0.25      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.50      0.44      0.46      2196\n",
      "weighted avg       0.72      0.74      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.LSTM,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.881627  [    0/ 8784]\n",
      "loss: 1.897253  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.548270, Avg loss: 1.575520 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.446818  [    0/ 8784]\n",
      "loss: 1.583484  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.622951, Avg loss: 1.298717 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.327830  [    0/ 8784]\n",
      "loss: 1.244951  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.658925, Avg loss: 1.151080 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.028336  [    0/ 8784]\n",
      "loss: 1.087917  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.684426, Avg loss: 1.079769 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.016642  [    0/ 8784]\n",
      "loss: 0.972635  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.694444, Avg loss: 1.021266 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.997646  [    0/ 8784]\n",
      "loss: 0.899113  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.711293, Avg loss: 0.972107 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.799433  [    0/ 8784]\n",
      "loss: 0.756676  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.715847, Avg loss: 0.954568 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.679155  [    0/ 8784]\n",
      "loss: 0.670355  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.720401, Avg loss: 0.951260 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.510739  [    0/ 8784]\n",
      "loss: 0.774990  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726321, Avg loss: 0.935295 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.555812  [    0/ 8784]\n",
      "loss: 0.748182  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.729053, Avg loss: 0.925696 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.609481  [    0/ 8784]\n",
      "loss: 0.699831  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733607, Avg loss: 0.914702 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.743457  [    0/ 8784]\n",
      "loss: 0.695813  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.923025 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.649552  [    0/ 8784]\n",
      "loss: 0.652283  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.923130 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.440038  [    0/ 8784]\n",
      "loss: 0.722412  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.946387 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.530398  [    0/ 8784]\n",
      "loss: 0.597478  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.926060 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.596823  [    0/ 8784]\n",
      "loss: 0.598366  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742259, Avg loss: 0.917588 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.528638  [    0/ 8784]\n",
      "loss: 0.613093  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.935278 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.409705  [    0/ 8784]\n",
      "loss: 0.493071  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.944450 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.407807  [    0/ 8784]\n",
      "loss: 0.479782  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.937698 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.473019  [    0/ 8784]\n",
      "loss: 0.553792  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.747268, Avg loss: 0.952067 \n",
      "\n",
      "CPU times: user 15.5 s, sys: 785 ms, total: 16.2 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.94      1.00      0.97       340\n",
      "     Chinese       0.73      0.71      0.72        38\n",
      "       Czech       0.71      0.25      0.37        96\n",
      "       Dutch       0.68      0.33      0.45        51\n",
      "     English       0.68      0.88      0.77       573\n",
      "      French       0.10      0.03      0.04        39\n",
      "      German       0.58      0.40      0.47       121\n",
      "       Greek       0.62      0.47      0.53        34\n",
      "       Irish       0.77      0.27      0.40        37\n",
      "     Italian       0.62      0.70      0.65       128\n",
      "    Japanese       0.84      0.83      0.84       156\n",
      "      Korean       0.14      0.10      0.12        10\n",
      "      Polish       0.55      0.42      0.48        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.83      0.87      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.48      0.44      0.46        50\n",
      "  Vietnamese       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.75      2196\n",
      "   macro avg       0.51      0.43      0.45      2196\n",
      "weighted avg       0.72      0.75      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesAutobotRNNClassifier(\n",
    "    rnn_cls=nn.GRU,\n",
    "    num_embeddings=len(surnames_dataset.vocab),\n",
    "    embedding_dim=128,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.882524  [    0/ 8784]\n",
      "loss: 1.701462  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.555556, Avg loss: 1.564122 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.729184  [    0/ 8784]\n",
      "loss: 1.257021  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.619763, Avg loss: 1.277214 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.238291  [    0/ 8784]\n",
      "loss: 1.264170  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.653461, Avg loss: 1.164596 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.100605  [    0/ 8784]\n",
      "loss: 1.004837  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.687614, Avg loss: 1.076801 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.068239  [    0/ 8784]\n",
      "loss: 0.889830  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.698998, Avg loss: 1.016363 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.863274  [    0/ 8784]\n",
      "loss: 0.725156  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.716302, Avg loss: 0.972016 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.775604  [    0/ 8784]\n",
      "loss: 0.737316  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726776, Avg loss: 0.942037 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.636706  [    0/ 8784]\n",
      "loss: 0.857919  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.730419, Avg loss: 0.948082 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.596445  [    0/ 8784]\n",
      "loss: 0.620632  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.930073 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.683630  [    0/ 8784]\n",
      "loss: 0.598535  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.927676 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.682902  [    0/ 8784]\n",
      "loss: 0.676390  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739526, Avg loss: 0.930253 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.538946  [    0/ 8784]\n",
      "loss: 0.702722  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741803, Avg loss: 0.920292 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.472399  [    0/ 8784]\n",
      "loss: 0.491259  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736794, Avg loss: 0.949475 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.400065  [    0/ 8784]\n",
      "loss: 0.490521  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.925693 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.696983  [    0/ 8784]\n",
      "loss: 0.341032  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738616, Avg loss: 0.938608 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.410351  [    0/ 8784]\n",
      "loss: 0.459912  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740893, Avg loss: 0.951076 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.497068  [    0/ 8784]\n",
      "loss: 0.720429  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.741348, Avg loss: 0.966408 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.343265  [    0/ 8784]\n",
      "loss: 0.595012  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.742714, Avg loss: 0.987191 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.387341  [    0/ 8784]\n",
      "loss: 0.514563  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.740437, Avg loss: 0.984081 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.591733  [    0/ 8784]\n",
      "loss: 0.323493  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.744536, Avg loss: 0.959734 \n",
      "\n",
      "CPU times: user 14.1 s, sys: 785 ms, total: 14.9 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.71      0.76      0.73        38\n",
      "       Czech       0.52      0.26      0.35        96\n",
      "       Dutch       0.76      0.43      0.55        51\n",
      "     English       0.67      0.86      0.76       573\n",
      "      French       0.12      0.08      0.09        39\n",
      "      German       0.61      0.43      0.50       121\n",
      "       Greek       0.61      0.50      0.55        34\n",
      "       Irish       0.53      0.22      0.31        37\n",
      "     Italian       0.64      0.67      0.66       128\n",
      "    Japanese       0.87      0.84      0.85       156\n",
      "      Korean       0.33      0.30      0.32        10\n",
      "      Polish       0.62      0.31      0.41        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.82      0.87      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.50      0.34      0.40        50\n",
      "  Vietnamese       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.74      2196\n",
      "   macro avg       0.57      0.44      0.47      2196\n",
      "weighted avg       0.73      0.74      0.72      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6YBam_3t-fO"
   },
   "source": [
    "1.3 Загрузите предобученные эмбеддинги (https://disk.yandex.ru/d/BHuT2tEXr_yBOQ?w=1) в модуль `nn.Embedding` и обучите модели из 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesDecepticonRNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(56, 50, padding_idx=0), 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.50d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.ones(len(surnames_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, ch in enumerate(surnames_dataset.vocab.alphabet):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[ch].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.844056  [    0/ 8784]\n",
      "loss: 1.961889  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.467213, Avg loss: 1.822342 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.779048  [    0/ 8784]\n",
      "loss: 1.709585  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.549180, Avg loss: 1.583308 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.586961  [    0/ 8784]\n",
      "loss: 1.536344  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.590619, Avg loss: 1.432243 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.422195  [    0/ 8784]\n",
      "loss: 1.295004  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.619763, Avg loss: 1.315370 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.026811  [    0/ 8784]\n",
      "loss: 1.261107  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.653005, Avg loss: 1.213327 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.207651  [    0/ 8784]\n",
      "loss: 1.371465  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.664390, Avg loss: 1.174516 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.001609  [    0/ 8784]\n",
      "loss: 1.127143  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.674863, Avg loss: 1.121807 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.114882  [    0/ 8784]\n",
      "loss: 0.997404  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.694444, Avg loss: 1.087345 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.751744  [    0/ 8784]\n",
      "loss: 0.995532  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.695811, Avg loss: 1.040971 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.896355  [    0/ 8784]\n",
      "loss: 0.798047  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.695355, Avg loss: 1.032741 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.887015  [    0/ 8784]\n",
      "loss: 0.953217  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.709927, Avg loss: 1.007165 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.821532  [    0/ 8784]\n",
      "loss: 0.865263  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.721767, Avg loss: 0.984645 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.868341  [    0/ 8784]\n",
      "loss: 0.833825  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.724044, Avg loss: 0.992559 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.879253  [    0/ 8784]\n",
      "loss: 0.811807  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.720401, Avg loss: 0.990630 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.818395  [    0/ 8784]\n",
      "loss: 0.716188  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.727687, Avg loss: 0.964243 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.739453  [    0/ 8784]\n",
      "loss: 0.745104  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728142, Avg loss: 0.970473 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.647621  [    0/ 8784]\n",
      "loss: 0.587193  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.739982, Avg loss: 0.945135 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.758711  [    0/ 8784]\n",
      "loss: 0.693703  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.731330, Avg loss: 0.951683 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.753960  [    0/ 8784]\n",
      "loss: 0.683821  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.967765 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.681926  [    0/ 8784]\n",
      "loss: 0.662540  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734062, Avg loss: 0.978683 \n",
      "\n",
      "CPU times: user 13.5 s, sys: 542 ms, total: 14.1 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.95      1.00      0.97       340\n",
      "     Chinese       0.68      0.89      0.77        38\n",
      "       Czech       0.44      0.17      0.24        96\n",
      "       Dutch       0.73      0.22      0.33        51\n",
      "     English       0.64      0.91      0.75       573\n",
      "      French       0.29      0.05      0.09        39\n",
      "      German       0.57      0.26      0.36       121\n",
      "       Greek       0.63      0.50      0.56        34\n",
      "       Irish       0.70      0.19      0.30        37\n",
      "     Italian       0.60      0.73      0.66       128\n",
      "    Japanese       0.77      0.87      0.82       156\n",
      "      Korean       0.33      0.10      0.15        10\n",
      "      Polish       0.41      0.35      0.38        26\n",
      "  Portuguese       1.00      0.00      0.00         9\n",
      "     Russian       0.86      0.84      0.85       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.40      0.16      0.23        50\n",
      "  Vietnamese       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.73      2196\n",
      "   macro avg       0.61      0.41      0.42      2196\n",
      "weighted avg       0.72      0.73      0.70      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(rnn_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.900342  [    0/ 8784]\n",
      "loss: 2.213569  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.427596, Avg loss: 1.954141 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.058177  [    0/ 8784]\n",
      "loss: 1.854866  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.525046, Avg loss: 1.634154 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.752625  [    0/ 8784]\n",
      "loss: 1.598981  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.575137, Avg loss: 1.473715 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.504472  [    0/ 8784]\n",
      "loss: 1.431903  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.615209, Avg loss: 1.337168 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.181609  [    0/ 8784]\n",
      "loss: 1.336328  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.648907, Avg loss: 1.247855 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.225144  [    0/ 8784]\n",
      "loss: 1.040383  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.665756, Avg loss: 1.151511 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.961408  [    0/ 8784]\n",
      "loss: 1.046402  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.684882, Avg loss: 1.100526 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.094806  [    0/ 8784]\n",
      "loss: 1.093279  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.692168, Avg loss: 1.037835 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.820307  [    0/ 8784]\n",
      "loss: 0.785100  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704007, Avg loss: 1.019090 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.723590  [    0/ 8784]\n",
      "loss: 1.096239  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704463, Avg loss: 0.994296 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.755592  [    0/ 8784]\n",
      "loss: 0.757259  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.716758, Avg loss: 0.985664 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.763125  [    0/ 8784]\n",
      "loss: 0.908435  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.717213, Avg loss: 0.967228 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.767880  [    0/ 8784]\n",
      "loss: 0.535491  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.723133, Avg loss: 0.947493 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.694060  [    0/ 8784]\n",
      "loss: 0.880087  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.733151, Avg loss: 0.919929 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.639907  [    0/ 8784]\n",
      "loss: 0.626777  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.726321, Avg loss: 0.944004 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.554029  [    0/ 8784]\n",
      "loss: 0.607244  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.917548 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.703819  [    0/ 8784]\n",
      "loss: 0.521138  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.737250, Avg loss: 0.921349 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.570754  [    0/ 8784]\n",
      "loss: 0.558696  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.936880 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.678497  [    0/ 8784]\n",
      "loss: 0.482724  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.738160, Avg loss: 0.919696 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.432330  [    0/ 8784]\n",
      "loss: 0.376955  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.734517, Avg loss: 0.945419 \n",
      "\n",
      "CPU times: user 14.2 s, sys: 1.17 s, total: 15.4 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.96      1.00      0.98       340\n",
      "     Chinese       0.78      0.82      0.79        38\n",
      "       Czech       0.51      0.24      0.33        96\n",
      "       Dutch       0.81      0.33      0.47        51\n",
      "     English       0.64      0.89      0.74       573\n",
      "      French       0.16      0.08      0.10        39\n",
      "      German       0.50      0.37      0.43       121\n",
      "       Greek       0.68      0.44      0.54        34\n",
      "       Irish       0.67      0.16      0.26        37\n",
      "     Italian       0.69      0.67      0.68       128\n",
      "    Japanese       0.84      0.82      0.83       156\n",
      "      Korean       0.25      0.20      0.22        10\n",
      "      Polish       0.67      0.31      0.42        26\n",
      "  Portuguese       0.00      0.00      0.00         9\n",
      "     Russian       0.83      0.84      0.83       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.47      0.32      0.38        50\n",
      "  Vietnamese       0.67      0.15      0.25        13\n",
      "\n",
      "    accuracy                           0.73      2196\n",
      "   macro avg       0.56      0.42      0.46      2196\n",
      "weighted avg       0.72      0.73      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(lstm_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "gru_net = SurnamesDecepticonRNNClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=surnames_dataset.vocab.max_len,\n",
    "    num_classes=len(surnames_dataset.labeler.classes_),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gru_net.parameters(), lr=0.0015)\n",
    "\n",
    "train_dataloader = DataLoader(train_surnames_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_surnames_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.875406  [    0/ 8784]\n",
      "loss: 1.868236  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.447177, Avg loss: 1.894630 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 1.732831  [    0/ 8784]\n",
      "loss: 1.549724  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.535974, Avg loss: 1.594002 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.401428  [    0/ 8784]\n",
      "loss: 1.449472  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.586976, Avg loss: 1.437853 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.214180  [    0/ 8784]\n",
      "loss: 1.418058  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.624772, Avg loss: 1.306517 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.270644  [    0/ 8784]\n",
      "loss: 1.450443  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.642532, Avg loss: 1.223909 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.351915  [    0/ 8784]\n",
      "loss: 1.343317  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.675319, Avg loss: 1.145013 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.985525  [    0/ 8784]\n",
      "loss: 1.002818  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.686703, Avg loss: 1.092562 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.905974  [    0/ 8784]\n",
      "loss: 0.918747  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.694444, Avg loss: 1.049730 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 1.094790  [    0/ 8784]\n",
      "loss: 1.141004  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.704463, Avg loss: 1.016187 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.818420  [    0/ 8784]\n",
      "loss: 1.056125  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.707195, Avg loss: 1.018995 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 1.091380  [    0/ 8784]\n",
      "loss: 0.815202  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714481, Avg loss: 0.978578 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.682685  [    0/ 8784]\n",
      "loss: 0.774810  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714481, Avg loss: 0.988900 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.767641  [    0/ 8784]\n",
      "loss: 0.698225  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.714481, Avg loss: 0.984372 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.951281  [    0/ 8784]\n",
      "loss: 0.753823  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.728142, Avg loss: 0.956839 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.714478  [    0/ 8784]\n",
      "loss: 0.738817  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.730874, Avg loss: 0.966173 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.720497  [    0/ 8784]\n",
      "loss: 0.631770  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.725410, Avg loss: 0.945504 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.870992  [    0/ 8784]\n",
      "loss: 0.600989  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736339, Avg loss: 0.958751 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.716781  [    0/ 8784]\n",
      "loss: 0.779762  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.736794, Avg loss: 0.941503 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.619216  [    0/ 8784]\n",
      "loss: 0.762638  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.743625, Avg loss: 0.942942 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.458017  [    0/ 8784]\n",
      "loss: 0.623875  [ 6400/ 8784]\n",
      "Test Error: \n",
      " Accuracy: 0.732240, Avg loss: 0.963809 \n",
      "\n",
      "CPU times: user 14.1 s, sys: 1.14 s, total: 15.2 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=20,\n",
    "    model=gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    verbose=50,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.94      1.00      0.97       340\n",
      "     Chinese       0.75      0.71      0.73        38\n",
      "       Czech       0.46      0.20      0.28        96\n",
      "       Dutch       0.61      0.22      0.32        51\n",
      "     English       0.66      0.87      0.75       573\n",
      "      French       0.14      0.05      0.08        39\n",
      "      German       0.59      0.40      0.47       121\n",
      "       Greek       0.50      0.44      0.47        34\n",
      "       Irish       0.92      0.30      0.45        37\n",
      "     Italian       0.66      0.75      0.70       128\n",
      "    Japanese       0.75      0.87      0.81       156\n",
      "      Korean       0.13      0.20      0.16        10\n",
      "      Polish       0.50      0.23      0.32        26\n",
      "  Portuguese       0.50      0.11      0.18         9\n",
      "     Russian       0.85      0.83      0.84       458\n",
      "    Scottish       0.00      0.00      0.00        17\n",
      "     Spanish       0.41      0.30      0.34        50\n",
      "  Vietnamese       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.73      2196\n",
      "   macro avg       0.55      0.42      0.44      2196\n",
      "weighted avg       0.71      0.73      0.71      2196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = get_y_test_y_pred(gru_net, test_dataloader, DEVICE)\n",
    "\n",
    "print(metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    target_names=surnames_dataset.labeler.classes_,\n",
    "    zero_division=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7kf990U9Do-"
   },
   "source": [
    "## 2. Классификация новостей на основе заголовка\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/FN-EgWGIpyjLxQ?w=1\n",
    "\n",
    "Эмбеддинги: https://nlp.stanford.edu/projects/glove/ (находите ссылку на архив\n",
    "glove.6B.zip, в нем несколько файлов с эмбеддингами слов, выбираете один из файлов в\n",
    "архиве)\n",
    "\n",
    "2.1 Загрузите набор данных train.csv. Выполните предобработку столбца Title\n",
    "\n",
    "2.2 На основе этих данных создайте датасет NewsDataset . Не забудьте добавить\n",
    "специальные токены `<PAD>` для дополнения последовательностей до нужной длины и\n",
    "`<UNK>` для корректной обработке ранее не встречавшихся токенов. В данной задаче\n",
    "рассматривайте отдельные слова как токены. Разбейте датасет на обучающее и\n",
    "валидационное множество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def simple_preprocess_news_title(title: str) -> str:\n",
    "    return title.lower()\n",
    "\n",
    "\n",
    "def complex_preprocess_news_title(\n",
    "        title: str,\n",
    "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
    "        min_word_len: int = 0,\n",
    ") -> str:\n",
    "    title = simple_preprocess_news_title(title)\n",
    "    title = PATTERN.sub(\" \", title)\n",
    "\n",
    "    words = []\n",
    "    for word in nltk.word_tokenize(title):\n",
    "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "            if not lemmatizer_or_stemmer:\n",
    "                words.append(word)\n",
    "                continue\n",
    "            word = lemmatizer_or_stemmer(word)\n",
    "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
    "                words.append(word)\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def wordnet_lemmatizer(token: str) -> str:\n",
    "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
    "\n",
    "\n",
    "_snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "\n",
    "\n",
    "def snowball_stemmer(token: str) -> str:\n",
    "    return _snowball_stemmer.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVocab:\n",
    "    pad = \"<PAD>\"\n",
    "    unknown = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, news_titles: t.List[str], max_len: int = 0):\n",
    "        uniques = set()\n",
    "        for title in news_titles:\n",
    "            words = nltk.word_tokenize(title)\n",
    "            uniques.update(words)\n",
    "            max_len = max(len(words), max_len)\n",
    "\n",
    "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
    "        unknown_idx = w2i[self.unknown]\n",
    "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "    def encode(self, review: str) -> torch.Tensor:\n",
    "        indices = [self.w2i[w] for w in nltk.word_tokenize(review)]\n",
    "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
    "        if len(pad_indices):\n",
    "            indices = indices[:pad_indices[0]]\n",
    "        return \" \".join(self.alphabet[i] for i in indices)\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "    titles: t.List[str]\n",
    "    classes: t.List[int]\n",
    "    vocab: NewsVocab\n",
    "    data: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "\n",
    "    def __init__(self, path: Path, preprocess: t.Callable[[str], str], title_max_len: int = 0):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "        self.titles = self.df[\"Title\"].apply(preprocess).tolist()\n",
    "        self.vocab = NewsVocab(self.titles, max_len=title_max_len)\n",
    "\n",
    "        self.data = torch.vstack([self.vocab.encode(w.lower()) for w in self.titles])\n",
    "        self.targets = torch.tensor(self.df[\"Class Index\"].to_numpy(), dtype=torch.long) - 1\n",
    "        self.classes = self.targets.unique().tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def encode(self, title: str) -> torch.Tensor:\n",
    "        return self.vocab.encode(title)\n",
    "\n",
    "    def decode(self, indices: torch.Tensor) -> str:\n",
    "        return self.vocab.decode(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 7600)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_news_title(title: str) -> str:\n",
    "    return complex_preprocess_news_title(title, lemmatizer_or_stemmer=snowball_stemmer, min_word_len=3)\n",
    "\n",
    "\n",
    "train_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/train.csv\",\n",
    "    preprocess_news_title,\n",
    ")\n",
    "test_news_dataset = NewsDataset(\n",
    "    DATA_DIR / \"news/test.csv\",\n",
    "    preprocess_news_title,\n",
    "    title_max_len=train_news_dataset.vocab.max_len,\n",
    ")\n",
    "len(train_news_dataset), len(test_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_dataloader = DataLoader(train_news_dataset, batch_size=256, shuffle=True)\n",
    "test_news_dataloader = DataLoader(test_news_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Создайте модель для классификации, используя слой nn.Embedding и слой nn.RNN.\n",
    "эмбеддинги инициализируйте случайным образом не забудьте указать аргумент padding_idx для nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding: nn.Embedding,\n",
    "            rnn_cls: t.Union[t.Type[nn.RNN], t.Type[nn.LSTM], t.Type[nn.GRU]],\n",
    "            rnn_hidden_size: int,\n",
    "            vector_size: int,\n",
    "            num_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.hx, self.cx = None, None\n",
    "        self.rnn = rnn_cls(input_size=self.embedding.embedding_dim, hidden_size=rnn_hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size * vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def reset_rnn_state(self):\n",
    "        self.hx, self.cx = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if isinstance(self.rnn, (nn.RNN, nn.GRU)):\n",
    "            x, hx = self.rnn(x, self.hx)\n",
    "            self.hx = hx.detach()\n",
    "        else:\n",
    "            if self.hx is not None and self.cx is not None:\n",
    "                hx_cx = (self.hx, self.cx)\n",
    "            else:\n",
    "                hx_cx = None\n",
    "            x, (hx, cx) = self.rnn(x, hx_cx)\n",
    "            self.hx = hx.detach()\n",
    "            self.cx = cx.detach()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.399165  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.262105, Avg loss: 1.840470 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.785680  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.259474, Avg loss: 2.033921 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.548066  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.256842, Avg loss: 2.154701 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.433791  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.259342, Avg loss: 2.363977 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.323912  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.258158, Avg loss: 2.609166 \n",
      "\n",
      "CPU times: user 40 s, sys: 6.19 s, total: 46.2 s\n",
      "Wall time: 47.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_rnn_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=500,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Переобучите модель, заменив слой nn.RNN на nn.LSTM и nn.GRU . Сравните качество\n",
    "на тестовой выборке. Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.387967  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.255921, Avg loss: 1.798040 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.540377  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.263421, Avg loss: 1.980840 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.448271  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.263684, Avg loss: 2.149188 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.301585  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.256447, Avg loss: 2.383534 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.378154  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.257632, Avg loss: 2.515698 \n",
      "\n",
      "CPU times: user 39.1 s, sys: 5.88 s, total: 45 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_lstm_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=500,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_net = NewsClassifier(\n",
    "    embedding=nn.Embedding(num_embeddings=len(train_news_dataset.vocab), embedding_dim=64, padding_idx=0),\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.384754  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.257632, Avg loss: 1.757510 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.617294  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.260789, Avg loss: 1.953100 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.537489  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.262895, Avg loss: 2.082329 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.386451  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.260658, Avg loss: 2.183148 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.410345  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.259211, Avg loss: 2.296090 \n",
      "\n",
      "CPU times: user 39.2 s, sys: 6.32 s, total: 45.5 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_gru_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=500,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Выполните пункты 2.3 и 2.4, используя предобученные эмбеддинги Glove.\n",
    "Прокомментируйте результат.\n",
    "Эмбеддинги из скачанного файла загрузите в виде двумерного тензора pretrained_embeddings.\n",
    "Обратите внимание, что номер строки в этом тензоре должен соответствовать\n",
    "токену (слову), имеющему такой индекс в вашем словаре.\n",
    "для слов, которых нет в файле с эмбеддингами, инициализуйте эмбеддинг\n",
    "случайным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21963/21963 [01:55<00:00, 189.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Embedding(21963, 100, padding_idx=0), 6143)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "embedding_weights = pd.read_csv(\n",
    "    DATA_DIR / \"glove.6B/glove.6B.100d.txt\",\n",
    "    sep=\" \",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "weights = torch.empty(len(train_news_dataset.vocab), embedding_weights.shape[1], dtype=torch.float32)\n",
    "torch.nn.init.normal_(weights)\n",
    "\n",
    "miss = 0\n",
    "for i, w in tqdm(enumerate(train_news_dataset.vocab.alphabet), total=len(train_news_dataset.vocab.alphabet)):\n",
    "    try:\n",
    "        weights[i] = torch.from_numpy(embedding_weights.loc[w].to_numpy())\n",
    "    except KeyError:\n",
    "        miss += 1\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(weights, padding_idx=0)\n",
    "embedding, miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_rnn_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.RNN,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_rnn_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.384148  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.240395, Avg loss: 2.024677 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.680559  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.240789, Avg loss: 2.103679 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.643991  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.235658, Avg loss: 2.202144 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.633764  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.236053, Avg loss: 2.255651 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.578327  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.233684, Avg loss: 2.311034 \n",
      "\n",
      "CPU times: user 36.4 s, sys: 3.29 s, total: 39.7 s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_rnn_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=500,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_lstm_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.LSTM,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_lstm_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.384447  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.241316, Avg loss: 1.992097 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.578082  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.241579, Avg loss: 2.273448 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.334912  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.246579, Avg loss: 2.456173 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.458666  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.245132, Avg loss: 2.498301 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.427835  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.249868, Avg loss: 2.628455 \n",
      "\n",
      "CPU times: user 39.3 s, sys: 3.42 s, total: 42.7 s\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_lstm_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=500,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "news_gru_pretrained_net = NewsClassifier(\n",
    "    embedding=embedding,\n",
    "    rnn_cls=nn.GRU,\n",
    "    rnn_hidden_size=64,\n",
    "    vector_size=train_news_dataset.vocab.max_len,\n",
    "    num_classes=len(train_news_dataset.classes),\n",
    ").to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(news_gru_pretrained_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 1.386531  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.235395, Avg loss: 1.919036 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.554642  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.237368, Avg loss: 2.109704 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.470054  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.235921, Avg loss: 2.188451 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.548236  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.243684, Avg loss: 2.385556 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.535775  [    0/120000]\n",
      "Test Error: \n",
      " Accuracy: 0.248421, Avg loss: 2.428009 \n",
      "\n",
      "CPU times: user 36.5 s, sys: 3.82 s, total: 40.3 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = common_train(\n",
    "    epochs=5,\n",
    "    model=news_gru_pretrained_net,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_news_dataloader,\n",
    "    test_dataloader=test_news_dataloader,\n",
    "    verbose=500,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты сведите в таблицу (модель/метрика качества на тестовом множестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_table(\n",
    "        models: t.List[t.Tuple[str, NewsClassifier]],\n",
    "        test_dataloader: DataLoader,\n",
    "        device: str = \"cpu\",\n",
    ") -> pd.DataFrame:\n",
    "    general_report = {}\n",
    "    for name, model in models:\n",
    "        report = {}\n",
    "        y_test, y_pred = get_y_test_y_pred(model, test_dataloader, device)\n",
    "        ms = metrics.classification_report(y_test, y_pred, zero_division=True, output_dict=True)\n",
    "        report[\"accuracy\"] = ms[\"accuracy\"]\n",
    "        report[\"precision (w avg)\"] = ms[\"weighted avg\"][\"precision\"]\n",
    "        report[\"recall (w avg)\"] = ms[\"weighted avg\"][\"recall\"]\n",
    "        report[\"f1-score (w avg)\"] = ms[\"weighted avg\"][\"f1-score\"]\n",
    "        general_report[name] = report\n",
    "    return pd.DataFrame(general_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "      <th>RNN (pretrained)</th>\n",
       "      <th>LSTM (pretrained)</th>\n",
       "      <th>GRU (pretrained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.258158</td>\n",
       "      <td>0.257632</td>\n",
       "      <td>0.259211</td>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.249868</td>\n",
       "      <td>0.248289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision (w avg)</th>\n",
       "      <td>0.256169</td>\n",
       "      <td>0.257710</td>\n",
       "      <td>0.259789</td>\n",
       "      <td>0.228780</td>\n",
       "      <td>0.245715</td>\n",
       "      <td>0.243924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall (w avg)</th>\n",
       "      <td>0.258158</td>\n",
       "      <td>0.257632</td>\n",
       "      <td>0.259211</td>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.249868</td>\n",
       "      <td>0.248289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score (w avg)</th>\n",
       "      <td>0.248798</td>\n",
       "      <td>0.251148</td>\n",
       "      <td>0.253172</td>\n",
       "      <td>0.224777</td>\n",
       "      <td>0.241715</td>\n",
       "      <td>0.234514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RNN      LSTM       GRU  RNN (pretrained)  \\\n",
       "accuracy           0.258158  0.257632  0.259211          0.233684   \n",
       "precision (w avg)  0.256169  0.257710  0.259789          0.228780   \n",
       "recall (w avg)     0.258158  0.257632  0.259211          0.233684   \n",
       "f1-score (w avg)   0.248798  0.251148  0.253172          0.224777   \n",
       "\n",
       "                   LSTM (pretrained)  GRU (pretrained)  \n",
       "accuracy                    0.249868          0.248289  \n",
       "precision (w avg)           0.245715          0.243924  \n",
       "recall (w avg)              0.249868          0.248289  \n",
       "f1-score (w avg)            0.241715          0.234514  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = make_pivot_table(\n",
    "    [\n",
    "        (\"RNN\", news_rnn_net),\n",
    "        (\"LSTM\", news_lstm_net),\n",
    "        (\"GRU\", news_gru_net),\n",
    "        (\"RNN (pretrained)\", news_rnn_pretrained_net),\n",
    "        (\"LSTM (pretrained)\", news_lstm_pretrained_net),\n",
    "        (\"GRU (pretrained)\", news_gru_pretrained_net),\n",
    "    ],\n",
    "    test_news_dataloader,\n",
    "    DEVICE,\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = report.plot.bar(rot=20)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1));"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPopRjm9A6la5QJRG/PWjfN",
   "collapsed_sections": [],
   "name": "blank__07_rnn_1_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
